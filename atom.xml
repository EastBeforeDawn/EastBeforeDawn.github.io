<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://EastBeforeDawn.github.io</id>
    <title>东方未明</title>
    <updated>2020-06-17T15:16:53.835Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://EastBeforeDawn.github.io"/>
    <link rel="self" href="https://EastBeforeDawn.github.io/atom.xml"/>
    <subtitle>温故而知新</subtitle>
    <logo>https://EastBeforeDawn.github.io/images/avatar.png</logo>
    <icon>https://EastBeforeDawn.github.io/favicon.ico</icon>
    <rights>All rights reserved 2020, 东方未明</rights>
    <entry>
        <title type="html"><![CDATA[MYSQL进阶]]></title>
        <id>https://EastBeforeDawn.github.io/post/mysqlAdvanced/</id>
        <link href="https://EastBeforeDawn.github.io/post/mysqlAdvanced/">
        </link>
        <updated>2020-06-11T15:02:58.000Z</updated>
        <content type="html"><![CDATA[<h2 id="mysql安装">MYSQL安装</h2>
<ul>
<li>略</li>
</ul>
<h3 id="配置文件问题">配置文件问题</h3>
<h4 id="mysql查看当前使用哪个路径下配置文件mycnf的方法">MySQL查看当前使用哪个路径下配置文件my.cnf的方法</h4>
<h5 id="查看mysql默认读取mycnf的目录">查看mysql默认读取my.cnf的目录</h5>
<ul>
<li>mysql --help|grep 'my.cnf' 或 mysqld --verbose --help |grep -A 1 'Default options'</li>
</ul>
<blockquote>
<p>/etc/my.cnf, /etc/mysql/my.cnf, /usr/local/etc/my.cnf, ~/.my.cnf 这些就是MySQL默认会搜寻my.cnf的目录，顺序排前的优先。</p>
</blockquote>
<h5 id="查看是否使用了指定目录的mycnf文件">查看是否使用了指定目录的my.cnf文件</h5>
<ul>
<li>ps -ef|grep mysql|grep 'my.cnf'</li>
</ul>
<blockquote>
<p>在启动MySQL后，可以通过查看MySQL的进程，看看是否有设置使用指定目录的my.cnf文件，如果有则表示MySQL启动时是加载了这个配置文件。如果命令没有输出，那么表示没有设置使用指定目录的my.cnf</p>
</blockquote>
<h5 id="启动时没有使用配置文件">启动时没有使用配置文件</h5>
<blockquote>
<p>从5.7.18开始不在二进制包中提供my-default.cnf文件。在5.7.18版本中，使用tar.gz安装时，也就是压缩包解压出来安装这种，已经不再需要my.cnf文件也能正常运行，此时为默认配置。<br>
如果没有设置使用指定目录my.cnf文件及默认读取目录没有my.cnf文件，表示MySQL启动时并没有加载配置文件，而是使用默认配置。需要修改配置，可以在MySQL默认读取的目录中，创建一个my.cnf文件（例如：/etc/my.cnf），把需要修改的配置内容写入，重启MySQL后即可生效。</p>
</blockquote>
<h3 id="字符集问题">字符集问题</h3>
<blockquote>
<p>5.7.30安装完毕之后无由于字符集的原因无法插入中文，在配置文件中【mysqld】下面添加 character-set-server=utf8并重启MYSQL可以解决，已经创建的表需要修改库和表的字符集</p>
</blockquote>
<ul>
<li><code>show variables like 'character%'</code> 查询字符集</li>
<li><code>alter database 库名 character set 'utf8'</code> 更改库的字符集</li>
<li><code>alter table 表名 convert to character set 'utf-8'</code>  改表的字符集</li>
</ul>
<h2 id="mysql权限管理">MYSQL权限管理</h2>
<h3 id="用户管理">用户管理</h3>
<blockquote>
<p>在 mysql库user表中为维护用户数据</p>
</blockquote>
<h4 id="查看用户">查看用户</h4>
<ul>
<li><code>select * from mysql.user</code></li>
</ul>
<h5 id="字段解释">字段解释</h5>
<ul>
<li>host 连接类型 一共有5种格式
<ul>
<li>% 表示可以通过所有方式链接</li>
<li>IP地址 指定的地址才可以连接</li>
<li>机器名 指定的机器才可以连接</li>
<li>localhost 本地连接</li>
<li>::1 ipv6</li>
</ul>
</li>
<li>user 用户名
<ul>
<li>一个用户可以通过多种方式连接，每个链接的权限不同</li>
</ul>
</li>
<li>authentication_string
<ul>
<li>密码，使用MYSQLSHA1算法，不可逆</li>
</ul>
</li>
<li>***_priv
<ul>
<li>各种权限</li>
</ul>
</li>
</ul>
<h4 id="创建用户">创建用户</h4>
<ul>
<li><code>create user 用户名 identified by '密码'</code></li>
</ul>
<h4 id="修改密码">修改密码</h4>
<h5 id="修改当前用户密码">修改当前用户密码</h5>
<ul>
<li><code>set password = password('密码')</code></li>
</ul>
<h5 id="修改其他用户密码">修改其他用户密码</h5>
<ul>
<li><code>update mysql.user set password = password('密码') where user = '用户名'</code></li>
</ul>
<h4 id="修改用户名">修改用户名</h4>
<ul>
<li><code>update mysql.user set e user = '用户名' where user = '用户名'</code></li>
</ul>
<h4 id="删除用户名">删除用户名</h4>
<ul>
<li><code>drop user 用户名</code></li>
</ul>
<p><strong><code>操作USER表的数据 在flush privileges之后才会生效</code></strong></p>
<h3 id="权限管理">权限管理</h3>
<h4 id="授予权限">授予权限</h4>
<ul>
<li><code>grant 权限1,权限2... on 库名.表名 to 用户名@用户访问方式 【 identified by ’密码‘】</code></li>
<li>*可以代替所有库和所有表，%可以代替所有权限
<ul>
<li>grant select on mydb.mytb to lisi@localhost    给lisi本地用户赋予读权限</li>
<li>grant select on 星号.星号to zhangsan@% identified by '123456';   给zhangsan用户赋予读权限，如果不存在则创建lisi</li>
</ul>
</li>
</ul>
<h4 id="查看权限">查看权限</h4>
<h5 id="查看当前用户">查看当前用户</h5>
<ul>
<li>show grants</li>
</ul>
<h5 id="查看其他用户">查看其他用户</h5>
<ul>
<li>select * from mysql.user where user =</li>
</ul>
<h5 id="查看某个表">查看某个表</h5>
<ul>
<li>select * from tables_priv;</li>
</ul>
<h3 id="查询所有用户正在干什么">查询所有用户正在干什么</h3>
<ul>
<li>SHOW PROCESSLIST</li>
<li>kill [id] //杀掉这个用户</li>
</ul>
<h2 id="mysql-sql_mode模式说明及设置">MYSQL sql_mode模式说明及设置</h2>
<h3 id="mysql的sql_mode合理设置">MySQL的sql_mode合理设置</h3>
<blockquote>
<p>sql_mode是个很容易被忽视的变量,默认值是空值,在这种设置下是可以允许一些非法操作的,比如允许一些非法数据的插入。在生产环境必须将这个值设置为严格模式,所以开发、测试环境的数据库也必须要设置,这样在开发测试阶段就可以发现问题.</p>
</blockquote>
<blockquote>
<p>如果设置的是宽松模式，那么我们在插入数据的时候，即便是给了一个错误的数据，也可能会被接受，并且不报错，例如：我在创建一个表时，该表中有一个字段为name，给name设置的字段类型时char(10)，如果我在插入数据的时候，其中name这个字段对应的有一条数据的长度超过了10，例如'1234567890abc'，超过了设定的字段长度10，那么不会报错，并且取前十个字符存上，也就是说你这个数据被存为了'1234567890',而'abc'就没有了，但是我们知道，我们给的这条数据是错误的，因为超过了字段长度，但是并没有报错，并且mysql自行处理并接受了，这就是宽松模式的效果，其实在开发、测试、生产等环境中，我们应该采用的是严格模式，出现这种错误，应该报错才对，所以MySQL5.7版本就将sql_mode默认值改为了严格模式，并且我们即便是用的MySQL5.6，也应该自行将其改为严格模式，而你记着，MySQL等等的这些数据库，都是想把关于数据的所有操作都自己包揽下来，包括数据的校验，其实好多时候，我们应该在自己开发的项目程序级别将这些校验给做了，虽然写项目的时候麻烦了一些步骤，但是这样做之后，我们在进行数据库迁移或者在项目的迁移时，就会方便很多，这个看你们自行来衡量。mysql除了数据校验之外，你慢慢的学习过程中会发现，它能够做的事情还有很多很多，将你程序中做的好多事情都包揽了。</p>
</blockquote>
<h3 id="sql-model-常用来解决下面几类问题">sql model 常用来解决下面几类问题</h3>
<ol>
<li>通过设置sql mode, 可以完成不同严格程度的数据校验，有效地保障数据准备性。</li>
<li>通过设置sql model 为宽松模式，来保证大多数sql符合标准的sql语法，这样应用在不同数据库之间进行迁移时，则不需要对业务sql 进行较大的修改。</li>
<li>在不同数据库之间进行数据迁移之前，通过设置SQL Mode 可以使MySQL 上的数据更方便地迁移到目标数据库中。</li>
</ol>
<h3 id="sql_mode常用值">sql_mode常用值</h3>
<h4 id="only_full_group_by">ONLY_FULL_GROUP_BY:</h4>
<ul>
<li>对于GROUP BY聚合操作,如果在SELECT中的列,没有在GROUP BY中出现,那么这个SQL是不合法的,因为列不在GROUP BY从句中</li>
</ul>
<h4 id="no_auto_value_on_zero">NO_AUTO_VALUE_ON_ZERO:</h4>
<ul>
<li>该值影响自增长列的插入。默认设置下,插入0或NULL代表生成下一个自增长值。如果用户 希望插入的值为0,而该列又是自增长的,那么这个选项就有用了。</li>
</ul>
<h4 id="strict_trans_tables">STRICT_TRANS_TABLES:</h4>
<ul>
<li>在该模式下,如果一个值不能插入到一个事务表中,则中断当前的操作,对非事务表不做限制</li>
</ul>
<h4 id="no_zero_in_date">NO_ZERO_IN_DATE:</h4>
<ul>
<li>在严格模式下,不允许日期和月份为零</li>
</ul>
<h4 id="no_zero_date">NO_ZERO_DATE:</h4>
<ul>
<li>设置该值,mysql数据库不允许插入零日期,插入零日期会抛出错误而不是警告。</li>
</ul>
<h4 id="error_for_division_by_zero">ERROR_FOR_DIVISION_BY_ZERO:</h4>
<ul>
<li>在INSERT或UPDATE过程中,如果数据被零除,则产生错误而非警告。如 果未给出该模式,那么数据被零除时MySQL返回NULL</li>
</ul>
<h4 id="no_auto_create_user">NO_AUTO_CREATE_USER:</h4>
<ul>
<li>禁止GRANT创建密码为空的用户</li>
</ul>
<h4 id="no_engine_substitution">NO_ENGINE_SUBSTITUTION:</h4>
<ul>
<li>如果需要的存储引擎被禁用或未编译,那么抛出错误。不设置此值时,用默认的存储引擎替代,并抛出一个异常</li>
</ul>
<h4 id="pipes_as_concat">PIPES_AS_CONCAT:</h4>
<ul>
<li>将&quot;||&quot;视为字符串的连接操作符而非或运算符,这和Oracle数据库是一样的,也和字符串的拼接函数Concat相类似</li>
</ul>
<h4 id="ansi_quotes">ANSI_QUOTES:</h4>
<ul>
<li>启用ANSI_QUOTES后,不能用双引号来引用字符串,因为它被解释为识别符</li>
</ul>
<h4 id="oracle">ORACLE</h4>
<ul>
<li>ORACLE的sql_mode设置等同:PIPES_AS_CONCAT, ANSI_QUOTES, IGNORE_SPACE, NO_KEY_OPTIONS, NO_TABLE_OPTIONS, NO_FIELD_OPTIONS, NO_AUTO_CREATE_USER.</li>
<li>如果使用mysql,为了继续保留大家使用oracle的习惯,可以对mysql的sql_mode设置如下: 在my.cnf添加如下配置</li>
</ul>
<pre><code>[mysqld]  
sql_mode='ONLY_FULL_GROUP_BY,NO_AUTO_VALUE_ON_ZERO,STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE, ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,PIPES_AS_CONCAT,ANSI_QUOTES'
</code></pre>
<h3 id="版本区别">版本区别</h3>
<p>MySQL5.6和MySQL5.7默认的sql_mode模式参数是不一样的,5.6的mode是NO_ENGINE_SUBSTITUTION，其实表示的是一个空值，相当于没有什么模式设置，可以理解为宽松模式。5.7的mode是STRICT_TRANS_TABLES，也就是严格模式。</p>
<h3 id="严格模式存在的问题">严格模式存在的问题：</h3>
<p>若设置模式中包含了NO_ZERO_DATE，那么MySQL数据库不允许插入零日期，插入零日期会抛出错误而不是警告。例如表中含字段TIMESTAMP列（如果未声明为NULL或显示DEFAULT子句）将自动分配DEFAULT '0000-00-00 00:00:00'（零时间戳），也或者是本测试的表day列默认允许插入零日期 '0000-00-00' COMMENT '日期'；这些显然是不满足sql_mode中的NO_ZERO_DATE而报错。</p>
<h3 id="如何修改">如何修改</h3>
<ul>
<li>方式一
<ul>
<li>先执行select @@sql_mode,复制查询出来的值并将其中的NO_ZERO_IN_DATE,NO_ZERO_DATE删除，然后执行set sql_mode = '修改后的值'或者set session sql_mode='修改后的值';，例如：set session sql_mode='STRICT_TRANS_TABLES';改为严格模式</li>
<li>此方法只在当前会话中生效，关闭当前会话就不生效了。</li>
</ul>
</li>
<li>方式二
<ul>
<li>先执行select @@global.sql_mode,复制查询出来的值并将其中的NO_ZERO_IN_DATE,NO_ZERO_DATE删除，然后执行set global sql_mode = '修改后的值'。</li>
<li>此方法在当前服务中生效，重新MySQL服务后失效</li>
</ul>
</li>
<li>方式三
<ul>
<li>在mysql的安装目录下，或my.cnf文件(windows系统是my.ini文件)，添加如下,然后重启mysql。</li>
</ul>
</li>
</ul>
<pre><code>[mysqld]
sql_mode=ONLY_FULL_GROUP_BY,STRICT_TRANS_TABLES,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER
</code></pre>
<h2 id="mysql逻辑架构">MYSQL逻辑架构</h2>
<p><img src="https://EastBeforeDawn.github.io/post-images/1591888055036.png" alt="" loading="lazy"><br>
<img src="https://EastBeforeDawn.github.io/post-images/1591888060387.jpeg" alt="" loading="lazy"></p>
<h3 id="总体概论">总体概论</h3>
<h4 id="连接层">连接层</h4>
<blockquote>
<p>最上层是一些客户端和连接服务，包括本地sock通信和大多数基于客户端/服务端工具实现的类似于tcp/ip的通信。主要完成一些类似于连接处理、授权认证、及相关的安全方案。在该层上引出了线程池的概念，为通过认证安全接入的客户端提供线程。同样在该层上可以实现基于SSl的安全链接。服务器也会为安全接入的每个客户端验证它所具有的的操作权限。</p>
</blockquote>
<h5 id="connectors是不同语言中与sql的交互">Connectors：是不同语言中与SQL的交互</h5>
<h5 id="management-serveices-utilities-系统管理和控制工具">Management Serveices &amp;Utilities ：系统管理和控制工具</h5>
<h4 id="服务层">服务层</h4>
<blockquote>
<p>第二层架构主要大多数的核心服务功能，如SQL接口，并完成缓存的查询，SQL的分析及优化及部分内置函数的执行。所有跨存储引擎的功能也在这层实现，如过程、函数等。在该层，服务器会解析查询并创建相应的内部解析树，并对其完成相应的优化，如确定查询表的顺序，是否利用索引等，最后生成相应的执行操作，如select语句，服务器还会查询内部的缓存。如果缓存空间足够大这样在解决大量读操作的环境中能够良好的提升系统的性能。</p>
</blockquote>
<h5 id="connection-pool-连接池管理缓冲用户连接线程处理等需要缓存的需求">Connection Pool: 连接池管理缓冲用户连接，线程处理等需要缓存的需求。</h5>
<ul>
<li>负责监听对 MySQL Server 的各种请求，接收连接请求，转发所有连接请求到线程管理模块。每一个连接上 MySQL Server 的客户端请求都会被分配（或创建）一个连接线程为其单独服务。而连接线程的主要工作就是负责 MySQL Server 与客户端的通信，</li>
<li>接受客户端的命令请求，传递 Server 端的结果信息等。线程管理模块则负责管理维护这些连接线程。包括线程的创建，线程的 cache 等</li>
</ul>
<h5 id="sql-interface-sql接口">SQL Interface: SQL接口</h5>
<ul>
<li>接受用户的SQL命令，并且返回用户需要查询的结果。比如select from就是调用SQL Interface</li>
</ul>
<h5 id="parser-解析器">Parser: 解析器</h5>
<ul>
<li>SQL命令传递到解析器的时候会被解析器验证和解析。解析器是由Lex和YACC实现的，是一个很长的脚本。在 MySQL中我们习惯将所有 Client 端发送给 Server 端的命令都称为 query ，在 MySQL Server 里面，连接线程接收到客户端的一个 Query 后，会直接将该 query 传递给专门负责将各种 Query 进行分类然后转发给各个对应的处理模块。主要功能：
<ul>
<li>将SQL语句进行语义和语法的分析，分解成数据结构，然后按照不同的操作类型进行分类，然后做出针对性的转发到后续步骤，以后SQL语句的传递和处理就是基于这个结构的。</li>
<li>如果在分解构成中遇到错误，那么就说明这个sql语句是不合理的</li>
</ul>
</li>
</ul>
<h5 id="optimizer-查询优化器">Optimizer: 查询优化器。</h5>
<ul>
<li>SQL语句在查询之前会使用查询优化器对查询进行优化。就是优化客户端请求的 query（sql语句） ，根据客户端请求的 query 语句，和数据库中的一些统计信息，在一系列算法的基础上进行分析，得出一个最优的策略，告诉后面的程序如何取得这个 query 语句的结果</li>
</ul>
<h5 id="cache和buffer-查询缓存">Cache和Buffer： 查询缓存。</h5>
<ul>
<li>他的主要功能是将客户端提交 给MySQL 的 Select 类 query 请求的返回结果集 cache 到内存中，与该 query 的一个 hash 值 做一个对应。该 Query 所取数据的基表发生任何数据的变化之后， MySQL 会自动使该 query 的Cache 失效。在读写比例非常高的应用系统中， Query Cache 对性能的提高是非常显著的。当然它对内存的消耗也是非常大的。</li>
<li>如果查询缓存有命中的查询结果，查询语句就可以直接去查询缓存中取数据。这个缓存机制是由一系列小缓存组成的。比如表缓存，记录缓存，key缓存，权限缓存等</li>
</ul>
<h4 id="引擎层存储引擎层">引擎层存储引擎层</h4>
<blockquote>
<p>存储引擎真正的负责了MySQL中数据的存储和读取，服务器通过api与存储引擎进行通信。不同的存储引擎具有的功能不同，这样我们可以根据自己的实际需求进行选取，后面介绍MyISAM和InnoDB<br>
存储引擎接口存储引擎接口模块可以说是 MySQL 数据库中最有特色的一点了。目前各种数据库产品中，基本上只有 MySQL 可以实现其底层数据存储引擎的插件式管理。这个模块实际上只是 一个抽象类，但正是因为它成功地将各种数据处理高度抽象化，才成就了今天 MySQL 可插拔存储引擎的特色。</p>
</blockquote>
<ul>
<li><code>注意：存储引擎是基于表的，而不是数据库。</code></li>
</ul>
<h4 id="数据存储层">数据存储层</h4>
<blockquote>
<p>只要将数据存储在运行与裸设备的文件系统上，并完成与存储引擎的交互。</p>
</blockquote>
<h3 id="查询sql执行周期">查询SQL执行周期</h3>
<h4 id="show-profile">show profile</h4>
<blockquote>
<p>show profile能够查出最近15条SQL语句的运行状态包含运行过程中执行了哪些操作，各占用了多长时间，以便开发者的分析。</p>
</blockquote>
<h4 id="查看是否开启profile默认为关闭">查看是否开启profile,默认为关闭</h4>
<ul>
<li><code>show variables like 'profiling';</code></li>
</ul>
<h4 id="开启profile">开启profile</h4>
<ul>
<li><code>set profiling = 1;</code></li>
</ul>
<h4 id="具体使用">具体使用</h4>
<ul>
<li>先使用show profiles 查询最近使用的SQL语句</li>
<li>再使用show profile [cpu,block,io] for query 编号 查询SQL执行周期 (show profile默认查询最后一次执行的SQL)</li>
</ul>
<pre><code class="language-tex">mysql&gt; show profiles;
+----------+------------+----------------------------------+
| Query_ID | Duration   | Query                            |
+----------+------------+----------------------------------+
|        1 | 0.00020600 | select * from clazz              |
|        2 | 0.00006400 | show profile for queru 1         |
|        3 | 0.00021500 | select * from clazz              |
|        4 | 0.00028800 | select * from clazz where id = 1 |
|        5 | 0.00024300 | select * from clazz where id = 1 |
+----------+------------+----------------------------------+
mysql&gt; show profile for query 5;
+----------------------+----------+
| Status               | Duration |
+----------------------+----------+
| starting             | 0.000065 |
| checking permissions | 0.000007 |
| Opening tables       | 0.000015 |
| init                 | 0.000022 |
| System lock          | 0.000008 |
| optimizing           | 0.000010 |
| statistics           | 0.000041 |
| preparing            | 0.000009 |
| executing            | 0.000003 |
| Sending data         | 0.000011 |
| end                  | 0.000003 |
| query end            | 0.000012 |
| closing tables       | 0.000006 |
| freeing items        | 0.000018 |
| cleaning up          | 0.000013 |
+----------------------+----------+
</code></pre>
<h3 id="sql执行顺序">SQL执行顺序</h3>
<ol>
<li>from</li>
<li>on</li>
<li>join</li>
<li>where</li>
<li>group by</li>
<li>having</li>
<li>select</li>
<li>distinct</li>
<li>order by</li>
<li>limit</li>
</ol>
<h3 id="存储引擎">存储引擎</h3>
<h4 id="查询mysql支持的引擎">查询MYSQL支持的引擎</h4>
<ul>
<li><code>show engines</code>;</li>
</ul>
<pre><code class="language-tex">mysql&gt; show engines;
+--------------------+---------+----------------------------------------------------------------+--------------+------+------------+
| Engine             | Support | Comment                                                        | Transactions | XA   | Savepoints |
+--------------------+---------+----------------------------------------------------------------+--------------+------+------------+
| InnoDB             | DEFAULT | Supports transactions, row-level locking, and foreign keys     | YES          | YES  | YES        |
| MRG_MYISAM         | YES     | Collection of identical MyISAM tables                          | NO           | NO   | NO         |
| MEMORY             | YES     | Hash based, stored in memory, useful for temporary tables      | NO           | NO   | NO         |
| BLACKHOLE          | YES     | /dev/null storage engine (anything you write to it disappears) | NO           | NO   | NO         |
| MyISAM             | YES     | MyISAM storage engine                                          | NO           | NO   | NO         |
| CSV                | YES     | CSV storage engine                                             | NO           | NO   | NO         |
| ARCHIVE            | YES     | Archive storage engine                                         | NO           | NO   | NO         |
| PERFORMANCE_SCHEMA | YES     | Performance Schema                                             | NO           | NO   | NO         |
| FEDERATED          | NO      | Federated MySQL storage engine                                 | NULL         | NULL | NULL       |
+--------------------+---------+----------------------------------------------------------------+--------------+------+------------+
</code></pre>
<h4 id="mysql引擎介绍">MYSQL引擎介绍</h4>
<h5 id="innodb">InnoDB</h5>
<ul>
<li>
<p>InnoDB是MySQL默认的事务型引擎，也是最重要、最广泛的存储引擎。它的设计是用来处理大量短期事务，短期事务大部分是正常提交的，很少回滚。InnoDB的性能和自动崩溃恢复特性，使得它在非事务型存储的需求中，也很流行。除了非常特别的原因需要使用其他引擎，InnoDB也是非常好值得花时间研究的对象。</p>
</li>
<li>
<p>InnoDB的数据存储在表空间中，表空间是由InnoDB管理的黑盒文件系统，由一系列系统文件组成。InnoDB可以将每个表的数据和索引存放在单独的文件中。InnoDB也可以使用裸设备作为表空间存储介质。</p>
</li>
<li>
<p>InnoDB通过间隙锁（next-key locking）防止幻读的出现。InnoDB是基于聚簇索引建立，与其他存储引擎有很大的区别，聚簇索引对主键查询有很高的性能，不过它的二级索引（secondary index，非主键索引）必须包含主键列。所以如果主键列很大的话，索引会很大。</p>
</li>
</ul>
<h5 id="myisam">MyISAM</h5>
<ul>
<li>
<p>在5.1之前，MyISAM是默认的引擎，MyISAM有大量的特心态，包括全文索引、压缩、空间函数。但是MyISAM不支持事务和行级锁，而且在崩溃后无法安全恢复。即使后续版本中MyISAM支持了事务，但是很多人的概念中依然是不支持事务的引擎。</p>
</li>
<li>
<p>MyISAM并不是无所事处。对于一些只读数据，或者表空间较小，可以忍受恢复操作，可以使用MyISAM。MyISAM会将表存储在两个文件中：数据文件、索引文件。分别是.MYD、.MYI扩展名。MyISAM表可以包含动态或者静态行。MySQL会根据表定义选择那种行格式。MyISAM表的行记录数，取决于磁盘空间和操作系统中的单个文件最大尺寸。</p>
</li>
<li>
<p>在MySQL中，默认配置只能存储256TB的数据。因为指向数据记录的指针长度是6字节。需要修改可以修改表的MAX_ROWS和AVG_ROW_LENGTH选项。两个相乘是最大的大小。会导致重建索引。</p>
</li>
<li>
<p>MyISAM是对整个表加锁，而不是行锁，读取的时候对表加共享锁，写入的时候加排他锁。但是在表有读取查询的同时，也可以往表内写入记录。</p>
</li>
<li>
<p>对于MyISAM，即使是Blob，Text等等长字段，也可以基于前500字符创建索引，MyISAM支持全文索引，这是一个基于分词创建的索引，也可以支持复杂的查询。</p>
</li>
<li>
<p>MyISAM可以选择延迟更新索引键，在创建表的时候指定delay_key_write选项，在每次修改执行完成时，不会立刻将修改的索引数据写入磁盘，而是写到缓存区，只有在清理缓存区或者关闭表的时候才会将索引写入磁盘。这可以极大的提升写入性能，但是在主机崩溃时会造成索引损坏，需要执行修复操作。</p>
</li>
<li>
<p>MyISAM另一个特性是支持压缩表。如果数据在写入后不会修改，那么这个表适合MyISAM压缩表。可以使用myisampack对MyISAM表进行打包，压缩表是不可以修改数据的。压缩表可以极大的减少磁盘占用，因此可以减少磁盘IO，提升性能，压缩表也支持索引，但是索引也是只读的。</p>
</li>
<li>
<p>整体来说MyISAM并没有那么不堪，但是由于没有行锁机制，所以在海量写入的时候，会导致所有查询处于Locked状态。</p>
</li>
</ul>
<h5 id="archive">Archive</h5>
<ul>
<li>
<p>Archive引擎支持是Insert，Select操作，现在支持索引，Archive引擎会缓存所有的写，并利用zlib对写入行进行压缩，所以比MyISAM表的磁盘IO更少。但是在每次Select查询都需要执行全表扫描。所以在Archive适合日志和数据采集应用。这类应用在分析时往往需要全表扫描忙活着更快的Insert操作场景中也可以使用。</p>
</li>
<li>
<p>Archive引擎支持行级锁和专用的缓存区，所以可以实现高并发写入，在查询开始到返回表存在的所有行数之前，Archive会阻止其他Select执行，用来实现一致性读。另外也实现了批量写入结束前批量写入数据对读操作不可见，这种机制模仿了事务和MVCC的特性，但是Archive不是一个事务型引擎，而是针对高写入压缩做了优化的简单引擎。</p>
</li>
</ul>
<h5 id="blackhole">Blackhole</h5>
<ul>
<li>Blackhole没有实现任何存储机制，它会舍弃所有写入数据，不做任何保存，但是服务器会记录Blackhole表的日志，用于复制数据到备库，或者只是简单的记录到日志，这种特殊的存储引擎可以在一些特俗的复制架构和日志审核时发挥作用。但是不推荐。</li>
</ul>
<h5 id="csv">CSV</h5>
<ul>
<li>CSV引擎可以将普通的CSV文件作为MySQL表来处理，但是这种表不支持索引，CSV可以在数据库运行时拷贝或者拷出文件，可以将Excel等电子表格中的数据存储未CSV文件，然后复制到MySQL中，就能在MySQL中打开使用。同样，如果将数据写入到一个CSV引擎表，其他外部程序也可以从表的数据文件中读取CSV的数据。因此CSV可以作为数据交换机制。非常好用。</li>
</ul>
<h5 id="federated">Federated</h5>
<ul>
<li>Federated引擎是访问其他MySQL服务器的一个代理，它会创建一个到远程MySQL服务器的客户端连接，并将查询传输到远程服务器执行，然后提取或者发送需要的数据。最初设计该存储引擎是为了和企业级数据库如MicrosoftSQLServer和Oracle的类似特性竞争的，可以说更多的是一种市场行为。尽管该引擎看起来提供了一种很好的跨服务器的灵活性，但也经常带来问题，因此默认是禁用的。</li>
</ul>
<h5 id="memroy">Memroy</h5>
<ul>
<li>如果需要快速地访问数据，并且这些数据不会被修改，重启以后丢失也没有关系，那么使用Memory表（以前也叫做HEAP表）是非常有用的。Memory表至少比MyISAM表要快一个数量级，因为所有的数据都保存在内存中，不需要进行磁盘I/O。Memory表的结构在重启以后还会保留，但数据会丢失。</li>
</ul>
<table>
<thead>
<tr>
<th>对比项</th>
<th>MyISAM</th>
<th>InnoDB</th>
</tr>
</thead>
<tbody>
<tr>
<td>主外键</td>
<td>不支持</td>
<td>支持</td>
</tr>
<tr>
<td>事务</td>
<td>不支持</td>
<td>支持</td>
</tr>
<tr>
<td>行表锁</td>
<td>表锁，即使操作一条记录会锁住整个表，不适合高并发的操作</td>
<td>行锁，操作时只锁某一行，不对其他行有影响，适合高并发的操作</td>
</tr>
<tr>
<td>缓存</td>
<td>只缓存索引，不缓存真实数据</td>
<td>不仅缓存索引还缓存真实数据，对内存要求较高，并且存储大小对性能有决定性的影响</td>
</tr>
<tr>
<td>表空间</td>
<td>小</td>
<td>大</td>
</tr>
<tr>
<td>关注点</td>
<td>性能</td>
<td>事务</td>
</tr>
</tbody>
</table>
<p>了解更多见：<a href="https://juejin.im/post/5c3ef9e051882525dc62de87">MySQL逻辑架构及性能优化原理</a></p>
<h2 id="mysql索引">MYSQL索引</h2>
<h3 id="索引介绍">索引介绍</h3>
<h4 id="什么是索引">什么是索引</h4>
<ul>
<li>在MYSQL官方介绍中说，索引（index）是帮助MYSQL高效获取数据的数据结构。所以可以理解为排好序便于快速查找的数据结构。</li>
<li>在数据之外，数据库系统还维护着满足特定查找算法的数据结构，这些数据结构以某种方式引用（指向）数据，这样就可以在这些数据结构上实现高级查找算法。这种数据结构，就是索引。</li>
<li>一般来说索引本身也很大，不可能全部存储在内存中，因此索引往往以索引文件的形式存储的磁盘上。</li>
</ul>
<h4 id="索引的优势和劣势">索引的优势和劣势</h4>
<h5 id="优势">优势</h5>
<ul>
<li>类似大学图书馆建书目索引，提高数据检索的效率，降低数据库的IO成本</li>
<li>通过索引列对数据进行排序，降低数据排序的成本，降低了CPU的消耗</li>
</ul>
<h5 id="劣势">劣势</h5>
<ul>
<li>虽然索引大大提高了查询速度，同时却会降低更新表的速度，如对表进行INSERT、UPDATE和DELETE。<br>
因为更新表时，MySQL不仅要保存数据，还要保存一下索引文件每次更新添加了索引列的字段，<br>
都会调整因为更新所带来的键值变化后的索引信息</li>
<li>实际上索引也是一张表，该表保存了主键与索引字段，并指向实体表的记录，所以索引列也是要占用空间的</li>
</ul>
<h4 id="mysql索引使用的数据结构">MYSQL索引使用的数据结构</h4>
<h5 id="聚簇索引与非聚簇索引">聚簇索引与非聚簇索引</h5>
<ul>
<li>聚簇索引：将数据存储与索引放到了一块，索引结构的叶子节点保存了行数据</li>
<li>非聚簇索引：将数据与索引分开存储，索引结构的叶子节点指向了数据对应的位置<br>
<img src="https://EastBeforeDawn.github.io/post-images/1591888086458.jpeg" alt="" loading="lazy"></li>
</ul>
<blockquote>
<p>在innodb中，在聚簇索引之上创建的索引称之为辅助索引，非聚簇索引都是辅助索引，像复合索引、前缀索引、唯一索引。辅助索引叶子节点存储的不再是行的物理位置，而是主键值，辅助索引访问数据总是需要二次查找。<br>
InnoDB使用的是聚簇索引，将主键组织到一棵B+树中，而行数据就储存在叶子节点上，若使用&quot;where id = 14&quot;这样的条件查找主键，则按照B+树的检索算法即可查找到对应的叶节点，之后获得行数据。<br>
若对Name列进行条件搜索，则需要两个步骤：第一步在辅助索引B+树中检索Name，到达其叶子节点获取对应的主键。第二步使用主键在主索引B+树种再执行一次B+树检索操作，最终到达叶子节点即可获取整行数据。（重点在于通过其他键需要建立辅助索引）</p>
</blockquote>
<ul>
<li>
<p><strong>聚簇索引具有唯一性</strong> 由于聚簇索引是将数据跟索引结构放到一块，因此一个表仅有一个聚簇索引。</p>
</li>
<li>
<p><strong>表中行的物理顺序和索引中行的物理顺序是相同的，在创建任何非聚簇索引之前创建聚簇索引</strong> 这是因为聚簇索引改变了表中行的物理顺序，数据行 按照一定的顺序排列，并且自动维护这个顺序；</p>
</li>
<li>
<p><strong>聚簇索引默认是主键</strong>  如果表中没有定义主键，InnoDB 会选择一个唯一且非空的索引代替。如果没有这样的索引，InnoDB 会隐式定义一个主键（类似oracle中的RowId）来作为聚簇索引。如果已经设置了主键为聚簇索引又希望再单独设置聚簇索引，必须先删除主键，然后添加我们想要的聚簇索引，最后恢复设置主键即可。</p>
</li>
<li>
<p><strong>使用聚簇索引的优势</strong> :每次使用辅助索引检索都要经过两次B+树查找，看上去聚簇索引的效率明显要低于非聚簇索引，这不是多此一举吗？聚簇索引的优势在哪？</p>
<ul>
<li>由于行数据和聚簇索引的叶子节点存储在一起，同一页中会有多条行数据，访问同一数据页不同行记录时，已经把页加载到了Buffer中（缓存器），再次访问时，会在内存中完成访问，不必访问磁盘。这样主键和行数据是一起被载入内存的，找到叶子节点就可以立刻将行数据返回了，如果按照主键Id来组织数据，获得数据更快。</li>
<li><code>辅助索引的叶子节点，存储主键值，而不是数据的存放地址</code>。好处是当行数据放生变化时，索引树的节点也需要分裂变化；或者是我们需要查找的数据，在上一次IO读写的缓存中没有，需要发生一次新的IO操作时，可以避免对辅助索引的维护工作，只需要维护聚簇索引树就好了。另一个好处是，因为辅助索引存放的是主键值，减少了辅助索引占用的存储空间大小。
<ul>
<li>注：我们知道一次io读写，可以获取到16K大小的资源，我们称之为读取到的数据区域为Page。而我们的B树，B+树的索引结构，叶子节点上存放好多个关键字（索引值）和对应的数据，都会在一次IO操作中被读取到缓存中，所以在访问同一个页中的不同记录时，会在内存里操作，而不用再次进行IO操作了。除非发生了页的分裂，即要查询的行数据不在上次IO操作的换村里，才会触发新的IO操作。</li>
</ul>
</li>
</ul>
</li>
<li>
<p><code>聚簇索引需要注意的地方</code></p>
<ul>
<li>
<p>当使用主键为聚簇索引时，主键最好不要使用uuid，因为uuid的值太过离散，不适合排序且可能出线新增加记录的uuid，会插入在索引树中间的位置，导致索引树调整复杂度变大，消耗更多的时间和资源。</p>
</li>
<li>
<p>建议使用int类型的自增，方便排序并且默认会在索引树的末尾增加主键值，对索引树的结构影响最小。而且，主键值占用的存储空间越大，辅助索引中保存的主键值也会跟着变大，占用存储空间，也会影响到IO操作读取到的数据量。</p>
<ul>
<li>聚簇索引的数据的物理存放顺序与索引顺序是一致的，即：只要索引是相邻的，那么对应的数据一定也是相邻地存放在磁盘上的。如果主键不是自增id，那么可以想 象，它会干些什么，不断地调整数据的物理地址、分页，当然也有其他一些措施来减少这些操作，但却无法彻底避免。但，如果是自增的，那就简单了，它只需要一 页一页地写，索引结构相对紧凑，磁盘碎片少，效率也高。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h5 id="b-tree和btree的选择">B-Tree和B+Tree的选择</h5>
<ul>
<li>B-Tree特点
<ul>
<li>所有键值分布在整个树中</li>
<li>任何关键字出现且只出现在一个节点中</li>
<li>搜索有可能在非叶子节点结束</li>
<li>在关键字全集内做一次查找，性能逼近二分查找算法<br>
<img src="https://EastBeforeDawn.github.io/post-images/1591888098099.jpeg" alt="" loading="lazy"></li>
</ul>
</li>
<li>B+Tree特点
<ul>
<li>所有关键字存储在叶子节点，非叶子节点不存储真正的data</li>
<li>为所有叶子节点增加了一个链指针<br>
<img src="https://EastBeforeDawn.github.io/post-images/1591888107532.jpeg" alt="" loading="lazy"></li>
</ul>
</li>
</ul>
<h5 id="为什么不用红黑树平衡二叉树">为什么不用红黑树/平衡二叉树</h5>
<ul>
<li>红黑树等结构也可以用来实现索引，但是文件系统及数据库系统普遍使用B/B+树结构来实现索引。mysql是基于磁盘的数据库，索引是以索引文件的形式存在于磁盘中的，索引的查找过程就会涉及到磁盘IO消耗，磁盘IO的消耗相比较于内存IO的消耗要高好几个数量级，所以索引的组织结构要设计得在查找关键字时要尽量减少磁盘IO的次数。使用B/B+树，跟磁盘的存储原理有关。</li>
<li>B-Tree借助计算机磁盘预读的机制，每次新建节点时，直接申请一个页的空间，这样就保证一个节点物理上也存储在一个页里，加之计算机存储分配都是按页对齐的，就实现了一个结点只需一次I/O。<br>
假设 B-Tree 的高度为 h,B-Tree中一次检索最多需要h-1次I/O（根节点常驻内存），渐进复杂度为O(h)=O(logdN)O(h)=O(logdN)。一般实际应用中，出度d是非常大的数字，通常超过100，因此h非常小（通常不超过3，也即索引的B+树层次一般不超过三层，所以查找效率很高）。<br>
而红黑树这种结构，h明显要深的多。由于逻辑上很近的节点（父子）物理上可能很远，无法利用局部性，所以红黑树的I/O渐进复杂度也为O(h)，效率明显比B-Tree差很多。</li>
<li>局部性原理与磁盘预读
<ul>
<li>为了提升效率，要尽量减少磁盘IO的次数。实际过程中，磁盘并不是每次严格按需读取，而是每次都会预读。磁盘读取完需要的数据后，会按顺序再多读一部分数据到内存中，这样做的理论依据是计算机科学中注明的局部性原理：<code>当一个数据被用到时，其附近的数据也通常会马上被使用，程序运行期间所需要的数据通常比较集中</code>
<ul>
<li>由于磁盘顺序读取的效率很高(不需要寻道时间，只需很少的旋转时间)，因此对于具有局部性的程序来说，预读可以提高I/O效率.预读的长度一般为页(page)的整倍数。</li>
<li>MySQL(默认使用InnoDB引擎),将记录按照页的方式进行管理,每页大小默认为16K(这个值可以修改)。linux 默认页大小为4K。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h5 id="为什么mysql的索引使用b树而不是b树">为什么mysql的索引使用B+树而不是B树</h5>
<ul>
<li>B+树更适合外部存储(一般指磁盘存储),由于内节点(非叶子节点)不存储data，所以一个节点可以存储更多的内节点，每个节点能索引的范围更大更精确。也就是说使用B+树单次磁盘IO的信息量相比较B树更大，IO效率更高。</li>
<li>mysql是关系型数据库，经常会按照区间来访问某个索引列，B+树的叶子节点间按顺序建立了链指针，加强了区间访问性，所以B+树对索引列上的区间范围查询很友好。而B树每个节点的key和data在一起，无法进行区间查找。</li>
</ul>
<h4 id="mysql索引分类">MYSQL索引分类</h4>
<h5 id="单值索引-即一个索引只包含单个列一个表可以有多个单列索引">单值索引 ：即一个索引只包含单个列，一个表可以有多个单列索引</h5>
<ul>
<li>创建表时建索引：CREATE TABLE customer (id INT(10) UNSIGNED  AUTO_INCREMENT ,customer_no VARCHAR(200),customer_name VARCHAR(200),  PRIMARY KEY(id),  KEY (customer_name));</li>
<li>单独建单值索引：CREATE  INDEX idx_customer_name ON customer(customer_name);</li>
<li>删除索引：DROP INDEX idx_customer_name  on customer;</li>
</ul>
<h5 id="唯一索引索引列的值必须唯一但允许有空值">唯一索引：索引列的值必须唯一，但允许有空值</h5>
<ul>
<li>随表一起建索引：CREATE TABLE customer (id INT(10) UNSIGNED  AUTO_INCREMENT ,customer_no VARCHAR(200),customer_name VARCHAR(200),  PRIMARY KEY(id),  KEY (customer_name),  UNIQUE (customer_no));</li>
<li>单独建唯一索引：CREATE UNIQUE INDEX idx_customer_no ON customer(customer_no);</li>
<li>删除索引：DROP INDEX idx_customer_no on customer ;</li>
</ul>
<h5 id="主键索引设定为主键后数据库会自动建立索引innodb为聚簇索引">主键索引：设定为主键后数据库会自动建立索引，innodb为聚簇索引</h5>
<ul>
<li>随表一起建索引：CREATE TABLE customer (id INT(10) UNSIGNED  AUTO_INCREMENT ,customer_no VARCHAR(200),customer_name VARCHAR(200),  PRIMARY KEY(id) );   CREATE TABLE customer2 (id INT(10) UNSIGNED   ,customer_no VARCHAR(200),customer_name VARCHAR(200),  PRIMARY KEY(id) );</li>
<li>单独建主键索引：ALTER TABLE customer  add PRIMARY KEY customer(customer_no);</li>
<li>删除建主键索引：ALTER TABLE customer  drop PRIMARY KEY ;</li>
<li>修改建主键索引：必须先删除掉(drop)原索引，再新建(add)索引</li>
</ul>
<h5 id="复合索引即一个索引包含多个列">复合索引：即一个索引包含多个列</h5>
<ul>
<li>随表一起建索引：CREATE TABLE customer (id INT(10) UNSIGNED  AUTO_INCREMENT ,customer_no VARCHAR(200),customer_name VARCHAR(200),  PRIMARY KEY(id),  KEY (customer_name),  UNIQUE (customer_name),  KEY (customer_no,customer_name));</li>
<li>单独建索引：CREATE  INDEX idx_no_name ON customer(customer_no,customer_name);</li>
<li>删除索引：DROP INDEX idx_no_name  on customer ;</li>
</ul>
<h5 id="基本语法">基本语法</h5>
<ul>
<li>创建： CREATE  [UNIQUE ]  INDEX [indexName] ON table_name(column))</li>
<li>删除：DROP INDEX [indexName] ON mytable;</li>
<li>查看：SHOW INDEX FROM table_name\G</li>
<li>ALTER：有四种方式来添加数据表的索引
<ul>
<li>ALTER TABLE tbl_name ADD PRIMARY KEY (column_list): 该语句添加一个主键，这意味着索引值必须是唯一的，且不能为NULL。</li>
<li>ALTER TABLE tbl_name ADD UNIQUE index_name (column_list): 这条语句创建索引的值必须是唯一的（除了NULL外，NULL可能会出现多次）。</li>
<li>ALTER TABLE tbl_name ADD INDEX index_name (column_list): 添加普通索引，索引值可出现多次。</li>
<li>ALTER TABLE tbl_name ADD FULLTEXT index_name (column_list):该语句指定了索引为 FULLTEXT ，用于全文索引。</li>
</ul>
</li>
</ul>
<h4 id="mysql是否应该建立索引的情况">MYSQL是否应该建立索引的情况</h4>
<h5 id="需要创建索引">需要创建索引</h5>
<ul>
<li>主键自动建立唯一索引</li>
<li>频繁作为查询条件的字段应该创建索引</li>
<li>查询中与其它表关联的字段，外键关系建立索引</li>
<li>单键/组合索引的选择问题， 组合索引性价比更高</li>
<li>查询中排序的字段，排序字段若通过索引去访问将大大提高排序速度</li>
<li>查询中统计或者分组字段</li>
</ul>
<h5 id="不需要创建索引">不需要创建索引</h5>
<ul>
<li>表记录太少</li>
<li>经常增删改的表或者字段
<ul>
<li>索引提高了查询速度，同时却会降低更新表的速度，如对表进行INSERT、UPDATE和DELETE。<br>
因为更新表时，MySQL不仅要保存数据，还要保存一下索引文件</li>
</ul>
</li>
<li>Where条件里用不到的字段不创建索引</li>
<li>过滤性不好的不适合建索引
<ul>
<li>比如性别字段就不适合做索引</li>
</ul>
</li>
</ul>
<h2 id="mysql索引与性能分析">MYSQL索引与性能分析</h2>
<h3 id="explain执行计划">EXPLAIN（执行计划）</h3>
<blockquote>
<p>使用EXPLAIN关键字可以模拟优化器执行SQL查询语句，从而知道MySQL是<br>
如何处理你的SQL语句的。分析你的查询语句或是表结构的性能瓶颈</p>
</blockquote>
<h4 id="explain-可以查到">EXPLAIN 可以查到</h4>
<ul>
<li>表的读取顺序</li>
<li>哪些索引可以使用</li>
<li>数据读取操作的操作类型</li>
<li><code>哪些索引被实际使用</code></li>
<li>表之间的引用</li>
<li><code>每张表有多少行被物理查询</code></li>
</ul>
<h4 id="使用-explain-sql">使用 ： EXPLAIN + SQL</h4>
<pre><code class="language-tex">+----+-------------+-------+------------+-------+---------------+---------+---------+-------+------+----------+-------+
| id | select_type | table | partitions | type  | possible_keys | key     | key_len | ref   | rows | filtered | Extra |
+----+-------------+-------+------------+-------+---------------+---------+---------+-------+------+----------+-------+
</code></pre>
<h3 id="explain字段解释"><code>EXPLAIN字段解释</code></h3>
<h4 id="id">id</h4>
<blockquote>
<p>select查询的序列号,包含一组数字，表示查询中执行select子句或操作表的顺序</p>
</blockquote>
<h5 id="三种情况">三种情况</h5>
<ul>
<li>id相同，执行顺序由上至下</li>
<li>id不同，如果是子查询，id的序号会递增，id值越大优先级越高，越先被执行</li>
<li>id相同不同，同时存在。id如果相同，可以认为是一组，从上往下顺序执行；在所有组中，id值越大，优先级越高，越先执行 衍生表 = DERIVED</li>
</ul>
<h5 id="关注点">关注点</h5>
<ul>
<li>id号每个号码，表示一趟独立的查询。一个sql 的查询趟数越少越好。</li>
</ul>
<h4 id="select_type">select_type</h4>
<blockquote>
<p>查询的类型，主要是用于区别普通查询、联合查询、子查询等的复杂查询</p>
</blockquote>
<h5 id="simple">SIMPLE</h5>
<ul>
<li>简单的 select 查询,查询中不包含子查询或者UNION</li>
</ul>
<h5 id="primary">PRIMARY</h5>
<ul>
<li>查询中若包含任何复杂的子部分，最外层查询则被标记为Primary</li>
</ul>
<h5 id="derived">DERIVED</h5>
<ul>
<li>在FROM列表中包含的子查询被标记为DERIVED(衍生)，MySQL会递归执行这些子查询, 把结果放在临时表里。</li>
</ul>
<h5 id="subquery">SUBQUERY</h5>
<ul>
<li>在SELECT或WHERE列表中包含了子查询</li>
</ul>
<h5 id="dependent-subquery">DEPENDENT SUBQUERY</h5>
<ul>
<li>在SELECT或WHERE列表中包含了子查询,子查询基于外层</li>
</ul>
<h5 id="uncacheable-subqurey">UNCACHEABLE SUBQUREY</h5>
<h5 id="union">UNION</h5>
<ul>
<li>若第二个SELECT出现在UNION之后，则被标记为UNION；</li>
<li>若UNION包含在FROM子句的子查询中,外层SELECT将被标记为：DERIVED</li>
</ul>
<h5 id="union-result">UNION RESULT</h5>
<ul>
<li>从UNION表获取结果的SELECT</li>
</ul>
<h4 id="table">table</h4>
<blockquote>
<p>显示这一行的数据是关于哪张表的</p>
</blockquote>
<h4 id="partitions">partitions</h4>
<blockquote>
<p>代表分区表中的命中情况，非分区表，该项为null</p>
</blockquote>
<h4 id="type">type</h4>
<blockquote>
<p>type显示的是访问类型，是较为重要的一个指标，结果值由好到坏一般为system &gt; const &gt; eq_ref &gt; ref &gt; range &gt; index &gt; ALL。一般来说，得保证查询至少达到range级别，最好能达到ref。</p>
</blockquote>
<h5 id="system">system</h5>
<ul>
<li>表只有一行记录（等于系统表），这是const类型的特列，平时不会出现，这个也可以忽略不计</li>
</ul>
<h5 id="const">const</h5>
<ul>
<li>表示通过索引一次就找到了,const用于比较primary key或者unique索引。因为只匹配一行数据，所以很快<br>
如将主键置于where列表中，MySQL就能将该查询转换为一个常量</li>
</ul>
<h5 id="eq_ref">eq_ref</h5>
<ul>
<li>唯一性索引扫描，对于每个索引键，表中只有一条记录与之匹配。常见于主键或唯一索引扫描</li>
</ul>
<h5 id="ref">ref</h5>
<ul>
<li>非唯一性索引扫描，返回匹配某个单独值的所有行.本质上也是一种索引访问，它返回所有匹配某个单独值的行，然而，它可能会找到多个符合条件的行，所以他应该属于查找和扫描的混合体</li>
</ul>
<h5 id="range"><code>range</code></h5>
<ul>
<li>只检索给定范围的行,使用一个索引来选择行。key 列显示使用了哪个索引一般就是在你的where语句中出现了between、&lt;、&gt;、in等的查询，这种范围扫描索引扫描比全表扫描要好，因为它只需要开始于索引的某一点，而结束语另一点，不用扫描全部索引。</li>
</ul>
<h5 id="index"><code>index</code></h5>
<ul>
<li>Full index scan ，index与all的区别是index只遍历索引树。出现index是sql使用了索引但是没用通过索引进行过滤，一般是使用了覆盖索引或者是利用索引进行了排序分组</li>
</ul>
<h5 id="all最为致命的类型"><em><code>all</code></em>(最为致命的类型)</h5>
<ul>
<li>Full Table Scan，将遍历全表以找到匹配的行</li>
</ul>
<h5 id="index_merge">index_merge</h5>
<ul>
<li>在查询过程中需要多个索引组合使用，通常出现在有 or 的关键字的sql中</li>
</ul>
<h5 id="ref_or_null">ref_or_null</h5>
<ul>
<li>对于某个字段既需要关联条件，也需要null值得情况下。查询优化器会选择用ref_or_null连接查询。</li>
</ul>
<h5 id="index_subquery">index_subquery</h5>
<ul>
<li>利用索引来关联子查询，不再全表扫描。</li>
</ul>
<h5 id="unique_subquery">unique_subquery</h5>
<ul>
<li>该联接类型类似于index_subquery。 子查询中的唯一索引</li>
</ul>
<h5 id="备注一般来说得保证查询至少达到range级别最好能达到ref">备注：一般来说，得保证查询至少达到range级别，最好能达到ref。</h5>
<h4 id="possible_keys">possible_keys</h4>
<blockquote>
<p>显示可能应用在这张表中的索引，一个或多个。<br>
查询涉及到的字段上若存在索引，则该索引将被列出，但不一定被查询实际使用</p>
</blockquote>
<h4 id="key">key</h4>
<blockquote>
<p>实际使用的索引。如果为NULL，则没有使用索引, 查询中若使用了覆盖索引，则该索引和查询的select字段重叠</p>
</blockquote>
<h4 id="key_len">key_len</h4>
<blockquote>
<p>表示索引中使用的字节数，可通过该列计算查询中使用的索引的长度。 key_len字段能够帮你检查是否充分的利用上了索引<br>
如何计算长度：EXPLAIN SELECT SQL_NO_CACHE * FROM emp WHERE emp.age=30 AND emp.name LIKE 'ab%';</p>
</blockquote>
<ol>
<li>先看索引上字段的类型+长度比如 int=4 ;  varchar(20) =20 ; char(20) =20</li>
<li>如果是varchar或者char这种字符串字段，视字符集要乘不同的值，比如utf-8  要乘 3,GBK要乘2</li>
<li>varchar这种动态字符串要加2个字节</li>
<li>允许为空的字段要加1个字节<br>
<img src="./%E4%B8%8B%E8%BD%BD.png" alt="Alt text" loading="lazy"></li>
</ol>
<h4 id="ref-2">ref</h4>
<blockquote>
<p>显示索引的哪一列被使用了，如果可能的话，是一个常数。哪些列或常量被用于查找索引列上的值</p>
</blockquote>
<h4 id="rows">rows</h4>
<blockquote>
<p>rows列显示MySQL认为它执行查询时必须检查的行数。(<code>越少越好</code>)</p>
</blockquote>
<h4 id="filtered">filtered</h4>
<blockquote>
<p>这个字段表示存储引擎返回的数据在server层过滤后，剩下多少满足查询的记录数量的比例，注意是百分比，不是具体记录数</p>
</blockquote>
<h4 id="extra">Extra</h4>
<blockquote>
<p>包含不适合在其他列中显示但十分重要的额外信息</p>
</blockquote>
<h5 id="using-filesort"><code>Using filesort</code></h5>
<ul>
<li>说明mysql会对数据使用一个外部的索引排序，而不是按照表内的索引顺序进行读取。<br>
MySQL中无法利用索引完成的排序操作称为“文件排序”</li>
</ul>
<h5 id="using-temporary"><code>Using temporary</code></h5>
<ul>
<li>使了用临时表保存中间结果,MySQL在对查询结果排序时使用临时表。常见于排序 order by 和分组查询 group by。</li>
</ul>
<h5 id="using-index"><code>USING index</code></h5>
<ul>
<li>表示相应的select操作中使用了覆盖索引(Covering Index)，避免访问了表的数据行，效率不错！</li>
<li>如果同时出现using where，表明索引被用来执行索引键值的查找;</li>
<li>如果没有同时出现using where，表明索引只是用来读取数据而非利用索引执行查找。</li>
</ul>
<h5 id="using-where">Using where</h5>
<ul>
<li>表明使用了where过滤</li>
</ul>
<h5 id="using-join-buffer">using join buffer</h5>
<ul>
<li>使用了连接缓存：</li>
</ul>
<h5 id="impossible-where">impossible where</h5>
<ul>
<li>SQL错误，where子句的值总是false，不能用来获取任何元组</li>
</ul>
<h5 id="select-tables-optimized-away">select tables optimized away</h5>
<ul>
<li>在没有GROUPBY子句的情况下，基于索引优化MIN/MAX操作或者，对于MyISAM存储引擎优化COUNT(*)操作，不必等到执行阶段再进行计算，查询执行计划生成的阶段即完成优化。</li>
</ul>
<h3 id="查询优化策略"><code>查询优化策略</code></h3>
<h4 id="单表使用索引及常见索引失效">单表使用索引及常见索引失效</h4>
<ul>
<li>全值匹配</li>
<li><code>最佳左前缀法则</code>
<ul>
<li>如果索引了多列，要遵守最左前缀法则。指的是查询从索引的最左前列开始并且不跳过索引中的列。</li>
</ul>
</li>
<li>不在索引列上做任何操作（计算、函数、(自动or手动)类型转换），会导致索引失效而转向全表扫描</li>
<li>存储引擎不能使用索引中范围条件右边的列</li>
<li>mysql 在使用不等于(!= 或者&lt;&gt;)的时候无法使用索引会导致全表扫描</li>
<li>is not null 也无法使用索引,但是is null是可以使用索引的</li>
<li>like以通配符开头('%abc...')mysql索引失效会变成全表扫描的操作</li>
<li>字符串不加单引号索引失效</li>
</ul>
<h4 id="一般性建议">一般性建议</h4>
<ul>
<li>对于单键索引，尽量选择针对当前query过滤性更好的索引</li>
<li>在选择组合索引的时候，当前Query中过滤性最好的字段在索引字段顺序中，位置越靠前越好。</li>
<li>在选择组合索引的时候，尽量选择可以能够包含当前query中的where字句中更多字段的索引</li>
<li>在选择组合索引的时候，如果某个字段可能出现范围查询时，尽量把这个字段放在索引次序的最后面</li>
<li>书写sql语句时，尽量避免造成索引失效的情况</li>
</ul>
<h4 id="关联查询优化">关联查询优化</h4>
<ul>
<li>保证被驱动表的join字段已经被索引</li>
<li>left join 时，选择小表作为驱动表，大表作为被驱动表。</li>
<li>inner join 时，mysql会自己帮你把小结果集的表选为驱动表。</li>
<li>子查询尽量不要放在被驱动表，有可能使用不到索引。</li>
<li>能够直接多表关联的尽量直接关联，不用子查询。</li>
</ul>
<h4 id="子查询优化">子查询优化</h4>
<ul>
<li>尽量不要使用not in  或者 not exists， 用left outer join  on  xxx is null 替代</li>
</ul>
<h4 id="分组查询优化">分组查询优化</h4>
<ul>
<li>ORDER BY子句，尽量使用Index方式排序,避免使用FileSort方式排序</li>
</ul>
<h5 id="无法避免filesort的情况">无法避免FileSort的情况</h5>
<ul>
<li>双路排序</li>
<li>MySQL 4.1之前是使用双路排序,字面意思就是两次扫描磁盘，最终得到数据，读取行指针和orderby列，对他们进行排序，然后扫描已经排序好的列表，按照列表中的值重新从列表中读取对应的数据输出</li>
<li>从磁盘取排序字段，在buffer进行排序，再从磁盘取其他字段。</li>
<li>取一批数据，要对磁盘进行了两次扫描，众所周知，I\O是很耗时的，所以在mysql4.1之后，出现了第二种改进的算法，就是单路排序。</li>
<li>单路排序
<ul>
<li>从磁盘读取查询需要的所有列，按照order by列在buffer对它们进行排序，然后扫描排序后的列表进行输出，它的效率更快一些，避免了第二次读取数据。并且把随机IO变成了顺序IO,但是它会使用更多的空间，<br>
因为它把每一行都保存在内存中了。</li>
</ul>
</li>
</ul>
<h5 id="单路排序的问题">单路排序的问题</h5>
<blockquote>
<p>由于单路是后出的，总体而言好过双路。但是在sort_buffer中，方法B比方法A要多占用很多空间，因为方法B是把所有字段都取出, 所以有可能取出的数据的总大小超出了sort_buffer的容量，导致每次只能取sort_buffer容量大小的数据，进行排序（创建tmp文件，多路合并），排完再取取sort_buffer容量大小，再排……从而多次I/O。本来想省一次I/O操作，反而导致了大量的I/O操作，反而得不偿失。</p>
</blockquote>
<h5 id="单路排序优化策略">单路排序优化策略</h5>
<ul>
<li>增大sort_buffer_size参数的设置</li>
<li>增大max_length_for_sort_data参数的设置</li>
<li>减少select 后面的查询的字段。</li>
</ul>
<h5 id="策略分析">策略分析</h5>
<ul>
<li>Order by时select * 是一个大忌只Query需要的字段， 这点非常重要。在这里的影响是</li>
<li>当Query的字段大小总和小于max_length_for_sort_data 而且排序字段不是 TEXT|BLOB 类型时，会用改进后的算法——单路排序， 否则用老算法——多路排序。</li>
<li>两种算法的数据都有可能超出sort_buffer的容量，超出之后，会创建tmp文件进行合并排序，导致多次I/O，但是用单路排序算法的风险会更大一些,所以要提高sort_buffer_size。</li>
<li>尝试提高 sort_buffer_size :不管用哪种算法，提高这个参数都会提高效率，当然，要根据系统的能力去提高，因为这个参数是针对每个进程的  1M-8M之间调整</li>
<li>尝试提高 max_length_for_sort_data: 提高这个参数， 会增加用改进算法的概率。但是如果设的太高，数据总容量超出sort_buffer_size的概率就增大，明显症状是高的磁盘I/O活动和低的处理器使用率.  (1024-8192之间调整 )</li>
</ul>
<h4 id="group-by关键字优化">GROUP BY关键字优化</h4>
<blockquote>
<p>group by 使用索引的原则几乎跟order by一致 ，唯一区别是groupby 即使没有过滤条件用到索引，也可以直接使用索引。</p>
</blockquote>
<h4 id="最后使用索引的手段覆盖索引">最后使用索引的手段：覆盖索引</h4>
<blockquote>
<p>什么是覆盖索引？简单说就是，select 到 from 之间查询的列 &lt;=使用的索引列+主键  explain select * from emp where name like '%abc';   使用覆盖索引后</p>
</blockquote>
<h2 id="查询截取分析">查询截取分析</h2>
<blockquote>
<p>MySQL的慢查询日志是MySQL提供的一种日志记录，它用来记录在MySQL中响应时间超过阀值的语句，具体指运行时间超过long_query_time值的SQL，则会被记录到慢查询日志中。 具体指运行时间超过long_query_time值的SQL，则会被记录到慢查询日志中。long_query_time的默认值为10，意思是运行10秒以上的语句。 由他来查看哪些SQL超出了我们的最大忍耐时间值，比如一条sql执行超过5秒钟，我们就算慢SQL，希望能收集超过5秒的sql，结合之前explain进行全面分析。</p>
</blockquote>
<h3 id="慢查询说明">慢查询说明</h3>
<blockquote>
<p>默认情况下，MySQL数据库没有开启慢查询日志，需要我们手动来设置这个参数。当然，如果不是调优需要的话，一般不建议启动该参数，因为开启慢查询日志会或多或少带来一定的性能影响。慢查询日志支持将日志记录写入文件<br>
那么开启了慢查询日志后，什么样的SQL才会记录到慢查询日志里面呢？这个是由参数long_query_time控制，默认情况下long_query_time的值为10秒，命令：SHOW VARIABLES LIKE 'long_query_time%';可以使用命令修改，也可以在my.cnf参数里面修改。假如运行时间正好等于long_query_time的情况，并不会被记录下来。也就是说，在mysql源码里是判断大于long_query_time，而非大于等于。</p>
</blockquote>
<h4 id="查询是否开启以及配置参数">查询是否开启以及配置参数</h4>
<ul>
<li>SHOW VARIABLES LIKE '%slow_query_log%';</li>
<li>SHOW VARIABLES LIKE 'long_query_time%';</li>
</ul>
<h4 id="开启以及配置参数">开启以及配置参数</h4>
<h5 id="命令方式">命令方式</h5>
<ul>
<li>set global slow_query_log=1; //开启慢查询日志</li>
<li>set  long_query_time=1   // 设置慢查询记录时间的阈值</li>
</ul>
<h5 id="配置文件方式-mycnf">配置文件方式  my.cnf</h5>
<pre><code>【mysqld】
slow_query_log=1
slow_query_log_file=/var/lib/mysql/atguigu-slow.log
long_query_time=3
log_output=FILE
</code></pre>
<h3 id="日志分析工具mysqldumpslow">日志分析工具mysqldumpslow</h3>
<h4 id="查看mysqldumpslow的帮助信息">查看mysqldumpslow的帮助信息</h4>
<ul>
<li><code>-a: 不将数字抽象成N，字符串抽象成S</code></li>
<li><code>-s: 是表示按照何种方式排序</code>
<ul>
<li>c: 访问次数</li>
<li>l: 锁定时间</li>
<li>r: 返回记录</li>
<li>t: 查询时间</li>
<li>al:平均锁定时间</li>
<li>ar:平均返回记录数</li>
<li>at:平均查询时间</li>
</ul>
</li>
<li><code>-t:即为返回前面多少条的数据</code></li>
<li><code>-g:后边搭配一个正则匹配模式，大小写不敏感的</code></li>
</ul>
<h4 id="工作常用参考">工作常用参考</h4>
<ul>
<li>得到返回记录集最多的10个SQL
<ul>
<li>mysqldumpslow -s r -t 10 /var/lib/mysql/atguigu-slow.log</li>
</ul>
</li>
<li>得到访问次数最多的10个SQL
<ul>
<li>mysqldumpslow -s c -t 10 /var/lib/mysql/atguigu-slow.log</li>
</ul>
</li>
<li>得到按照时间排序的前10条里面含有左连接的查询语句
<ul>
<li>mysqldumpslow -s t -t 10 -g &quot;left join&quot; /var/lib/mysql/atguigu-slow.log</li>
</ul>
</li>
<li>另外建议在使用这些命令时结合 | 和more 使用 ，否则有可能出现爆屏情况
<ul>
<li>mysqldumpslow -s r -t 10 /var/lib/mysql/atguigu-slow.log | more</li>
</ul>
</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Redis]]></title>
        <id>https://EastBeforeDawn.github.io/post/redis/</id>
        <link href="https://EastBeforeDawn.github.io/post/redis/">
        </link>
        <updated>2020-06-11T14:55:42.000Z</updated>
        <content type="html"><![CDATA[<blockquote>
<p>redis是一个基于C语言编写的基本内存又可以持久化的Key-Value数据库。支持的数据类型有String，List，Set，SortedSet，Hash。</p>
</blockquote>
<h2 id="基本理论">基本理论</h2>
<ol>
<li>传统数据库的ACID理论</li>
</ol>
<ul>
<li>A(atomicty)原子性</li>
</ul>
<blockquote>
<p>一个事务（transaction）中的所有操作，或者全部完成，或者全部不完成，不会结束在中间某个环节。事务在执行过程中发生错误，会被回滚（Rollback）到事务开始前的状态，就像这个事务从来没有执行过一样。即，事务不可分割、不可约简。</p>
</blockquote>
<ul>
<li>C(consistency)一致性</li>
</ul>
<blockquote>
<p>在事务开始之前和事务结束以后，数据库的完整性没有被破坏。这表示写入的资料必须完全符合所有的预设约束、触发器、级联回滚等。</p>
</blockquote>
<ul>
<li>I(isolation)隔离性</li>
</ul>
<blockquote>
<p>数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。事务隔离分为不同级别，包括未提交读（Read uncommitted）、提交读（read committed）、可重复读（repeatable read）和串行化（Serializable）。</p>
</blockquote>
<ul>
<li>D(durabliity)持久性</li>
</ul>
<blockquote>
<p>事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。</p>
</blockquote>
<ol start="2">
<li>分布式系统的CAP理论</li>
</ol>
<ul>
<li>C(consistency)一致性</li>
</ul>
<blockquote>
<p>一致性指“all nodes see the same data at the same time”，即所有节点在同一时间的数据完全一致。<br>
一致性是因为多个数据拷贝下并发读写才有的问题，因此理解时一定要注意结合考虑多个数据拷贝下并发读写的场景。<br>
对于一致性，可以分为从客户端和服务端两个不同的视角。<br>
客户端<br>
从客户端来看，一致性主要指的是多并发访问时更新过的数据如何获取的问题。<br>
服务端<br>
从服务端来看，则是更新如何分布到整个系统，以保证数据最终一致。<br>
对于一致性，可以分为强/弱/最终一致性三类<br>
从客户端角度，多进程并发访问时，更新过的数据在不同进程如何获取的不同策略，决定了不同的一致性。<br>
强一致性<br>
对于关系型数据库，要求更新过的数据能被后续的访问都能看到，这是强一致性。<br>
弱一致性<br>
如果能容忍后续的部分或者全部访问不到，则是弱一致性。<br>
最终一致性<br>
如果经过一段时间后要求能访问到更新后的数据，则是最终一致性。</p>
</blockquote>
<ul>
<li>A(availability)可用性</li>
</ul>
<blockquote>
<p>可用性指“Reads and writes always succeed”，即服务在正常响应时间内一直可用。<br>
好的可用性主要是指系统能够很好的为用户服务，不出现用户操作失败或者访问超时等用户体验不好的情况。可用性通常情况下可用性和分布式数据冗余，负载均衡等有着很大的关联。</p>
</blockquote>
<ul>
<li>P(partition tolerance)分区容错性</li>
</ul>
<blockquote>
<p>分区容错性指“the system continues to operate despite arbitrary message loss or failure of part of the system”，即分布式系统在遇到某节点或网络分区故障的时候，仍然能够对外提供满足一致性或可用性的服务。</p>
</blockquote>
<p>在分布式系统中（集群环境）P分区容错性是我们必须要满足的，满足P的情况下C和A是相互冲突的，如果满足一致性即保证客户端在高并发下读取数据的一致那么必然需要服务端协调每一个节点，这就有了数据同步问题，其他客户端访问要等带服务端同步完成，不能保证高可用性。<br>
3. BASE理论</p>
<blockquote>
<p>BASE理论是对CAP理论的延伸，核心思想是即使无法做到强一致性（Strong Consistency，CAP的一致性就是强一致性），但应用可以采用适合的方式达到最终一致性（Eventual Consitency）。</p>
</blockquote>
<ul>
<li>基本可用（Basically Available）<br>
基本可用是指分布式系统在出现故障的时候，允许损失部分可用性，即保证核心可用。<br>
电商大促时，为了应对访问量激增，部分用户可能会被引导到降级页面，服务层也可能只提供降级服务。这就是损失部分可用性的体现。</li>
<li>软状态（ Soft State）<br>
软状态是指允许系统存在中间状态，而该中间状态不会影响系统整体可用性。分布式存储中一般一份数据至少会有三个副本，允许不同节点间副本同步的延时就是软状态的体现。mysql replication的异步复制也是一种体现。</li>
<li>最终一致性（ Eventual Consistency）<br>
最终一致性是指系统中的所有数据副本经过一定时间后，最终能够达到一致的状态。弱一致性和强一致性相反，最终一致性是弱一致性的一种特殊情况。</li>
</ul>
<ol start="4">
<li>CAP理论3选2</li>
</ol>
<ul>
<li>CA CA表示是单机项目 主要有传统数据库的MYSQL(非集群)</li>
<li>CP CP在分布式系统中保证了一致性 主要有Redis,Zookepper</li>
</ul>
<h2 id="redis持久化">Redis持久化</h2>
<h3 id="rdbredis-database">RDB(Redis DataBase)</h3>
<blockquote>
<p>在指定的时间间隔内将内存中的数据集快照写入磁盘，也就是Snapshot快照，它恢复时将快照文件直接读到内存里。</p>
</blockquote>
<blockquote>
<p>Redis会单独创建（Fork）一个子进程来进行持久化，会先将数据写入到一个临时文件中，待持久化过程都结束了，再用这个临时文件替换上次持久化好的文件。                                                 整个过程中，主进程是不进行任何IO操作的，这就确保了极高的性能                                             如果需要进行大规模数据的恢复，且对于数据恢复的完整性不是非常敏感，那RDB方式要比AOF方式更加的高效。RDB的缺点是最后一次持久化后的数据可能丢失。</p>
</blockquote>
<blockquote>
<p>Fork的作用是复制一个与当前进程一样的进程。新进程的所有数据（变量、环境变量‘程序计数器等）数值都和原进程一致，但是是一个全新的进程，并作为原进程的子进程。</p>
</blockquote>
<blockquote>
<p>文件名默认为dump.rdb 默认的存储策略为1分钟10000次，5分钟10次，15分钟1次</p>
</blockquote>
<blockquote>
<p>当达到存储策略时自动触发，也可手动出发：使用save命令或者bgsave</p>
</blockquote>
<ul>
<li>Save：save时只管保存，其他不管，全部阻塞</li>
<li>BGSAVE：Redis会在后台异步进行快照操作，快照操作同时还可以响应客户端请求。可以通过lastsave命令获取最后一次成功执行快照的时间。</li>
</ul>
<h4 id="优势与劣势">优势与劣势</h4>
<blockquote>
<p>RDB的优势是适合大规模的数据并且对数据的完整行要求不高的情况。劣势是它是隔一段时间做一次备份如果redis意外挂掉会损失最后一次备份之后数据，RDB在备份时内存的数据被复制了一份，如果存储的数据较大对内存来说是一笔不小的开销。</p>
</blockquote>
<h3 id="aofappend-only-file">AOF(Append Only File)</h3>
<blockquote>
<p>以日志的形式来记录每个写操作，将Redis执行过的所有写指令记录下来（读操作不记录），只许追加文件但不可以改写文件，redis启动之初会读取该文件重新构建数据，换言之，redis重启的话根据日志文件的内容将写指令从前到后执行一次已完成数据的恢复工作。</p>
</blockquote>
<blockquote>
<p>默认文件名是appendonly.aof  AOF默认关闭</p>
</blockquote>
<h4 id="aof策略">AOF策略</h4>
<ul>
<li>always 同步持久化，每次发生数据变更会立即记录到磁盘，性能较差但数据完整性比较好</li>
<li>everysec 出厂默认推荐，异步操作，每秒记录，如果一秒内宕机，有数据丢失</li>
<li>no 不进行aof</li>
</ul>
<h4 id="重写rewrite">重写(rewrite)</h4>
<p>随着命令不断写入 AOF，文件会越来越大，导致文件占用空间变大，数据恢复时间变长。为了解决这个问题，Redis 引入了重写机制来对 AOF 文件中的写命令进行合并，进一步压缩文件体积。<br>
AOF 文件重写指的是把 Redis 进程内的数据转化为写命令，同步到新的 AOF 文件中，然后使用新的 AOF 文件覆盖旧的 AOF 文件，这个过程不对旧的 AOF 文件的进行任何读写操作。</p>
<h5 id="触发机制">触发机制</h5>
<p>AOF 重写过程提供了手动触发和自动触发两种机制：</p>
<ul>
<li>手动触发：直接调用 bgrewriteaof 命令，该命令的执行与 bgsave 有些类似，都是 fork 子进程进行具体的工作，且都只有在 fork 时会阻塞</li>
<li>自动触发：根据 auto-aof-rewrite-min-size 和 auto-aof-rewrite-percentage 配置项，以及 aof_current_size 和 aof_base_size 的状态确定触发时机
<ul>
<li>auto-aof-rewrite-min-size：执行 AOF 重写时，文件的最小体积，默认值为 64MB</li>
<li>auto-aof-rewrite-percentage：执行 AOF 重写时，当前 AOF 大小（aof_current_size）和上一次重写时 AOF 大小（aof_base_size）的比值</li>
</ul>
</li>
</ul>
<h5 id="重写流程">重写流程</h5>
<ol>
<li>客户端通过 bgrewriteaof 命令对 Redis 主进程发起 AOF 重写请求</li>
<li>当前不存在正在执行 bgsave/bgrewriteaof 的子进程时，Redis 主进程通过 fork 操作创建子进程，这个过程主进程是阻塞的。如果发现 bgrewriteaof 子进程直接返回；如果发现 bgsave 子进程则等 bgsave 执行完成后再执行 fork 操作</li>
<li>主进程的 fork 操作完成后，继续处理其他命令，把新的写命令同时追加到 aof_buf 和 aof_rewrite_buf 缓冲区中</li>
</ol>
<ul>
<li>在文件重写完成之前，主进程会继续把写命令追加到 aof_buf 缓冲区，根据 appendfsync 策略同步到旧的 AOF 文件，这样可以避免 AOF 重写失败造成数据丢失，保证原有的 AOF 文件的正确性</li>
<li>由于 fork 操作运用写时复制技术，子进程只能共享 fork 操作时的内存数据，主进程会把新命令追加到一个 aof_rewrite_buf 缓冲区中，避免 AOF 重写时丢失这部分数据</li>
<li>子进程读取 Redis 进程中的数据快照，生成写入命令并按照命令合并规则批量写入到新的 AOF 文件</li>
<li>子进程写完新的 AOF 文件后，向主进程发信号，主进程更新统计信息，具体可以通过 info persistence 查看</li>
<li>主进程接受到子进程的信号以后，将 aof_rewrite_buf 缓冲区中的写命令追加到新的 AOF 文件</li>
<li>主进程使用新的 AOF 文件替换旧的 AOF 文件，AOF 重写过程完成</li>
</ul>
<h5 id="压缩机制">压缩机制</h5>
<p>文件重写之所以能够压缩 AOF 文件的大小，原因在于以下几方面：</p>
<ul>
<li>过期的数据不再写入 AOF 文件</li>
<li>无效的命令不再写入 AOF 文件。比如：重复为数据设值（set mykey v1, set mykey v2）、删除键值对数据（sadd myset v1, del myset）等等</li>
<li>多条命令可以合并为单个。比如：sadd myset v1, sadd myset v2, sadd myset v3 可以合并为 sadd myset v1 v2 v3。不过为了防止单条命令过大造成客户端缓冲区溢出，对于 list、set、hash、zset 类型的 key，并不一定只使用单条命令，而是以某个 Redis 定义的一个常量为界，将命令拆分为多条</li>
</ul>
<h4 id="优势与劣势-2">优势与劣势</h4>
<h5 id="优势">优势</h5>
<ul>
<li>每修改同步：appendfsync always  同步持久化  每次发生数据变更会被立即记录到磁盘  性能较差但数据完整性比较好</li>
</ul>
<h5 id="劣势">劣势</h5>
<ul>
<li>同数据集的数据而言aof文件要远大于rdb文件，恢复速度慢于rdb。AOF运行效率要慢于rdb，每秒同步策略效率较好，不同步效率和rdb相同。</li>
</ul>
<h3 id="持久化策略选择">持久化策略选择</h3>
<h4 id="rdb-和-aof-性能开销">RDB 和 AOF 性能开销</h4>
<p>在介绍持久化策略之前，首先要明白无论是 RDB 还是 AOF 方式，开启持久化都是会造成性能开销的。</p>
<ul>
<li>RDB 持久化：
<ul>
<li>BGSAVE 命令在进行 fork 操作时，Redis 服务器主进程会发生阻塞</li>
<li>Redis 子进程向磁盘写入数据也会带来 IO 压力</li>
</ul>
</li>
<li>AOF 持久化：
<ul>
<li>向磁盘写入数据的频率大大提高，IO 压力更大，甚至可能造成 AOF 追加阻塞问题</li>
<li>AOF 文件重写与 RDB 的 BGSAVE 过程类似，存在父进程 fork 时的阻塞和子进程的 IO 压力问题</li>
</ul>
</li>
</ul>
<h4 id="持久化策略">持久化策略</h4>
<p>在实际生产环境中，根据数据量、应用对数据的安全要求、预算限制等不同情况，会有各种各样的持久化策略。</p>
<ul>
<li>完全不使用任何持久化功能</li>
<li>使用 RDB 或 AOF 其中一种</li>
<li>同时开启 RDB 和 AOF 持久化</li>
</ul>
<p>对于分布式环境，持久化的选择必须与 Redis 的主从策略一起考虑，因为主从复制与持久化同样具有数据备份的功能，而且主节点（Master Node）和从节点（Slave Node）可以独立选择持久化方案。<br>
下面分场景来讨论持久化策略的选择，下面的讨论也只是作为参考，实际方案可能更复杂更具多样性。</p>
<h5 id="数据库缓存">数据库缓存</h5>
<p>如果 Redis 中的数据完全丢弃也没有关系（如 Redis 完全用作 DB 层数据的缓存），那么无论是单机，还是主从架构，都可以不进行任何持久化。</p>
<h5 id="单机环境">单机环境</h5>
<p>在单机环境下，如果可以接受十几分钟或更多的数据丢失，RDB 方案对 Redis 的性能更加有利；如果只能接受秒级别的数据丢失，选择 AOF 方案更合适。</p>
<h5 id="主从部署">主从部署</h5>
<p>在多数情况下，Redis 都会配置主从部署机制。从节点（slave）既可以实现数据的热备，也可以进行读写分担 Redis 读请求，以及在主节点（master）宕机后的顶替作用。<br>
在这种情况下，一种可行的做法如下：</p>
<ul>
<li>master：完全关闭持久化（包括 RDB 和 AOF 功能），这样可以让主节点的性能达到最好</li>
<li>slave：关闭 RDB 功能，开启 AOF 功能（如果对数据安全要求不高，开启 RDB 关闭 AOF 也可以）。定时对持久化文件进行备份（如备份到其他文件夹，并标记好备份的时间）。然后关闭 AOF 的自动重写功能，然后添加定时任务，在每天 Redis 服务器闲时（如凌晨 12 点）调用 bgrewriteaof 手动重写。</li>
</ul>
<p>为什么开启了主从复制，可以实现数据的热备份，还需要设置持久化呢？因为在一些特殊情况下，主从复制仍然不足以保证数据的安全，例如：</p>
<ul>
<li>master 和 slave 同时停止：如果 master 节点和 slave 节点位于同一个机房，则一次停电事故就可能导致<br>
master 和 slave 机器同时关机，Redis 服务器进程停止。如果没有持久化，则面临的是数据的完全丢失。</li>
<li>master 重启：如果 master 节点因为故障宕机，并且系统中有自动拉起机制（即检测到服务停止后重启该服务）将 master 节点自动重启。</li>
</ul>
<p>由于没有持久化文件，那么 master 重启后数据是空的，slave 同步数据也变成了空的<br>
如果 master 和 slave 节点都没有开启持久化，同样会引发数据的完全丢失</p>
<h3 id="redis的过期策略和内存淘汰策略">Redis的过期策略和内存淘汰策略</h3>
<h4 id="redis的过期策略">Redis的过期策略</h4>
<blockquote>
<p>Redis是key-value数据库，我们可以设置Redis中缓存的key的过期时间。Redis的过期策略就是指当Redis中缓存的key过期了，Redis如何处理。</p>
</blockquote>
<ul>
<li>定时过期：每个设置过期时间的key都需要创建一个定时器，到过期时间就会立即清除。该策略可以立即清除过期的数据，对内存很友好；但是会占用大量的CPU资源去处理过期的数据，从而影响缓存的响应时间和吞吐量。</li>
<li>惰性过期：只有当访问一个key时，才会判断该key是否已过期，过期则清除。该策略可以最大化地节省CPU资源，却对内存非常不友好。极端情况可能出现大量的过期key没有再次被访问，从而不会被清除，占用大量内存。</li>
<li>定期过期：每隔一定的时间，会扫描一定数量的数据库的expires字典中一定数量的key，并清除其中已过期的key。该策略是前两者的一个折中方案。通过调整定时扫描的时间间隔和每次扫描的限定耗时，可以在不同情况下使得CPU和内存资源达到最优的平衡效果。<br>
(expires字典会保存所有设置了过期时间的key的过期时间数据，其中，key是指向键空间中的某个键的指针，value是该键的毫秒精度的UNIX时间戳表示的过期时间。键空间是指该Redis集群中保存的所有键。)</li>
</ul>
<p><code>Redis中同时使用了惰性过期和定期过期两种过期策略。</code></p>
<h4 id="redis的内存淘汰策略">Redis的内存淘汰策略</h4>
<blockquote>
<p>Redis的内存淘汰策略是指在Redis的用于缓存的内存不足时，怎么处理需要新写入且需要申请额外空间的数据。</p>
</blockquote>
<ul>
<li>noeviction：当内存不足以容纳新写入数据时，新写入操作会报错。</li>
<li>allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key。</li>
<li>allkeys-random：当内存不足以容纳新写入数据时，在键空间中，随机移除某个key。</li>
<li>volatile-lru：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的key。</li>
<li>volatile-random：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个key。</li>
<li>volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的key优先移除。</li>
</ul>
<p><code>Redis默认使用noeviction策略</code></p>
<p><strong>当使用volatile-lru、volatile-random、volatile-ttl这三种策略时，如果没有key可以被淘汰，则和noeviction一样返回错误</strong></p>
<h2 id="配置文件">配置文件</h2>
<h3 id="通用">通用</h3>
<table>
<thead>
<tr>
<th>英文</th>
<th>解释</th>
</tr>
</thead>
<tbody>
<tr>
<td>Daemonize</td>
<td>Redis默认不是以守护进程的方式运行，可以通过该配置项修改，使用yes启用守护进程</td>
</tr>
<tr>
<td>Pidfile</td>
<td>当Redis以守护进程方式运行时，Redis默认会把pid写入/var/run/redis.pid文件，可以通过pidfile指定</td>
</tr>
<tr>
<td>Port</td>
<td>指定Redis监听端口，默认端口为6379</td>
</tr>
<tr>
<td>Tcp-backlog</td>
<td>tcp-backing 551设置tcp的backlog，backlog其实是一个连接队列，backlog队列总和=未完成三次握手队列+已经完成三次握手队列。在高并发环境下你需要一个高backlog值来避免慢客户端连接问题。注意linux内核会将这个值减小到/proc/sys/net/core/somaxconn的值，所以需要确认增大somaxconn和tcp_max_syn_backing两个值来达到想要的效果。</td>
</tr>
<tr>
<td>Timeout</td>
<td>当客户端闲置多长时间后关闭连接，如果指定为0，表示关闭该功能</td>
</tr>
<tr>
<td>Bind</td>
<td>绑定的网络IP，如果不指定redis将会监听所有网络接口，建议绑定本地IP</td>
</tr>
<tr>
<td>Tcp-keepalive</td>
<td>当客户端闲置多长时间后关闭连接，如果指定为0，表示关闭该功能。</td>
</tr>
<tr>
<td>Loglevel</td>
<td>配置日志级别。选项有debug, verbose, notice, warning。级别越高，日志越少</td>
</tr>
<tr>
<td>Logfile</td>
<td>日志名称。空字符串表示标准输出。注意如果redis配置为后台进程，标准输出中信息会发送到/dev/null。</td>
</tr>
<tr>
<td>Syslog-enabled</td>
<td>是否把日志输出到syslog中</td>
</tr>
<tr>
<td>Syslog-ident</td>
<td>指定syslog里的日志标志</td>
</tr>
<tr>
<td>Databases</td>
<td>Redis数据库的数量 默认是为16</td>
</tr>
</tbody>
</table>
<h3 id="rdb">RDB</h3>
<table>
<thead>
<tr>
<th>英文</th>
<th>解释</th>
</tr>
</thead>
<tbody>
<tr>
<td>save m n</td>
<td>bgsave 自动触发的条件；如果没有 save m n 配置，相当于自动的 RDB 持久化关闭，不过此时仍可以通过其他方式触发。</td>
</tr>
<tr>
<td>stop-writes-on-bgsave-error</td>
<td>当 bgsave 出现错误时，Redis 是否停止执行写命令。如果设置为 yes，则当硬盘出现问题时，可以及时发现，避免数据的大量丢失；如果设置为 no，则 Redis 忽略 bgsave 的错误继续执行写命令，当对 Redis 服务器的系统（尤其是硬盘）使用了监控时，该选项考虑设置为 no。</td>
</tr>
<tr>
<td>rdbcompression</td>
<td>是否开启 RDB 文件压缩。</td>
</tr>
<tr>
<td>rdbchecksum</td>
<td>是否开启 RDB 文件的校验，在写入文件和读取文件时都起作用。关闭 checksum 在写入文件和启动文件时大约能带来 10% 的性能提升，但是数据损坏时无法发现。</td>
</tr>
<tr>
<td>dbfilename</td>
<td>dump.rdb 设置 RDB 的文件名。</td>
</tr>
<tr>
<td>dir ./</td>
<td>设置 RDB 文件和 AOF 文件所在目录。</td>
</tr>
</tbody>
</table>
<h3 id="aof">AOF</h3>
<table>
<thead>
<tr>
<th>英文</th>
<th>解释</th>
</tr>
</thead>
<tbody>
<tr>
<td>appendonly</td>
<td>是否开启 AOF 持久化功能</td>
</tr>
<tr>
<td>appendfilename</td>
<td>&quot;appendonly.aof&quot;：AOF 文件的名称</td>
</tr>
<tr>
<td>dir ./</td>
<td>RDB 文件和 AOF 文件所在目录</td>
</tr>
<tr>
<td>appendfsync</td>
<td>everysec：fsync 持久化策略</td>
</tr>
<tr>
<td>no-appendfsync-on-rewrite</td>
<td>重写 AOF 文件期间是否禁止 fsync 操作。如果开启该选项，可以减轻文件重写时 CPU 和磁盘的负载（尤其是磁盘），但是可能会丢失 AOF 重写期间的数据，需要在负载和安全性之间进行平衡</td>
</tr>
<tr>
<td>auto-aof-rewrite-percentage 100</td>
<td>AOF 文件重写触发条件之一</td>
</tr>
<tr>
<td>auto-aof-rewrite-min-size 64mb</td>
<td>AOF 文件重写触发条件之一</td>
</tr>
<tr>
<td>aof-load-truncated yes</td>
<td>如果 AOF 文件结尾损坏，Redis 服务器在启动时是否仍载入 AOF 文件</td>
</tr>
</tbody>
</table>
<h2 id="redis出现的问题">Redis出现的问题</h2>
<h3 id="缓存穿透">缓存穿透</h3>
<blockquote>
<p>缓存穿透是指查询一个一定不存在的数据，由于缓存是不命中时被动写的，并且出于容错考虑，如果从存储层查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到存储层去查询，失去了缓存的意义。在流量大时，可能DB就挂掉了，要是有人利用不存在的key频繁攻击我们的应用，这就是漏洞。</p>
</blockquote>
<h4 id="解决方案">解决方案</h4>
<ol>
<li>如果一个查询返回的数据为空（不管是数据不存在，还是系统故障），我们仍然把这个空结果进行缓存，但它的过期时间会很短，最长不超过五分钟。通过这个直接设置的默认值存放到缓存，这样第二次到缓存中获取就有值了，而不会继续访问数据库，这种办法最简单粗暴</li>
<li>采用布隆过滤器，将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被这个bitmap拦截掉，从而避免了对底层存储系统的查询压力。Guava中提供了一个方便的工具，不过这个工具是基于单体架构的，集群模式可以将Guava中的bitmap换成redis中的位图(setbit命令)</li>
</ol>
<h3 id="缓存击穿">缓存击穿</h3>
<blockquote>
<p>对于一些设置了过期时间的key，如果这些key可能会在某些时间点被超高并发地访问，是一种非常“热点”的数据。这个时候，需要考虑一个问题：缓存被“击穿”的问题，这个和缓存雪崩的区别在于这里针对某一key缓存，前者则是很多key。缓存在某个时间点过期的时候，恰好在这个时间点对这个Key有大量的并发请求过来，这些请求发现缓存过期一般都会从后端DB加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端DB压垮。</p>
</blockquote>
<h4 id="解决方案-2">解决方案</h4>
<ol>
<li>设置key永不过期</li>
<li>使用redis双端锁(类似单例模式)</li>
</ol>
<h3 id="缓存雪崩">缓存雪崩</h3>
<blockquote>
<p>缓存雪崩是指缓存中数据大批量到过期时间，而查询数据量巨大，引起数据库压力过大甚至down机。和缓存击穿不同的是，        缓存击穿指并发查同一条数据，缓存雪崩是不同数据都过期了，很多数据都查不到从而查数据库。</p>
</blockquote>
<h4 id="解决方案-3">解决方案</h4>
<ol>
<li>缓存数据的过期时间设置随机，防止同一时间大量数据过期现象发生。</li>
<li>如果缓存数据库是分布式部署，将热点数据均匀分布在不同搞得缓存数据库中。</li>
<li>设置热点数据永远不过期。</li>
</ol>
<h2 id="redis分布式锁">Redis分布式锁</h2>
<blockquote>
<p>在多线程的环境下，为了保证一个代码块在同一时间只能由一个线程访问，Java中我们一般可以使用synchronized语法和ReetrantLock去保证，这实际上是本地锁的方式。<br>
在分布式状态下多个进程或者多个服务器之间的锁并不能够互斥，最常见的案例是使用Nginx作为负载均衡时单纯的syn或者Reentrantlock并不能锁住其他服务器，为了解决这个问题需要使用分布式锁，它是控制分布式系统之间互斥访问共享资源的一种方式。</p>
</blockquote>
<blockquote>
<p>分布式锁的实现方式</p>
</blockquote>
<ul>
<li>基于数据库</li>
<li>基于Redis</li>
<li>基于zookeeper</li>
</ul>
<h3 id="分布式锁实现">分布式锁实现</h3>
<h4 id="利用setnxexpire命令">利用setnx+expire命令</h4>
<h5 id="执行方式">执行方式</h5>
<ul>
<li>Redis的SETNX命令，setnx key value，将key设置为value，当键不存在时，才能成功，若键存在，什么也不做，成功返回1，失败返回0 。 SETNX实际上就是SET IF NOT Exists的缩写。因为分布式锁还需要超时机制，所以我们利用expire命令来设置，所以利用setnx+expire命令的核心。</li>
</ul>
<h5 id="错误分析">错误分析</h5>
<ul>
<li>实际上上面的步骤是有问题的，setnx和expire是分开的两步操作，不具有原子性，如果执行完第一条指令应用异常或者重启了，锁将无法过期。</li>
</ul>
<h4 id="利用-public-string-setstring-key-string-value-setparams-params-命令">利用  public String set(String key, String value, SetParams params) 命令</h4>
<h5 id="执行方式-2">执行方式</h5>
<ul>
<li>Redis在 2.6.12 版本开始，为 SET 命令增加一系列选项，利用这个命令将setnx+expire整合为一条命令，确保为原子操作</li>
<li>EX seconds: 设定过期时间，单位为秒</li>
<li>PX milliseconds: 设定过期时间，单位为毫秒</li>
<li>NX: 仅当key不存在时设置值</li>
<li>XX: 仅当key存在时设置值<br>
####利用 lua脚本</li>
<li>Lua 是一种轻量小巧的脚本语言，用标准C语言编写并以源代码形式开放， 其设计目的是为了嵌入应用程序中，从而为应用程序提供灵活的扩展和定制功能。</li>
<li>减少网络开销：本来多次网络请求的操作，可以用一个请求完成，原先多次请求的逻辑放在redis服务器上完成。使用脚本，减少了网络往返时延</li>
<li>原子操作：Redis会将整个脚本作为一个整体执行，中间不会被其他命令插入</li>
</ul>
<h4 id="redis锁中key和value的分析">redis锁中key和value的分析</h4>
<ul>
<li>
<p>key：key要保证资源的互斥。在秒杀场景中，可以取商品id作为key，不同的商品时不同的key，保证只锁住相同的商品提高效率。如果秒杀流量足够大，也可以将相同商品库存拆分，利用分段锁提高效率。</p>
</li>
<li>
<p>value：value必须要具有唯一性，我们可以用UUID来做，设置随机字符串保证唯一性，至于为什么要保证唯一性？假如value不是随机字符串，而是一个固定值，那么就可能存在下面的问题：</p>
<ol>
<li>客户端1获取锁成功</li>
<li>客户端1在某个操作上阻塞了太长时间</li>
<li>设置的key过期了，锁自动释放了</li>
<li>客户端2获取到了对应同一个资源的锁</li>
<li>客户端1从阻塞中恢复过来，因为value值一样，所以执行释放锁操作时就会释放掉客户端2持有的锁</li>
</ol>
<p>解锁时，我们需要判断锁是否是自己的，基于value值来判断。</p>
</li>
</ul>
<h3 id="开源jar包里的分布式锁-redisson">开源jar包里的分布式锁 Redisson</h3>
<h4 id="redissonlock">RedissonLock</h4>
<h5 id="基本用法">基本用法</h5>
<pre><code class="language-java">RLock lock = redisson.getLock(&quot;foobar&quot;); // 1.获得锁对象实例
lock.lock(); // 2.获取分布式锁
try {
    // do sth.
} finally {
    lock.unlock(); // 3.释放锁
}
</code></pre>
<ol>
<li>通过 RedissonClient 的 getLock() 方法取得一个 RLock 实例。</li>
<li>lock() 方法尝试获取锁，如果成功获得锁，则继续往下执行，否则等待锁被释放，然后再继续尝试获取锁，直到成功获得锁。</li>
<li>unlock() 方法释放获得的锁，并通知等待的节点锁已释放。</li>
</ol>
<h5 id="具体实现">具体实现</h5>
<p>这里的 RLock 是继承自 java.util.concurrent.locks.Lock 的一个 interface，getLock 返回的实际上是其实现类 RedissonLock 的实例。</p>
<pre><code>@(Redis)Override
public RLock getLock(String name) {
  return new RedissonLock(commandExecutor, name, id);
}
</code></pre>
<p><strong>RedissonLock 的参数</strong></p>
<ol>
<li>commandExecutor: 与 Redis 节点通信并发送指令的真正实现。需要说明一下，Redisson 缺省的 CommandExecutor 实现是通过 eval 命令来执行 Lua 脚本，所以要求 Redis 的版本必须为 2.6 或以上，否则你可能要自己来实现 CommandExecutor。关于 Redisson 的 CommandExecutor 以后会专门解读，所以本次就不多说了。</li>
<li>name: 锁的全局名称，例如上面代码中的 &quot;foobar&quot;，具体业务中通常可能使用共享资源的唯一标识作为该名称。</li>
<li>id: Redisson 客户端唯一标识，实际上就是一个 UUID.randomUUID()。</li>
</ol>
<p><strong>RedissonLock的lock方法</strong><br>
此处略过前面几个方法的层层调用，直接看最核心部分的方法 lockInterruptibly()，该方法在 RLock 中声明，支持对获取锁的线程进行中断操作。在直接使用 lock() 方法获取锁时，最后实际执行的是 lockInterruptibly(-1, null)。</p>
<pre><code class="language-java">@Override
public void lockInterruptibly(long leaseTime, TimeUnit unit) throws InterruptedException {
    // 1.尝试获取锁
    Long ttl = tryAcquire(leaseTime, unit);
    // 2.获得锁成功
    if (ttl == null) {
        return;
    }
    // 3.等待锁释放，并订阅锁
    long threadId = Thread.currentThread().getId();
    Future&lt;RedissonLockEntry&gt; future = subscribe(threadId);
    get(future);

    try {
        while (true) {
            // 4.重试获取锁
            ttl = tryAcquire(leaseTime, unit);
            // 5.成功获得锁
            if (ttl == null) {
                break;
            }
            // 6.等待锁释放
            if (ttl &gt;= 0) {
                getEntry(threadId).getLatch().tryAcquire(ttl, TimeUnit.MILLISECONDS);
            } else {
                getEntry(threadId).getLatch().acquire();
            }
        }
    } finally {
        // 7.取消订阅
        unsubscribe(future, threadId);
    }
}
</code></pre>
<ol>
<li>先尝试获取锁，具体代码下面再看，返回结果是已存在的锁的剩余存活时间，为 null 则说明没有已存在的锁并成功获得锁。</li>
<li>如果获得锁则结束流程，回去执行业务逻辑。</li>
<li>如果没有获得锁，则需等待锁被释放，并通过 Redis 的 channel 订阅锁释放的消息，这里的具体实现本文也不深入，只是简单提一下 Redisson 在执行 Redis 命令时提供了同步和异步的两种实现，但实际上同步的实现都是基于异步的，具体做法是使用 Netty 中的异步工具 Future 和 FutureListener 结合 JDK 中的 CountDownLatch 一起实现。</li>
<li>订阅锁的释放消息成功后，进入一个不断重试获取锁的循环，循环中每次都先试着获取锁，并得到已存在的锁的剩余存活时间。</li>
<li>如果在重试中拿到了锁，则结束循环，跳过第 6 步。<br>
6 .如果锁当前是被占用的，那么等待释放锁的消息，具体实现使用了 JDK 并发的信号量工具 Semaphore 来阻塞线程，当锁释放并发布释放锁的消息后，信号量的 release() 方法会被调用，此时被信号量阻塞的等待队列中的一个线程就可以继续尝试获取锁了。</li>
<li>在成功获得锁后，就没必要继续订阅锁的释放消息了，因此要取消对 Redis 上相应 channel 的订阅。</li>
</ol>
<p><strong>RedissonLock的tryAcquire方法</strong></p>
<pre><code class="language-java">private Long tryAcquire(long leaseTime, TimeUnit unit) {
    // 1.将异步执行的结果以同步的形式返回
    return get(tryAcquireAsync(leaseTime, unit, Thread.currentThread().getId()));
}

private &lt;T&gt; Future&lt;Long&gt; tryAcquireAsync(long leaseTime, TimeUnit unit, long threadId) {
    if (leaseTime != -1) {
        return tryLockInnerAsync(leaseTime, unit, threadId, RedisCommands.EVAL_LONG);
    }
    // 2.用默认的锁超时时间去获取锁
    Future&lt;Long&gt; ttlRemainingFuture = tryLockInnerAsync(LOCK_EXPIRATION_INTERVAL_SECONDS,
                TimeUnit.SECONDS, threadId, RedisCommands.EVAL_LONG);
    ttlRemainingFuture.addListener(new FutureListener&lt;Long&gt;() {
        @Override
        public void operationComplete(Future&lt;Long&gt; future) throws Exception {
            if (!future.isSuccess()) {
                return;
            }
            Long ttlRemaining = future.getNow();
            // 成功获得锁
            if (ttlRemaining == null) {
                // 3.锁过期时间刷新任务调度
                scheduleExpirationRenewal();
            }
        }
    });
    return ttlRemainingFuture;
}

&lt;T&gt; Future&lt;T&gt; tryLockInnerAsync(long leaseTime, TimeUnit unit, long threadId,
                RedisStrictCommand&lt;T&gt; command) {
    internalLockLeaseTime = unit.toMillis(leaseTime);
    // 4.使用 EVAL 命令执行 Lua 脚本获取锁
    return commandExecutor.evalWriteAsync(getName(), LongCodec.INSTANCE, command,
              &quot;if (redis.call('exists', KEYS[1]) == 0) then &quot; +
                  &quot;redis.call('hset', KEYS[1], ARGV[2], 1); &quot; +
                  &quot;redis.call('pexpire', KEYS[1], ARGV[1]); &quot; +
                  &quot;return nil; &quot; +
              &quot;end; &quot; +
              &quot;if (redis.call('hexists', KEYS[1], ARGV[2]) == 1) then &quot; +
                  &quot;redis.call('hincrby', KEYS[1], ARGV[2], 1); &quot; +
                  &quot;redis.call('pexpire', KEYS[1], ARGV[1]); &quot; +
                  &quot;return nil; &quot; +
              &quot;end; &quot; +
              &quot;return redis.call('pttl', KEYS[1]);&quot;,
                Collections.&lt;Object&gt;singletonList(getName()), internalLockLeaseTime,
                        getLockName(threadId));
}
</code></pre>
<ol>
<li>上面说过 Redisson 实现的执行 Redis 命令都是异步的，但是它在异步的基础上提供了以同步的方式获得执行结果的封装。</li>
<li>前面提到分布式锁要确保未来的一段时间内锁一定能够被释放，因此要对锁设置超时释放的时间，在我们没有指定该时间的情况下，Redisson 默认指定为30秒。</li>
<li>在成功获取到锁的情况下，为了避免业务中对共享资源的操作还未完成，锁就被释放掉了，需要定期（锁失效时间的三分之一）刷新锁失效的时间，这里 Redisson 使用了 Netty 的 TimerTask、Timeout 工具来实现该任务调度。</li>
<li>获取锁真正执行的命令，Redisson 使用 EVAL 命令执行上面的 Lua 脚本来完成获取锁的操作：</li>
<li>如果通过 exists 命令发现当前 key 不存在，即锁没被占用，则执行 hset 写入 Hash 类型数据 key:全局锁名称（例如共享资源ID）, field:锁实例名称（Redisson客户端ID:线程ID）, value:1，并执行 pexpire 对该 key 设置失效时间，返回空值 nil，至此获取锁成功。</li>
<li>如果通过 hexists 命令发现 Redis 中已经存在当前 key 和 field 的 Hash 数据，说明当前线程之前已经获取到锁，因为这里的锁是可重入的，则执行 hincrby 对当前 key field 的值加一，并重新设置失效时间，返回空值，至此重入获取锁成功。</li>
<li>最后是锁已被占用的情况，即当前 key 已经存在，但是 Hash 中的 Field 与当前值不同，则执行 pttl 获取锁的剩余存活时间并返回，至此获取锁失败。</li>
</ol>
<p><strong>RedissonLock的unlock方法</strong></p>
<pre><code class="language-java">@Override
public void unlock() {
    // 1.通过 EVAL 和 Lua 脚本执行 Redis 命令释放锁
    Boolean opStatus = commandExecutor.evalWrite(getName(), LongCodec.INSTANCE,
                    RedisCommands.EVAL_BOOLEAN,
                    &quot;if (redis.call('exists', KEYS[1]) == 0) then &quot; +
                        &quot;redis.call('publish', KEYS[2], ARGV[1]); &quot; +
                        &quot;return 1; &quot; +
                    &quot;end;&quot; +
                    &quot;if (redis.call('hexists', KEYS[1], ARGV[3]) == 0) then &quot; +
                        &quot;return nil;&quot; +
                    &quot;end; &quot; +
                    &quot;local counter = redis.call('hincrby', KEYS[1], ARGV[3], -1); &quot; +
                    &quot;if (counter &gt; 0) then &quot; +
                        &quot;redis.call('pexpire', KEYS[1], ARGV[2]); &quot; +
                        &quot;return 0; &quot; +
                    &quot;else &quot; +
                        &quot;redis.call('del', KEYS[1]); &quot; +
                        &quot;redis.call('publish', KEYS[2], ARGV[1]); &quot; +
                        &quot;return 1; &quot;+
                    &quot;end; &quot; +
                    &quot;return nil;&quot;,
                    Arrays.&lt;Object&gt;asList(getName(), getChannelName()), 
                            LockPubSub.unlockMessage, internalLockLeaseTime, 
                            getLockName(Thread.currentThread().getId()));
    // 2.非锁的持有者释放锁时抛出异常
    if (opStatus == null) {
        throw new IllegalMonitorStateException(
                &quot;attempt to unlock lock, not locked by current thread by node id: &quot;
                + id + &quot; thread-id: &quot; + Thread.currentThread().getId());
    }
    // 3.释放锁后取消刷新锁失效时间的调度任务
    if (opStatus) {
        cancelExpirationRenewal();
    }
}
</code></pre>
<ol>
<li>使用 EVAL 命令执行 Lua 脚本来释放锁：</li>
<li>key 不存在，说明锁已释放，直接执行 publish 命令发布释放锁消息并返回 1。</li>
<li>key 存在，但是 field 在 Hash 中不存在，说明自己不是锁持有者，无权释放锁，返回 nil。</li>
<li>因为锁可重入，所以释放锁时不能把所有已获取的锁全都释放掉，一次只能释放一把锁，因此执行 hincrby 对锁的值减一。</li>
<li>释放一把锁后，如果还有剩余的锁，则刷新锁的失效时间并返回 0；如果刚才释放的已经是最后一把锁，则执行 del 命令删除锁的 key，并发布锁释放消息，返回 1。</li>
<li>上面执行结果返回 nil 的情况（即第2中情况），因为自己不是锁的持有者，不允许释放别人的锁，故抛出异常。</li>
<li>执行结果返回 1 的情况，该锁的所有实例都已全部释放，所以不需要再刷新锁的失效时间。</li>
</ol>
<h2 id="redis复制">Redis复制</h2>
<blockquote>
<p>主从复制，主机数据更新后根据配置和策略，自动同步到备机的master/slver机制，Master以写为主，Slave以读为主。作用为</p>
<ul>
<li>读写分离</li>
<li>容灾恢复</li>
</ul>
</blockquote>
<h3 id="配置方法">配置方法</h3>
<p><code>配从不配主</code></p>
<h4 id="手动配置">手动配置</h4>
<ol>
<li>slaveof主库IP主库端口</li>
<li>Info replication查看是否配置成功</li>
</ol>
<p>每次与master断开之后，都需要重新连接</p>
<h4 id="配置文件配置">配置文件配置</h4>
<ol>
<li>拷贝多个redis.conf文件</li>
<li>开启daemonize yes</li>
<li>更改Pid文件名字</li>
<li>更改指定端口</li>
<li>更改Log文件名字</li>
<li>更改Dump.rdb名字</li>
</ol>
<h3 id="常用的配置">常用的配置</h3>
<h4 id="一主二从一主多从">一主二从/一主多从</h4>
<blockquote>
<p>当主节点shutdown后，从节点可读，但是从节点也不会升级为主节点</p>
</blockquote>
<h4 id="薪火相传">薪火相传</h4>
<blockquote>
<p>上一个Slave可以是下一个slave的Master，slave同样可以接受其他slaves的连接和同步请求，那么该slave作为链条中下一个的master，可以有效减轻master的写压力。</p>
</blockquote>
<h4 id="反客为主">反客为主</h4>
<blockquote>
<p>手动操作。当master节点挂掉之后，从节点使用slaveof no one 可以升级为主节点</p>
</blockquote>
<h4 id="哨兵模式重点">哨兵模式（重点）</h4>
<blockquote>
<p>反客为主的自动版，能够后台监控主机是否故障，如果故障了根据投票数自动将从库转换为主库。如果之前故障的master恢复，将自动变为slave。<br>
sentinel也是集群模式</p>
</blockquote>
<h3 id="复制原理">复制原理</h3>
<ol>
<li>如果设置了一个Slave，无论是第一次连接还是重连到Master，它都会发出一个SYNC命令；</li>
<li>当Master收到SYNC命令之后，会做两件事：<br>
a) Master执行BGSAVE，即在后台保存数据到磁盘（rdb快照文件）；<br>
b) Master同时将新收到的写入和修改数据集的命令存入缓冲区（非查询类）；</li>
<li>当Master在后台把数据保存到快照文件完成之后，Master会把这个快照文件传送给Slave，而Slave则把内存清空后，加载该文件到内存中；</li>
<li>而Master也会把此前收集到缓冲区中的命令，通过Reids命令协议形式转发给Slave，Slave执行这些命令，实现和Master的同步；</li>
<li>Master/Slave此后会不断通过异步方式进行命令的同步，达到最终数据的同步一致；</li>
<li>需要注意的是Master和Slave之间一旦发生重连都会引发全量同步操作。但在2.8之后版本，也可能是部分同步操作。</li>
</ol>
<p><code>部分复制</code><br>
2.8开始，当Master和Slave之间的连接断开之后，他们之间可以采用持续复制处理方式代替采用全量同步。<br>
Master端为复制流维护一个内存缓冲区（in-memory backlog），记录最近发送的复制流命令；同时，Master和Slave之间都维护一个复制偏移量(replication offset)和当前Master服务器ID（Master run id）。当网络断开，Slave尝试重连时：<br>
a. 如果MasterID相同（即仍是断网前的Master服务器），并且从断开时到当前时刻的历史命令依然在Master的内存缓冲区中存在，则Master会将缺失的这段时间的所有命令发送给Slave执行，然后复制工作就可以继续执行了；<br>
b. 否则，依然需要全量复制操作；</p>
<h3 id="脑裂问题">脑裂问题</h3>
<blockquote>
<p>redis的集群脑裂是指因为网络问题，导致redis master节点跟redis slave节点和sentinel集群处于不同的网络分区，此时因为sentinel集群无法感知到master的存在，所以将slave节点提升为master节点。此时存在两个不同的master节点，就像一个大脑分裂成了两个。<br>
集群脑裂问题中，如果客户端还在基于原来的master节点继续写入数据，那么新的master节点将无法同步这些数据，当网络问题解决之后，sentinel集群将原先的master节点降为slave节点，此时再从新的master中同步数据，将会造成大量的数据丢失。</p>
</blockquote>
<h4 id="解决方案-4">解决方案</h4>
<p>redis的配置文件中，存在两个参数</p>
<pre><code>min-slaves-to-write 3   //连接到master的最少slave数量
min-slaves-max-lag 10   //slave连接到master的最大延迟时间
</code></pre>
<p>按照上面的配置，要求至少3个slave节点，且数据复制和同步的延迟不能超过10秒，否则的话master就会拒绝写请求，配置了这两个参数之后，如果发生集群脑裂，原先的master节点接收到客户端的写入请求会拒绝，就可以减少数据同步之后的数据丢失。<br>
<code>注意：较新版本的redis.conf文件中的参数变成了</code></p>
<pre><code>min-replicas-to-write 3
min-replicas-max-lag 10
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Java并发编程]]></title>
        <id>https://EastBeforeDawn.github.io/post/javaConcurrent/</id>
        <link href="https://EastBeforeDawn.github.io/post/javaConcurrent/">
        </link>
        <updated>2020-06-11T14:18:10.000Z</updated>
        <content type="html"><![CDATA[<h2 id="volatile关键字">volatile关键字</h2>
<blockquote>
<p>volatile是java提供的轻量级的同步机制，主要有三个特性：</p>
</blockquote>
<ul>
<li>保证可见性</li>
<li>禁止指令重排</li>
<li>不保证原子性。</li>
</ul>
<h3 id="jmmjava-内存模型">JMM（Java 内存模型）</h3>
<h4 id="基本概念">基本概念</h4>
<blockquote>
<p>JMM本身是一种抽象的概念 并不真实存在，他描述的是一组定义或规范，通过这组规范规定了程序中的访问方式<br>
JMM同步规定：</p>
</blockquote>
<ul>
<li>线程解锁前必须把共享变量的值刷回主内存</li>
<li>线程加锁前把主内存的值复制到自己的内存</li>
<li>加锁和解锁必须是同一把锁。</li>
</ul>
<blockquote>
<p>运行程序的实体是线程，而每个线程创建时 JVM 都会为其创建一个工作内存，工作内存是每个线程的私有数据区域，而 Java 内存模型中规定所有变量的储存在主内存，主内存是共享内存区域，所有的线程都可以访问，但线程对变量的操作（读取赋值等）必须都工作内存进行看。</p>
</blockquote>
<blockquote>
<p>从主内存拷贝内存空间，然后对变量进行操作，操作完成后再将变量写回主内存，不能直接操作主内存中的变量，工作内存中存储着主内存中的变量副本拷贝，前面说过，工作内存是每个线程的私有数据区域，因此不同的线程间无法访问对方的工作内存，线程间的通信(传值)必须通过主内存来完成。</p>
</blockquote>
<h5 id="可见性代码示例">可见性代码示例</h5>
<pre><code class="language-java">public class VolatileDemo {
    static int v1;

    public static void main(String[] args) {
        new Thread(new Runnable() {

            @Override
            public void run() {
                try {
                    Thread.sleep(1000);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
                v1 = 100;

            }
        }).start();
        
        while (v1 == 0) {

        }
        System.out.println(&quot;v1 = &quot; + v1);

    }

}
</code></pre>
<p>上面示例无法输出结果，当主线程已经读到v1的值时，如果不加volatile关键字，另一个线程更改这个值不会去通知主线程。所以进入死循环。如果加上volatile关键字，则会刷新主线程的v1的值，打印之后结束主线程。</p>
<h5 id="不保证原子性代码示例">不保证原子性代码示例</h5>
<pre><code class="language-java">public class VolatileDemo {
     static volatile int v1;
     public static void add(){
         v1++;
     }

    public static void main(String[] args) throws InterruptedException {

        for(int i = 0;i&lt; 20;i++) {
            new Thread(new Runnable() {

                @Override
                public void run() {
                    for(int i = 0;i &lt; 1000; i++){
                    add();
                    }
                }
            }).start();
        }
          //当活动线程只有主线程和GC时才进行打印否则让位其他线程
       while (Thread.activeCount() &gt; 2){
           Thread.yield();
       }
        System.out.println(&quot;v1 = &quot; + v1);

    }

}
</code></pre>
<ul>
<li>i++并非原子操作，包含三个步骤</li>
</ul>
<ol>
<li>读取i的值</li>
<li>将i的值加一</li>
<li>将加一后的值写回i</li>
</ol>
<ul>
<li>发现上面示例打印的总是比20000小，说明volatile并不能保证原子性 。</li>
</ul>
<h5 id="禁止指令重排">禁止指令重排</h5>
<blockquote>
<p>指令重排：一般情况下，CPU和编译器为了提升程序执行的效率，会按照一定的规则允许进行指令优化，在某些情况下，这种优化会带来一些执行的逻辑问题，主要的原因是代码逻辑之间是存在一定的先后顺序，在并发执行情况下，会发生二义性，即按照不同的执行逻辑，会得到不同的结果信息。</p>
</blockquote>
<blockquote>
<p>volatile 实现禁止指令重排序的优化，从而避免了多线程环境下程序出现乱序的现象。先了解一个概念，内存屏障（Memory Barrier）又称内存栅栏，是一个 CPU 指令，他的作用有两个：</p>
</blockquote>
<ol>
<li>保证特定操作的执行顺序</li>
<li>保证某些变量的内存可见性（利用该特性实现 volatile 的内存可见性）</li>
</ol>
<blockquote>
<p>由于编译器个处理器都能执行指令重排序优化，如果在指令间插入一条 Memory Barrier 则会告诉编译器和 CPU，不管什么指令都不能个这条 Memory Barrier 指令重排序，也就是说通过插入内存屏障禁止在内存屏障前后执行重排序优化。内存屏障另一个作用是强制刷出各种 CPU 缓存数据，因此任何 CPU 上的线程都能读取到这些数据的最新版本。</p>
</blockquote>
<h5 id="volatile常见用法双端检锁单例">volatile常见用法（双端检锁单例）</h5>
<pre><code class="language-java">public class Singleton {
    private static volatile Singleton singleton;

    private Singleton() {
    }

    public static Singleton getInstance(){
        if(singleton == null){
            synchronized (Singleton.class){
                if(singleton == null){
                    singleton = new Singleton();
                }
            }
        }
        return singleton;
    }
}
</code></pre>
<ul>
<li>如果不加volatile多线程环境下存在指令重排的风险，singleton = new Singleton(); 可以分解为三条指令
<ol>
<li>分配内存地址</li>
<li>初始化对象</li>
<li>将内存地址指向初始化对象</li>
</ol>
</li>
<li>由于指令重排只保证单线程下程序的执行结果，编译可以优化为1,3,2的顺序，这样在getInstance方法调用时singleton == null。加上volatile可以避免这个问题。</li>
</ul>
<h2 id="cas-compareandswap比较并交换">CAS （CompareAndSwap）比较并交换</h2>
<blockquote>
<p>CAS是一种无锁编程，对比synchronized效率更高。CAS操作包含三个操作数——内存位置（V），预期原值（A）和新值（B）。如果内存位置的值与预期原值相匹配，那么处理器将会自动将该位置值更新为新值，否则，不做任何操作。无论哪种情况，它都会在CAS指令之前返回该位置的值。</p>
</blockquote>
<blockquote>
<p>通过以上定义我们知道CAS其实是有三个步骤的:</p>
</blockquote>
<ol>
<li>读取内存中的值</li>
<li>将读取的值和预期的值比较</li>
<li>如果比较的结果符合预期，则写入新值</li>
</ol>
<blockquote>
<p>CAS 体现在 JAVA 语言中就是 sun.misc.Unsafe 类中的各个方法。调用 UnSafe 类中的 CAS 方法，JVM 会帮我们实现出 CAS 汇编指令。这是一种完全依赖硬件的功能，通过它实现了原子操作。由于 CAS 是一种系统源语，源语属于操作系统用语范畴，是由若干条指令组成，用于完成某一个功能的过程，并且原语的执行必须是连续的，在执行的过程中不允许被中断，也就是说 CAS 是一条原子指令，不会造成所谓的数据不一致的问题。</p>
</blockquote>
<h3 id="unsafe类">UnSafe类</h3>
<pre><code class="language-java">public class AtomicInteger extends Number implements java.io.Serializable {
    private static final long serialVersionUID = 6214790243416807050L;

    // setup to use Unsafe.compareAndSwapInt for updates
    private static final Unsafe unsafe = Unsafe.getUnsafe();
    private static final long valueOffset;

    static {
        try {
            valueOffset = unsafe.objectFieldOffset
                (AtomicInteger.class.getDeclaredField(&quot;value&quot;));
        } catch (Exception ex) { throw new Error(ex); }
    }

    private volatile int value;

    /**
     * Creates a new AtomicInteger with the given initial value.
     *
     * @param initialValue the initial value
     */
    public AtomicInteger(int initialValue) {
        value = initialValue;
    }

    /**
     * Creates a new AtomicInteger with initial value {@code 0}.
     */
    public AtomicInteger() {
    }
</code></pre>
<p>Unsafe 是 CAS 的核心类，由于 Java 方法无法直接访问底层系统，而需要通过本地（native）方法来访问， Unsafe 类相当一个后门，基于该类可以直接操作特定内存的数据。Unsafe 类存在于 sun.misc 包中，其内部方法操作可以像 C 指针一样直接操作内存，因为 Java 中 CAS 操作执行依赖于 Unsafe 类。<br>
变量 vauleOffset，表示该变量值在内存中的偏移量，因为 Unsafe 就是根据内存偏移量来获取数据的。<br>
变量 value 用 volatile 修饰，保证了多线程之间的内存可见性。</p>
<h4 id="atomicinteger示例代码">AtomicInteger示例代码</h4>
<pre><code class="language-java">import java.util.concurrent.atomic.AtomicInteger;

public class AtomicDemo {

    public static void main(String[] args) {

        AtomicInteger i = new AtomicInteger(2019);
        System.out.println(i.compareAndSet(2019, 2020));  //true
        System.out.println(i); //2020
        
        AtomicInteger n = new AtomicInteger();
        System.out.println(n.compareAndSet(2019, 2020)); //false
        System.out.println(n); // 0
    }
}
</code></pre>
<p>除了JAVA提供的基本类型外还提供了AtuomicRefence 原子引用类，可以处理对象的原子类。</p>
<h4 id="atomicrefence示例代码">AtomicRefence示例代码</h4>
<pre><code class="language-java">import java.util.Objects;
import java.util.concurrent.atomic.AtomicReference;

public class AtomicDemo {

    public static void main(String[] args) {
        User user = new User(&quot;zhangsan&quot;, 18);
        AtomicReference atomicReference = new AtomicReference(user);
        atomicReference.compareAndSet(user,new User(&quot;lisi&quot;,20));
        System.out.println(atomicReference.get());
    }
}


class User {
    private String name;
    private int age;

    public User(String name, int age) {
        this.name = name;
        this.age = age;
    }

    @Override
    public String toString() {
        return &quot;User{&quot; +
                &quot;name='&quot; + name + '\'' +
                &quot;, age=&quot; + age +
                '}';
    }

}
</code></pre>
<h3 id="cas的缺点">CAS的缺点</h3>
<ol>
<li>循环时间长开销很大。如果 CAS 失败，会一直尝试，如果 CAS 长时间一直不成功，可能会给 CPU 带来很大的开销（比如线程数很多，每次比较都是失败，就会一直循环），所以希望是线程数比较小的场景。</li>
<li>只能对一个共享变量进行原子操作，多个变量的情况不可用。</li>
<li>会出现ABA问题</li>
</ol>
<h4 id="aba问题">ABA问题</h4>
<p>两个线程修改共享变量，共享变量由A改为B，又由B改为A。此时另一个线程并不知道情况，以为共享变量的值没有改变，将共享变量的值修改。</p>
<h5 id="代码示例">代码示例</h5>
<pre><code class="language-java">import java.util.concurrent.atomic.AtomicInteger;

public class AtomicABADemo {

    public static void main(String[] args) {
        AtomicInteger i = new AtomicInteger();
        new Thread(new Runnable() {
            @Override
            public void run() {
                i.compareAndSet(0,1);
                System.out.println(&quot;i的值由0改为1&quot;);
                i.compareAndSet(1,0);
                System.out.println(&quot;i的值由1改为0&quot;);
            }
        }).start();

        new Thread(new Runnable() {
            @Override
            public void run() {
                try {
                    Thread.sleep(2000);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
                i.compareAndSet(0,2019);
                System.out.println(&quot;ABA问题出现——》i的值由0改为2019&quot;);
            }
        }).start();
    }
}
</code></pre>
<h4 id="解决方案">解决方案</h4>
<p>java提供了一个带有版本号的原子引用类AtomicStampedRefence，实际上就是一个乐观锁。</p>
<h5 id="代码示例-2">代码示例</h5>
<pre><code class="language-java">import java.util.concurrent.atomic.AtomicStampedReference;

public class AtomicDemo {
    public static void main(String[] args) {
        User user  = new User(&quot;zhangsan&quot;,18);
        // 传入初始对象和版本号
        AtomicStampedReference atomicStampedReference = new AtomicStampedReference(user,0);
        User user1  = new User(&quot;lisi&quot;,20);

        new Thread(new Runnable() {
            @Override
            public void run() {
                try {
                    Thread.sleep(1000);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
                atomicStampedReference.compareAndSet(user,user1,atomicStampedReference.getStamp(),atomicStampedReference.getStamp()+1);
                System.out.println(&quot;版本号为&quot; + atomicStampedReference.getStamp() + &quot;，User对象信息为&quot; + atomicStampedReference.getReference());
                atomicStampedReference.compareAndSet(user1,user,atomicStampedReference.getStamp(),atomicStampedReference.getStamp()+1);
                System.out.println(&quot;版本号为&quot; + atomicStampedReference.getStamp() + &quot;，User对象信息为&quot; + atomicStampedReference.getReference());

            }
        }).start();

        new Thread(new Runnable() {
            @Override
            public void run() {
                int stamp = atomicStampedReference.getStamp();
                User user2  = new User(&quot;wangwu&quot;,28);
                try {
                    Thread.sleep(3000);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
                atomicStampedReference.compareAndSet(user,user2,stamp,stamp++);
                System.out.println(&quot;版本号为&quot; + atomicStampedReference.getStamp() + &quot;，User对象信息为&quot; + atomicStampedReference.getReference());


            }
        }).start();

    }
}


class User {
    private String name;
    private int age;

    public User(String name, int age) {
        this.name = name;
        this.age = age;
    }

    @Override
    public String toString() {
        return &quot;User{&quot; +
                &quot;name='&quot; + name + '\'' +
                &quot;, age=&quot; + age +
                '}';
    }

}
</code></pre>
<h2 id="java中的锁">Java中的锁</h2>
<h3 id="公平锁与非公平锁">公平锁与非公平锁</h3>
<ul>
<li>公平锁：是指多个线程按照申请的顺序来获取值</li>
<li>非公平锁：是值多个线程获取值的顺序并不是按照申请锁的顺序，有可能后申请的线程比先申请的线程优先获取锁，在高并发的情况下，可能会造成优先级翻转或者饥饿现象</li>
</ul>
<h4 id="两者区别">两者区别</h4>
<ul>
<li>公平锁：在并发环境中，每一个线程在获取锁时会先查看此锁维护的等待队列，如果为空，或者当前线程是等待队列的第一个就占有锁，否者就会加入到等待队列中，以后会按照 FIFO 的规则获取锁</li>
<li>非公平锁：一上来就尝试占有锁，如果失败在进行排队</li>
</ul>
<h5 id="代码示例-3">代码示例</h5>
<pre><code class="language-java">/**
     * Creates an instance of {@code ReentrantLock}.
     * This is equivalent to using {@code ReentrantLock(false)}.
     */
    public ReentrantLock() {
        sync = new NonfairSync();
    }

    /**
     * Creates an instance of {@code ReentrantLock} with the
     * given fairness policy.
     *
     * @param fair {@code true} if this lock should use a fair ordering policy
     */
    public ReentrantLock(boolean fair) {
        sync = fair ? new FairSync() : new NonfairSync();
    }
</code></pre>
<p>ReentrantLock的构造方法中可传入一个boolean值，表示是否是公平锁。默认为非公平锁。 synchronized是一种非公平锁。</p>
<h3 id="可重入锁递归锁和不可重入锁">可重入锁（递归锁）和不可重入锁</h3>
<ul>
<li>可重入锁：指的是同一个线程外层函数获得锁之后，内层仍然能获取到该锁，在同一个线程在外层方法获取锁的时候，在进入内层方法或会自动获取该锁。</li>
<li>不可重入锁： 若当前线程执行某个方法已经获取了该锁，那么在方法中尝试再次获取锁时，就会获取不到被阻塞。</li>
</ul>
<h5 id="代码示例-4">代码示例</h5>
<pre><code class="language-java">public class ReentrantLockDemo {
    public static void main(String[] args) {
        method1();
    }
    public static synchronized void method1(){
        System.out.println(&quot;method1执行&quot;);
        method2();
    }

    public static synchronized void method2(){
        System.out.println(&quot;method2执行&quot;);
    }
}
</code></pre>
<p>在main方法中调用method1()发现两个方法都执行了，说明synchronized是可重入锁。ReentrantLock也是可重入锁。</p>
<h3 id="自旋锁-cas原理">自旋锁 (CAS原理)</h3>
<ul>
<li>尝试获取锁的线程不会立即堵塞，而是采用循环的方式去尝试获取锁，这样的好处是减少线程上线文切换的消耗，缺点就是循环会消耗 CPU。</li>
</ul>
<h5 id="代码示例-5">代码示例</h5>
<pre><code class="language-java">import java.util.concurrent.atomic.AtomicReference;

public class SpinLockTest {
    public static void main(String[] args) {
        SpinLock spinLock = new SpinLock();
        new Thread(new Runnable() {
            @Override
            public void run() {
                spinLock.lock();
                try {
                    Thread.sleep(1000);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
                System.out.println(&quot;------------&quot;);
                spinLock.unlock();
            }
        }).start();
        new Thread(new Runnable() {
            @Override
            public void run() {
                spinLock.lock();
                try {
                    Thread.sleep(1000);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
                System.out.println(&quot;++++++++++++&quot;);
                spinLock.unlock();
            }
        }).start();

    }
}

class SpinLock {
   private AtomicReference&lt;Thread&gt; atomicReference = new AtomicReference();
    public void lock() {
        Thread thread = Thread.currentThread();
        while (!atomicReference.compareAndSet(null, thread)) {

        }
        System.out.println(thread.getName() + &quot;获取锁&quot;);
    }
    public void unlock() {
        Thread thread = Thread.currentThread();
        atomicReference.compareAndSet(thread, null);
        System.out.println(thread.getName() + &quot;释放锁&quot;);
    }
}
/*
Thread-0获取锁
------------
Thread-0释放锁
Thread-1获取锁
++++++++++++
Thread-1释放锁
*/
</code></pre>
<p>输出结果表示加锁成功。获取锁的时候，如果原子引用为空就获取锁，不为空表示有人获取了锁，就循环等待。</p>
<h3 id="独占锁与共享锁读写锁">独占锁与共享锁（读写锁）</h3>
<ul>
<li>独占锁：指该锁一次只能被一个线程持有</li>
<li>共享锁：该锁可以被多个线程持有</li>
</ul>
<h4 id="分类">分类</h4>
<ul>
<li>Java中的ReentrantLock和synchronized都是独占锁。ReentrantReadWriteLock中的ReadLock是共享锁，WriteLock是独占锁。多个线程可以同时持有ReadLock，读写·写读·写写都是互斥的。</li>
</ul>
<h5 id="代码示例-6">代码示例</h5>
<pre><code class="language-java">import java.util.ArrayList;
import java.util.List;
import java.util.concurrent.locks.ReentrantReadWriteLock;

public class ReentrantReadWriteLockTest {

    public static void main(String[] args) {
        ReentrantReadWriteLock readWriteLock = new ReentrantReadWriteLock();
        List list = new ArrayList();


        for(int i = 0;i &lt; 20 ; i++){
            new Thread(new Runnable() {
                @Override
                public void run() {
                    readWriteLock.writeLock().lock();
                    System.out.println(Thread.currentThread() + &quot;写开始&quot;);
                    list.add(Math.round(Math.random()*100));
                    try {
                        Thread.sleep(500);
                    } catch (InterruptedException e) {
                        e.printStackTrace();
                    }
                    System.out.println(Thread.currentThread() + &quot;写结束&quot;);
                    readWriteLock.writeLock().unlock();
                }
            }).start();

        }

        for(int i = 0;i &lt; 20 ; i++){
            new Thread(new Runnable() {
                @Override
                public void run() {
                    readWriteLock.readLock().lock();
                    System.out.println(Thread.currentThread() + &quot;读开始&quot;);
                    System.out.println(list);
                    try {
                        Thread.sleep(1000);
                    } catch (InterruptedException e) {
                        e.printStackTrace();
                    }
                    System.out.println(Thread.currentThread() + &quot;读结束&quot;);
                    readWriteLock.readLock().unlock();
                }
            }).start();
        }
    }
}
</code></pre>
<h3 id="synchronized-和-lock">synchronized 和 Lock</h3>
<h3 id="原始结构">原始结构</h3>
<ul>
<li>synchronized 是关键字属于 JVM 层面，反应在字节码上是 monitorenter 和 monitorexit，其底层是通过 monitor 对象来完成，其实 wait/notify 等方法也是依赖 monitor 对象只有在同步快或方法中才能调用 wait/notify 等方法。</li>
<li>Lock 是具体类（java.util.concurrent.locks.Lock）是 api 层面的锁。</li>
</ul>
<h5 id="使用方法">使用方法</h5>
<ul>
<li>synchronized 不需要用户手动去释放锁，当 synchronized 代码执行完后系统会自动让线程释放对锁的占用。</li>
<li>ReentrantLock 则需要用户手动的释放锁，若没有主动释放锁，可能导致出现死锁的现象，lock() 和 unlock() 方法需要配合 try/finally 语句来完成。</li>
</ul>
<h5 id="等待是否可中断">等待是否可中断</h5>
<ul>
<li>synchronized 不可中断，除非抛出异常或者正常运行完成。</li>
<li>ReentrantLock 可中断，设置超时方法 tryLock(long timeout, TimeUnit unit)，lockInterruptibly() 放代码块中，调用 interrupt() 方法可中断。</li>
</ul>
<h5 id="加锁是否公平">加锁是否公平</h5>
<ul>
<li>synchronized 非公平锁</li>
<li>ReentrantLock 默认非公平锁，构造方法中可以传入 boolean 值，true 为公平锁，false 为非公平锁。</li>
</ul>
<h5 id="锁可以绑定多个-condition">锁可以绑定多个 Condition</h5>
<ul>
<li>synchronized 没有 Condition。</li>
<li>ReentrantLock 用来实现分组唤醒需要唤醒的线程们，可以精确唤醒，而不是像 synchronized 要么随机唤醒一个线程要么唤醒全部线程。</li>
</ul>
<table>
<thead>
<tr>
<th>类别</th>
<th>synchronized</th>
<th>Lock</th>
</tr>
</thead>
<tbody>
<tr>
<td>存在层次</td>
<td>Java的关键字，在jvm层面上</td>
<td>是一个类</td>
</tr>
<tr>
<td>锁的释放</td>
<td>1、以获取锁的线程执行完同步代码，释放锁 2、线程执行发生异常，jvm会让线程释放锁</td>
<td>在finally中必须释放锁，不然容易造成线程死锁</td>
</tr>
<tr>
<td>锁的获取</td>
<td>假设A线程获得锁，B线程等待。如果A线程阻塞，B线程会一直等待</td>
<td>分情况而定，Lock有多个锁获取的方式，具体下面会说道，大致就是可以尝试获得锁，线程可以不用一直等待</td>
</tr>
<tr>
<td>锁状态</td>
<td>无法判断</td>
<td>可以判断</td>
</tr>
<tr>
<td>锁类型</td>
<td>可重入 不可中断 非公平</td>
<td>可重入 可判断 可公平（两者皆可）</td>
</tr>
<tr>
<td>性能</td>
<td>少量同步</td>
<td>大量同步</td>
</tr>
</tbody>
</table>
<p>JDK1.6以后，为了减少获得锁和释放锁所带来的性能消耗，提高性能，引入了“轻量级锁”和“偏向锁”。官方更建议使用synchronized。<a href="https://blog.csdn.net/lengxiao1993/article/details/81568130">详情见Java中的偏向锁，轻量级锁， 重量级锁解析</a></p>
<h5 id="代码示例synchronized实现生产消费模型">代码示例:synchronized实现生产消费模型</h5>
<pre><code class="language-java">import java.util.concurrent.TimeUnit;

public class ProdConsume_Synchronized {
    private int count = 0;
    public static final int FULL = 10;
    private volatile boolean flag = true;
    private Object lock;

    public ProdConsume_Synchronized(Object lock) {
        this.lock = lock;
    }

    public static void main(String[] args) {
        Object lock = new Object();
        ProdConsume_Synchronized prodConsume_synchronized = new ProdConsume_Synchronized(lock);
        new Thread(new Runnable() {
            @Override
            public void run() {
                try {
                    prodConsume_synchronized.consume();
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
            }
        }).start();

        new Thread(new Runnable() {
            @Override
            public void run() {
                try {
                    prodConsume_synchronized.prod();
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
            }
        }).start();

        try {
            TimeUnit.SECONDS.sleep(10);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
        prodConsume_synchronized.flag = false;
    }

    public void prod() throws InterruptedException {
        while (flag) {
            synchronized (lock) {
                while (count == FULL) {
                    lock.wait();
                }
                count++;
                long round = Math.round(Math.random() * 1000);
                Thread.sleep(round);
                System.out.println(round + &quot;号商品生产完毕，还有&quot; + count + &quot;个商品&quot;);
                lock.notifyAll();

            }
        }
    }

    public void consume() throws InterruptedException {
        while (flag) {
            synchronized (lock) {
                while (count == 0) {
                    lock.wait();
                }
                count--;
                Thread.sleep(500);
                System.out.println(&quot;取走一个商品，还有&quot; + count + &quot;个商品&quot;);
                lock.notifyAll();

            }
        }
    }
}

输出结果

643号商品生产完毕，还有1个商品
322号商品生产完毕，还有2个商品
819号商品生产完毕，还有3个商品
877号商品生产完毕，还有4个商品
112号商品生产完毕，还有5个商品
904号商品生产完毕，还有6个商品
978号商品生产完毕，还有7个商品
569号商品生产完毕，还有8个商品
949号商品生产完毕，还有9个商品
661号商品生产完毕，还有10个商品
取走一个商品，还有9个商品
取走一个商品，还有8个商品
取走一个商品，还有7个商品
取走一个商品，还有6个商品
取走一个商品，还有5个商品
取走一个商品，还有4个商品
取走一个商品，还有3个商品
124号商品生产完毕，还有4个商品
</code></pre>
<h5 id="代码示例reentrantlock实现生产消费模型">代码示例:ReentrantLock实现生产消费模型</h5>
<pre><code class="language-java">import java.util.concurrent.TimeUnit;
import java.util.concurrent.locks.Condition;
import java.util.concurrent.locks.Lock;
import java.util.concurrent.locks.ReentrantLock;

public class ProdConsume_ReentrantLock {
    private int count = 0;
    public static final int FULL = 10;
    private volatile boolean flag = true;
    private Lock lock = new ReentrantLock();
    private Condition condition_prod = lock.newCondition();
    private Condition condition_consume = lock.newCondition();

    public static void main(String[] args) {
        ProdConsume_ReentrantLock prodConsume_reentrantLock = new ProdConsume_ReentrantLock();
        for (int i = 0; i &lt; 3; i++) {
            new Thread(new Runnable() {
                @Override
                public void run() {
                    prodConsume_reentrantLock.prod();
                }
            }).start();
        }


        for (int i = 0; i &lt; 3; i++) {
            new Thread(new Runnable() {
                @Override
                public void run() {
                    prodConsume_reentrantLock.consume();
                }
            }).start();
        }


        try {
            TimeUnit.SECONDS.sleep(10);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
        prodConsume_reentrantLock.flag = false;
    }

    public void prod() {
        while (flag) {
            try {
                lock.lock();
                try {
                    while (count == FULL) {
                        condition_prod.await();
                    }
                    count++;
                    long round = Math.round(Math.random() * 1000);
                    Thread.sleep(round);
                    System.out.println(round + &quot;号商品生产完毕，还有&quot; + count + &quot;个商品&quot;);
                    condition_consume.signalAll();
                } catch (Exception e) {
                    e.printStackTrace();
                }

            } finally {
                lock.unlock();
            }
        }
    }

    public void consume() {
        while (flag) {
            try {
                lock.lock();
                try {
                    while (count == 0) {
                        condition_consume.await();
                    }
                    count--;
                    Thread.sleep(500);
                    System.out.println(&quot;取走一个商品，还有&quot; + count + &quot;个商品&quot;);
                    condition_prod.signalAll();
                } catch (Exception e) {
                    e.printStackTrace();
                }
            } finally {
                lock.unlock();
            }
        }
    }
}
</code></pre>
<h5 id="代码示例reentrantlock实现精准唤醒">代码示例:ReentrantLock实现精准唤醒</h5>
<pre><code class="language-java">import java.util.concurrent.locks.Condition;
import java.util.concurrent.locks.Lock;
import java.util.concurrent.locks.ReentrantLock;

public class PrecisionWeakUp_ReentrantLock {
    private final Lock lock = new ReentrantLock();
    private Condition conditionA = lock.newCondition();
    private Condition conditionB = lock.newCondition();
    private Condition conditionC = lock.newCondition();
    private int flag = 1;

    // 多线程下先输出五次A 再输出五次B 再输出五次C
    public static void main(String[] args) {
        PrecisionWeakUp_ReentrantLock precisionWeakUp_reentrantLock = new PrecisionWeakUp_ReentrantLock();
        for(int i = 0;i &lt; 3;i++) {
            new Thread(new Runnable() {
                @Override
                public void run() {
                    try {
                        precisionWeakUp_reentrantLock.printA();
                    } catch (InterruptedException e) {
                        e.printStackTrace();
                    }
                }
            }).start();
        }

        for(int i = 0;i &lt; 3;i++) {
            new Thread(new Runnable() {
                @Override
                public void run() {
                    try {
                        precisionWeakUp_reentrantLock.printB();
                    } catch (InterruptedException e) {
                        e.printStackTrace();
                    }
                }
            }).start();
        }

        for(int i = 0;i &lt; 3;i++) {
            new Thread(new Runnable() {
                @Override
                public void run() {
                    try {
                        precisionWeakUp_reentrantLock.printC();
                    } catch (InterruptedException e) {
                        e.printStackTrace();
                    }
                }
            }).start();
        }

    }

    public void printA() throws InterruptedException {
        try {
            lock.lock();
            while (flag != 1) {
                conditionA.await();
            }
            for (int i = 0; i &lt; 5; i++) {
                System.out.println(&quot;A&quot;);
            }
            flag = 2;
            conditionB.signalAll();
        }finally {
            lock.unlock();
        }
    }
    public void printB() throws InterruptedException {
        try {
            lock.lock();
            while (flag != 2) {
                conditionB.await();
            }
            for (int i = 0; i &lt; 5; i++) {
                System.out.println(&quot;B&quot;);
            }
            flag = 3;
            conditionC.signalAll();
        }finally {
            lock.unlock();
        }
    }
    public void printC() throws InterruptedException {
        try {
            lock.lock();
            while (flag != 3) {
                conditionC.await();
            }
            for (int i = 0; i &lt; 5; i++) {
                System.out.println(&quot;C&quot;);
            }
            flag = 1;
            conditionA.signalAll();
        }finally {
            lock.unlock();
        }
    }
}
</code></pre>
<h2 id="juc包的并发工具类">JUC包的并发工具类</h2>
<h3 id="countdownlatch">CountDownLatch</h3>
<blockquote>
<p>CountDownLatch中count down是倒数的意思，latch则是门闩的含义。整体含义可以理解为倒数的门栓。在构造CountDownLatch的时候需要传入一个整数n，在这个整数“倒数”到0之前，主线程需要等待在门口，而这个“倒数”过程则是由各个执行线程驱动的，每个线程执行完一个任务“倒数”一次。总结来说，CountDownLatch的作用就是等待其他的线程都执行完任务，必要时可以对各个任务的执行结果进行汇总，然后主线程才继续往下执行。</p>
</blockquote>
<h4 id="countdownlatch主要有两个方法countdown和await">CountDownLatch主要有两个方法：countDown()和await()。</h4>
<ul>
<li>countDown()方法用于使计数器减一，其一般是执行任务的线程调用，</li>
<li>await()方法则使调用该方法的线程处于等待状态，其一般是主线程调用。</li>
</ul>
<p>这里需要注意的是，countDown()方法并没有规定一个线程只能调用一次，当同一个线程调用多次countDown()方法时，每次都会使计数器减一；另外，await()方法也并没有规定只能有一个线程执行该方法，如果多个线程同时执行await()方法，那么这几个线程都将处于等待状态，并且以共享模式享有同一个锁。</p>
<h5 id="代码示例-7">代码示例</h5>
<pre><code class="language-java">import java.util.ArrayList;
import java.util.Collections;
import java.util.List;
import java.util.concurrent.CountDownLatch;
import java.util.concurrent.TimeUnit;

public class CountDownLatchDemo {
    public static void main(String[] args) {
        List list = new ArrayList();
        List synchronizedList = Collections.synchronizedList(list);
        CountDownLatch countDownLatch = new CountDownLatch(5);
        for(int i = 0;i &lt; 5;i++){
            new Thread(new Runnable() {
                @Override
                public void run() {
                    try {
                        TimeUnit.SECONDS.sleep(1);
                    } catch (InterruptedException e) {
                        e.printStackTrace();
                    }
                    long round = Math.round(Math.random() * 100);
                    synchronizedList.add(round);
                    System.out.println(round + &quot;添加进List&quot;);
                    countDownLatch.countDown();

                }
            }).start();
        }

        try {
            countDownLatch.await();
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
        System.out.println(synchronizedList);
    }
}

输出结果

68添加进List
91添加进List
57添加进List
12添加进List
98添加进List
[68, 57, 12, 98, 91]
</code></pre>
<p>CountDownLatch非常适合于对任务进行拆分，使其并行执行，比如某个任务执行2s，其对数据的请求可以分为五个部分，那么就可以将这个任务拆分为5个子任务，分别交由五个线程执行，执行完成之后再由主线程进行汇总，此时，总的执行时间将决定于执行最慢的任务，平均来看，还是大大减少了总的执行时间。</p>
<h3 id="cyclicbarrier">CyclicBarrier</h3>
<blockquote>
<p>CyclicBarrier同步屏障，可以让一组线程达到一个屏障时被阻塞，直到最后一个线程达到屏障时，所以被阻塞的线程才能继续执行。<br>
CyclicBarrier好比一扇门，默认情况下关闭状态，堵住了线程执行的道路，直到所有线程都就位，门才打开，让所有线程一起通过。</p>
</blockquote>
<h4 id="cyclicbarrier的构造方法">CyclicBarrier的构造方法</h4>
<ul>
<li>CyclicBarrier(int parties)：创建一个新的 CyclicBarrier，它将在给定数量的参与者（线程）处于等待状态时启动，但它不会在启动 barrier 时执行预定义的操作。</li>
<li>CyclicBarrier(int parties, Runnable barrierAction) ：创建一个新的 CyclicBarrier，它将在给定数量的参与者（线程）处于等待状态时启动，并在启动 barrier 时执行给定的屏障操作，该操作由最后一个进入 barrier 的线程执行。</li>
</ul>
<h5 id="代码示例-8">代码示例</h5>
<pre><code class="language-java">import java.util.concurrent.BrokenBarrierException;
        import java.util.concurrent.CyclicBarrier;

public class CyclicBarrierDemo {
    public static void main(String[] args) {
        //景区观光车循环发车，每一辆车一个五个座位，坐满发车
        CyclicBarrier cyclicBarrier = new CyclicBarrier(5, new Runnable() {
            @Override
            public void run() {
                System.out.println(&quot;人员已到位，出发&quot;);
            }
        });

        for(int i = 1;i &lt;= 5;i++){
            final int n = i;
            new Thread(new Runnable() {
                @Override
                public void run() {
                    System.out.println(n + &quot;号游客上车&quot;);
                    try {
                        cyclicBarrier.await();
                    } catch (InterruptedException e) {
                        e.printStackTrace();
                    } catch (BrokenBarrierException e) {
                        e.printStackTrace();
                    }
                }
            }).start();
        }

        for(int i = 6;i &lt;= 10;i++){
            final int n = i;
            new Thread(new Runnable() {
                @Override
                public void run() {
                    System.out.println(n + &quot;号游客上车&quot;);
                    try {
                        cyclicBarrier.await();
                    } catch (InterruptedException e) {
                        e.printStackTrace();
                    } catch (BrokenBarrierException e) {
                        e.printStackTrace();
                    }
                }
            }).start();
        }
    }
}
</code></pre>
<p>输出结果</p>
<pre><code>1号游客上车
3号游客上车
2号游客上车
5号游客上车
4号游客上车
人员已到位，出发
6号游客上车
7号游客上车
8号游客上车
9号游客上车
10号游客上车
人员已到位，出发
</code></pre>
<p>每当线程执行await，内部变量count减1，如果count！= 0，说明有线程还未到屏障处，则在锁条件变量trip上等待。<br>
当count == 0时，说明所有线程都已经到屏障处，执行条件变量的signalAll方法唤醒等待的线程。</p>
<h3 id="countdownlatch与cyclicbarrier比较">CountDownLatch与CyclicBarrier比较</h3>
<table>
<thead>
<tr>
<th>CountDownLatch</th>
<th>CyclicBarrier</th>
</tr>
</thead>
<tbody>
<tr>
<td>减计数方式</td>
<td>加计数方式</td>
</tr>
<tr>
<td>计算为0时释放所有等待的线程</td>
<td>计数达到指定值时释放所有等待线程</td>
</tr>
<tr>
<td>计数为0时，无法重置</td>
<td>计数达到指定值时，计数置为0重新开始</td>
</tr>
<tr>
<td>调用countDown()方法计数减一，调用await()方法只进行阻塞，对计数没任何影响</td>
<td>调用await()方法计数加1，若加1后的值不等于构造方法的值，则线程阻塞</td>
</tr>
<tr>
<td>不可重复利用可重复利用</td>
<td></td>
</tr>
</tbody>
</table>
<h3 id="semaphore">Semaphore</h3>
<blockquote>
<p>ReentrantLock和Synchronized一次都只允许一个线程访问一个资源。Semaphore允许多个线程同时访问同一个资源。<br>
Semaphore管理着一组许可（permit），许可的初始数量可以通过构造函数设定，操作时首先要获取到许可，才能进行操作，操作完成后需要释放许可。如果没有获取许可，则阻塞到有许可被释放。如果初始化了一个许可为1的Semaphore，那么就相当于一个不可重入的互斥锁。其中0、1就相当于它的状态，当=1时表示其他线程可以获取，当=0时，排他，即其他线程必须要等待。</p>
</blockquote>
<h4 id="semaphore的构造方法">Semaphore的构造方法</h4>
<ul>
<li>Semaphore(int permits) ：创建具有给定的许可数和非公平的公平设置的 Semaphore，默认非公平锁。</li>
<li>Semaphore(int permits, boolean fair) ：创建具有给定的许可数和给定的公平设置的 Semaphore。</li>
</ul>
<h5 id="代码示例-9">代码示例</h5>
<pre><code class="language-java">import java.util.concurrent.Semaphore;
import java.util.concurrent.TimeUnit;

public class SemaphoreDemo {
    public static void main(String[] args) {
        // 六个车抢三个车位
        Semaphore semaphore = new Semaphore(3);
        for(int i = 1;i &lt;= 6;i++){
            final int n = i;
            new Thread(new Runnable() {
                @Override
                public void run() {
                    try {
                        semaphore.acquire();
                        System.out.println(n + &quot;号抢到车位——————————&quot;);
                        TimeUnit.SECONDS.sleep(2);
                    } catch (InterruptedException e) {
                        e.printStackTrace();
                    }finally {
                        System.out.println(n + &quot;号离开车位++++++++++&quot;);
                        semaphore.release();
                    }
                }
            }).start();
        }
    }
}
</code></pre>
<p>输出结果</p>
<pre><code>1号抢到车位——————————
2号抢到车位——————————
3号抢到车位——————————
2号离开车位++++++++++
1号离开车位++++++++++
3号离开车位++++++++++
4号抢到车位——————————
6号抢到车位——————————
5号抢到车位——————————
6号离开车位++++++++++
4号离开车位++++++++++
5号离开车位++++++++++
</code></pre>
<p>Semaphore在限制流量方面有非常多的应用，比如程序跑批高峰时几万个数据库的连接同时操作，为了不影响其他用户访问只允许同时开放十条连接。</p>
<h2 id="线程安全的集合类">线程安全的集合类</h2>
<blockquote>
<p>Java中的集合包括三大类，它们是Set、List和Map它们都处于java.util包中，Set、List和Map都是接口，它们有各自的实现类。</p>
</blockquote>
<h3 id="list列表">List（列表）</h3>
<blockquote>
<ul>
<li>实现类主要有ArrayList，LinkedList，Vector</li>
</ul>
</blockquote>
<blockquote>
<p>ArrayList,LinkedList为线程不安全的集合类，ArrayList底层是数组而LinkedList底层实现为链表。Vector和ArrayList类似，是长度可变的数组。Vector是线程安全的，它给几乎所有的public方法都加上了synchronized关键字。由于加锁导致性能降低，在不需要并发访问同一对象时，这种强制性的同步机制就显得多余，所以现在Vector已被弃用。</p>
</blockquote>
<h3 id="set集">Set（集）</h3>
<blockquote>
<ul>
<li>实现类主要有HashSet，TreeSet</li>
</ul>
</blockquote>
<blockquote>
<p>HashSet是一个无序的集合，基于HashMap实现；TreeSet是一个有序的集合，基于TreeMap实现。HashSet集合中允许有null元素，TreeSet集合中不允许有null元素。HashSet和TreeSet都是线程不安全的。</p>
</blockquote>
<h3 id="map映射">Map（映射）</h3>
<blockquote>
<ul>
<li>实现类主要有HashMap，TreeMap，HashTable</li>
</ul>
</blockquote>
<blockquote>
<p>HashTable和HashMap类似，不同点是HashTable是线程安全的，它给几乎所有public方法都加上了synchronized关键字，还有一个不同点是HashTable的K，V都不能是null，但HashMap可以，它现在也因为性能原因被弃用。TreeMap也是线程不安全的。</p>
</blockquote>
<h3 id="除废弃的集合类外还有哪些方法可以保证线程安全">除废弃的集合类外还有哪些方法可以保证线程安全</h3>
<h4 id="collections包装方法">Collections包装方法</h4>
<ul>
<li>Collections工具类中提供了相应的包装方法把它们包装成线程安全的集合</li>
</ul>
<pre><code>List&lt;E&gt; synArrayList = Collections.synchronizedList(new ArrayList&lt;E&gt;());
Set&lt;E&gt; synHashSet = Collections.synchronizedSet(new HashSet&lt;E&gt;());
Map&lt;K,V&gt; synHashMap = Collections.synchronizedMap(new HashMap&lt;K,V&gt;());
</code></pre>
<h4 id="javautilconcurrent包中的集合">java.util.concurrent包中的集合</h4>
<h5 id="copyonwritearraylist和copyonwritearrayset">CopyOnWriteArrayList和CopyOnWriteArraySet</h5>
<ul>
<li>CopyOnWriteArrayList 中的set、add、remove等方法，都使用了ReentrantLock的lock来加锁， unlock来解锁当增加元素的时候使用Arrays.copyOf()来拷贝副本，在副本上增加元素，然后改变原来引用的指向副本。读操作不需要加锁，因此，CopyOnWriteArrayList类是一个线程安全的List接口实现，这对于读操作远远多于写操作的应用非常适合，特别是在并发的情况下，可以提供高性能的并发读取，并保证读取的内容一定是正确的，不受多线程并发问题的影响。</li>
</ul>
<h5 id="concurrenthashmap">ConcurrentHashMap</h5>
<ul>
<li>1.8版本的ConcurrentHashMap抛弃了原有的 Segment 分段锁，而采用了 CAS + synchronized 来保证并发安全性。详情见HashMap? ConcurrentHashMap? 相信看完这篇没人能难住你！</li>
</ul>
<h4 id="copyonwrite机制">CopyOnWrite机制</h4>
<ul>
<li>CopyOnWrite容器即写是复制的容器。通俗的理解就是当我们往一个容器添加元素的时候，不直接往当前容器添加，而是先将当前容器进行Copy，复制出一个新的容器，然后新的容器里添加元素，添加完元素后，再将原容器的引用指向新的容器。这样做的好处就是我们可以对CopyOnWrite容器进行并发的读，而不需要加锁，因为当前容器不会添加任何元素.所以，CopyOnWrite容器也是一种读写分离的思想。读和写不容的容器。</li>
<li>ArrayList里添加元素，在添加的时候是需要加锁的，否则多线程写的时候会copy出多个副本出来<br>
读的时候不需要加锁，如果读的时候有多线程正在像ArrayList中添加数据，还是会读到旧的数据，因为写的时候不会锁住旧的ArrayList</li>
</ul>
<h5 id="使用场景">使用场景</h5>
<ul>
<li>读多写少</li>
</ul>
<h5 id="使用注意点">使用注意点</h5>
<ul>
<li>减少扩容开销；b、使用批量添加</li>
</ul>
<h5 id="缺点">缺点</h5>
<ul>
<li>内存占用问题</li>
<li>数据一致性问题</li>
</ul>
<h2 id="blockingqueue阻塞队列">BlockingQueue（阻塞队列）</h2>
<blockquote>
<p>在某些情况下对阻塞队列的访问可能会造成阻塞。被阻塞的情况主要有如下两种:</p>
</blockquote>
<ul>
<li>当阻塞队列是空时，从队列中获取元素的操作将会被阻塞。</li>
<li>当阻塞队列是满时，往队列里添加元素的操作将会被阻塞。</li>
<li>当一个线程对已经满了的阻塞队列进行入队操作时会阻塞，除非有另外一个线程进行了出队操作，当一个线程对一个空的阻塞队列进行出队操作时也会阻塞，除非有另外一个线程进行了入队操作。</li>
</ul>
<h3 id="blockingqueue的七个实现类">BlockingQueue的七个实现类</h3>
<ul>
<li>ArrayBlockingQueue ：一个由数组结构组成的有界阻塞队列。</li>
<li>LinkedBlockingQueue ：一个由链表结构组成的有界阻塞队列。</li>
<li>PriorityBlockingQueue ：一个支持优先级排序的无界阻塞队列。</li>
<li>DelayQueue：一个使用优先级队列实现的无界阻塞队列。</li>
<li>SynchronousQueue：一个不存储元素的阻塞队列。</li>
<li>LinkedTransferQueue：一个由链表结构组成的无界阻塞队列。</li>
<li>LinkedBlockingDeque：一个由链表结构组成的双向阻塞队列。</li>
</ul>
<h3 id="blockingqueue阻塞队列的api">BlockingQueue阻塞队列的api</h3>
<p>|操作|抛异常 ThrowsException|特定值 SpecialValue|阻塞 Blocks|超时 TimesOut|<br>
|-|-|-|-|<br>
|插入|add(o)	|offer(o)|put(o)|offer(o, timeout, timeunit)|<br>
|移除|remove(o)|poll(o)|take(o)|poll(timeout, timeunit)|<br>
|检查|	element(o)|	peek(o)	|</p>
<h4 id="这四类方法分别对应的是">这四类方法分别对应的是：</h4>
<ul>
<li>ThrowsException ：如果操作不能马上进行，则抛出异常</li>
<li>SpecialValue ：如果操作不能马上进行，将会返回一个特殊的值，一般是true或者false</li>
<li>Blocks : 如果操作不能马上进行，操作会被阻塞</li>
<li>TimesOut : 如果操作不能马上进行，操作会被阻塞指定的时间，如果指定时间没执行，则返回一个特殊值，一般是true或者false</li>
</ul>
<h5 id="插入方法">插入方法</h5>
<p>add(E e)：添加成功返回true，失败抛 IllegalStateException 异常<br>
offer(E e)：成功返回 true，如果此队列已满，则返回 false<br>
put(E e)：将元素插入此队列的尾部，如果该队列已满，则一直阻塞</p>
<h5 id="删除方法">删除方法</h5>
<p>remove(Object o) ：移除指定元素,成功返回true，失败返回false<br>
poll()：获取并移除此队列的头元素，若队列为空，则返回 null<br>
take()：获取并移除此队列头元素，若没有元素则一直阻塞</p>
<h5 id="检查方法">检查方法</h5>
<p>element() ：获取但不移除此队列的头元素，没有元素则抛异常<br>
peek() :获取但不移除此队列的头；若队列为空，则返回 null</p>
<h4 id="blockingqueue实现生产消费模型">BlockingQueue实现生产消费模型</h4>
<h5 id="代码示例-10">代码示例</h5>
<pre><code class="language-java">import java.util.concurrent.ArrayBlockingQueue;
import java.util.concurrent.BlockingQueue;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicInteger;

public class ProdConsume_BlockingQueue {

    private AtomicInteger atomicInteger = new AtomicInteger();
    private BlockingQueue blockingQueue;
    private volatile boolean flag = true;


    public ProdConsume_BlockingQueue(BlockingQueue blockingQueue) {
        this.blockingQueue = blockingQueue;
    }

    public void prod() {
        while (flag) {
            try {
                long round = Math.round(Math.random() * 1000);
                Thread.sleep(round);
                blockingQueue.put(round);
                int i = atomicInteger.incrementAndGet();
                System.out.println(round + &quot;号商品生产完毕放入队列，队列中还有&quot; + i + &quot;个商品&quot;);
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        }
    }

    public void consum() {
        while (flag) {
            try {
                Thread.sleep(500);
                Object take = blockingQueue.take();
                atomicInteger.decrementAndGet();
                System.out.println(take + &quot;号商品被购买&quot;);
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        }
    }

    public static void main(String[] args) {
        BlockingQueue blockingQueue = new ArrayBlockingQueue(100);
        ProdConsume_BlockingQueue prodConsume_blockingQueue = new ProdConsume_BlockingQueue(blockingQueue);

        new Thread(new Runnable() {
            @Override
            public void run() {
                prodConsume_blockingQueue.prod();
            }
        }).start();


        new Thread(new Runnable() {
            @Override
            public void run() {
                prodConsume_blockingQueue.consum();
            }
        }).start();

        try {
            TimeUnit.SECONDS.sleep(10);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
        prodConsume_blockingQueue.flag = false;
    }
}
输出结果
</code></pre>
<pre><code>180号商品生产完毕放入队列，队列中还有1个商品
180号商品被购买
331号商品生产完毕放入队列，队列中还有1个商品
201号商品生产完毕放入队列，队列中还有2个商品
331号商品被购买
201号商品被购买
897号商品生产完毕放入队列，队列中还有1个商品
897号商品被购买
588号商品生产完毕放入队列，队列中还有1个商品
217号商品生产完毕放入队列，队列中还有2个商品
588号商品被购买
154号商品生产完毕放入队列，队列中还有2个商品
217号商品被购买
592号商品生产完毕放入队列，队列中还有2个商品
154号商品被购买
442号商品生产完毕放入队列，队列中还有2个商品
592号商品被购买
712号商品生产完毕放入队列，队列中还有2个商品
442号商品被购买
712号商品被购买
893号商品生产完毕放入队列，队列中还有1个商品
15号商品生产完毕放入队列，队列中还有2个商品
893号商品被购买
496号商品生产完毕放入队列，队列中还有2个商品
4号商品生产完毕放入队列，队列中还有3个商品
15号商品被购买
534号商品生产完毕放入队列，队列中还有3个商品
172号商品生产完毕放入队列，队列中还有4个商品
496号商品被购买
4号商品被购买
891号商品生产完毕放入队列，队列中还有3个商品
534号商品被购买
414号商品生产完毕放入队列，队列中还有3个商品
172号商品被购买
891号商品被购买
920号商品生产完毕放入队列，队列中还有2个商品
71号商品生产完毕放入队列，队列中还有3个商品
144号商品生产完毕放入队列，队列中还有4个商品
414号商品被购买
586号商品生产完毕放入队列，队列中还有4个商品
920号商品被购买
71号商品被购买
553号商品生产完毕放入队列，队列中还有3个商品
</code></pre>
<h2 id="实现多线程的几种方式">实现多线程的几种方式</h2>
<h3 id="继承thread类重写run方法">继承Thread类，重写run方法</h3>
<p>略</p>
<h3 id="实现runnable接口重写run方法">实现Runnable接口，重写run方法</h3>
<p>略</p>
<h3 id="实现callable接口重写call方法通过futuretask包装器来创建thread线程">实现Callable接口，重写call方法，通过FutureTask包装器来创建Thread线程</h3>
<h4 id="runnable和callable的区别">Runnable和Callable的区别：</h4>
<ul>
<li>Callable规定的方法是call(),Runnable规定的方法是run().</li>
<li>Callable的任务执行后可返回值，而Runnable的任务是不能返回值得</li>
<li>call方法可以抛出异常，run方法不可以</li>
</ul>
<p>运行Callable任务可以拿到一个Future对象，表示异步计算的结果。它提供了检查计算是否完成的方法，以等待计算的完成，并检索计算的结果。通过Future对象可以了解任务执行情况，可取消任务的执行，还可获取执行结果。</p>
<h4 id="future接口">Future接口</h4>
<ul>
<li>Future是一个接口，代表了一个异步计算的结果。接口中的方法用来检查计算是否完成、等待完成和得到计算的结果。</li>
<li>当计算完成后，只能通过get()方法得到结果，get方法会阻塞直到结果准备好了。</li>
<li>如果想取消，那么调用cancel()方法。其他方法用于确定任务是正常完成还是取消了。一旦计算完成了，那么这个计算就不能被取消。</li>
</ul>
<h4 id="futuretask类">FutureTask类</h4>
<ul>
<li>FutureTask类实现了RunnableFuture接口，而RunnnableFuture接口继承了Runnable和Future接口，所以说FutureTask是一个提供异步计算的结果的任务。</li>
<li>FutureTask可以用来包装Callable或者Runnbale对象。因为FutureTask实现了Runnable接口，所以FutureTask也可以被提交给Executor。</li>
</ul>
<h4 id="callable两种执行方式">Callable两种执行方式</h4>
<h5 id="借助futuretask执行">借助FutureTask执行</h5>
<p>FutureTask类同时实现了两个接口，Future和Runnable接口，所以它既可以作为Runnable被线程执行，又可以作为Future得到Callable的返回值。<br>
** 代码示例 **</p>
<pre><code class="language-java">import java.util.concurrent.Callable;
import java.util.concurrent.ExecutionException;
import java.util.concurrent.FutureTask;

public class CallableDemo {
    public static void main(String[] args) {
        FutureTask&lt;Integer&gt; futureTask = new FutureTask&lt;&gt;(new Callable&lt;Integer&gt;() {
            @Override
            public Integer call() throws Exception {
                System.out.println(&quot;Callable&quot;);
                Thread.sleep(1000);
                return (int)(Math.random()*100);
            }
        });
        futureTask.run();
        //如果没有执行完一直阻塞
        while (!futureTask.isDone()){
        }
        Integer integer = null;
        try {
            integer = futureTask.get();
        } catch (InterruptedException e) {
            e.printStackTrace();
        } catch (ExecutionException e) {
            e.printStackTrace();
        }
        System.out.println(integer);
    }
}
</code></pre>
<h5 id="借助线程池来运行">借助线程池来运行</h5>
<p>↓</p>
<h3 id="线程池threadpoolexecuter">线程池ThreadPoolExecuter</h3>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[JVM上篇]]></title>
        <id>https://EastBeforeDawn.github.io/post/jvmPart1/</id>
        <link href="https://EastBeforeDawn.github.io/post/jvmPart1/">
        </link>
        <updated>2020-06-11T13:42:17.000Z</updated>
        <content type="html"><![CDATA[<h2 id="jvm内存结构概述">JVM内存结构概述</h2>
<h3 id="整体结构图">整体结构图</h3>
<figure data-type="image" tabindex="1"><img src="https://EastBeforeDawn.github.io/post-images/1591883345936.png" alt="" loading="lazy"></figure>
<h3 id="类加载器和加载过程概述">类加载器和加载过程概述</h3>
<h4 id="类加载器概念">类加载器概念</h4>
<blockquote>
<p>Java虚拟机把描述类的数据从Class文件加载到内存，并对数据进行校验、转换解析和初始化，最终形成可以被虚拟机直接使用的Java类型，这就是虚拟机的加载机制。Class文件由类装载器装载后，在JVM中将形成一份描述Class结构的元信息对象，通过该元信息对象可以获知Class的结构信息：如构造函数，属性和方法等，Java允许用户借由这个Class相关的元信息对象间接调用Class对象的功能,这里就是我们经常能见到的Class类。</p>
</blockquote>
<h4 id="类加载子系统作用">类加载子系统作用</h4>
<ul>
<li>类加载子系统负责从文件系统或者网络中加载class文件，class文件在文件开头有特定的文件标识- （0xCAFEBABE）</li>
<li>ClassLoader只负责class文件的加载。至于它是否可以运行，则由Execution Engine决定</li>
<li>加载的类信息存放于一块称为方法区的内存空间。除了类的信息外，方法区中还存放运行时常量池信息，可能还包括字符串字面量和数字常量（这部分常量信息是class文件中常量池部分的内存映射）</li>
<li>Class对象是存放在堆区的</li>
</ul>
<h4 id="类加载器classloader角色">类加载器ClassLoader角色</h4>
<ul>
<li>class file存在于本地硬盘上，可以理解为设计师画在纸上的模板，而最终这个模板在执行的时候是要加载到JVM当中来根据这个文件实例化出n个一模一样的实例</li>
<li>class file加载到JVM中，被称为DNA元数据模板，放在方法区</li>
<li>在.calss文件 -&gt; JVM -&gt; 最终成为元数据模板，此过程就要一个运输工具（类装载器），扮演一个快递员的角色</li>
</ul>
<h3 id="类加载过程">类加载过程</h3>
<blockquote>
<p>类从被加载到虚拟机内存中开始，到卸载出内存为止，它的整个生命周期包括：加载、验证、准备、解析、初始化、使用和卸载七个阶段。(验证、准备和解析又统称为连接，为了支持Java语言的运行时绑定，所以解析阶段也可以是在初始化之后进行的。以上顺序都只是说开始的顺序，实际过程中是交叉的混合式进行的，加载过程中可能就已经开始验证了)<br>
<img src="https://EastBeforeDawn.github.io/post-images/1591883779566.png" alt="" loading="lazy"></p>
</blockquote>
<h4 id="一-加载loading">一. 加载（Loading）：</h4>
<ul>
<li>通过一个类的全限定名获取定义此类的二进制字节流</li>
<li>将这个字节流所代表的的静态存储结构转化为方法区的运行时数据结构</li>
<li>在内存中生成一个代表这个类的 java.lang.Class 对象，作为方法区这个类的各种数据的访问入口</li>
</ul>
<h5 id="加载-calss-文件的方式">加载 .calss 文件的方式</h5>
<ul>
<li>从本地系统中直接加载</li>
<li>通过网络获取，典型场景：Web Applet</li>
<li>从zip压缩文件中读取，成为日后jar、war格式的基础</li>
<li>运行时计算生成，使用最多的是：动态代理技术</li>
<li>由其他文件生成，比如 JSP 应用</li>
<li>从专有数据库提取.class 文件，比较少见</li>
<li>从加密文件中获取，典型的防 Class 文件被反编译的保护措施</li>
</ul>
<h4 id="二-连接linking">二. 连接（Linking）</h4>
<h5 id="1验证verify">1.验证（Verify）</h5>
<ul>
<li>目的在于确保Class文件的字节流中包含信息符合当前虚拟机要求，保证被加载类的正确性，不会危害虚拟机自身安全</li>
<li>主要包括四种验证，文件格式验证，元数据验证，字节码验证，符号引用验证</li>
</ul>
<h5 id="2准备prepare">2.准备（Prepare）</h5>
<ul>
<li>为类变量分配内存并且设置该类变量的默认初始值，即零值</li>
<li>这里不包含用final修饰的static，因为final在编译的时候就会分配了，准备阶段会显示初始化</li>
<li><code>这里不会为实例变量分配初始化</code>，类变量会分配在方法区中，而实例变量是会随着对象一起分配到Java堆中</li>
</ul>
<pre><code class="language-java">private static int i = 1;  //变量i在准备阶只会被赋值为0，初始化时才会被赋值为1
private final static int j = 2;  //这里被final修饰的变量j，直接成为常量，编译时就会被分配为2
</code></pre>
<table>
<thead>
<tr>
<th>数据类型</th>
<th>int</th>
<th>long</th>
<th>short</th>
<th>char</th>
<th>byte</th>
<th>boolean</th>
<th>float</th>
<th>double</th>
<th>reference</th>
</tr>
</thead>
<tbody>
<tr>
<td>零值</td>
<td>0</td>
<td>0L</td>
<td>(short)0</td>
<td>'\u0000'</td>
<td>(byte)0</td>
<td>false</td>
<td>0.0f</td>
<td>0.0d</td>
<td>null</td>
</tr>
</tbody>
</table>
<h5 id="3解析resolve">3.解析（Resolve）</h5>
<ul>
<li>将常量池内的符号引用转换为直接引用的过程</li>
<li>事实上，解析操作往往会伴随着JVM在执行完初始化之后再执行</li>
<li>符号引用就是一组符号来描述所引用的目标。符号引用的字面量形式明确定义在《Java虚拟机规范》的Class文件格式中。直接引用就是直接指向目标的指针、相对偏移量或一个间接定位到目标的句柄</li>
<li>解析动作主要针对类或接口、字段、类方法、接口方法、方法类型等。对应常量池中的CONSTANT_Class_info、CONSTANT_Fieldref_info、CONSTANT_Methodref_info等</li>
</ul>
<h4 id="三-初始化initialization">三. 初始化（Initialization）</h4>
<ul>
<li><code>初始化阶段就是执行类构造器方法</code>&lt;clinit&gt;()<code>的过程</code></li>
<li>此方法不需要定义，是javac编译器自动收集类中的所有类变量的赋值动作和静态代码块中的语句合并而来</li>
<li>构造器方法中指令按语句在源文件中出现的<code>顺序执行</code></li>
<li>&lt;clinit&gt;()不同于类的构造器（构造器是虚拟机视角下的&lt;linit&gt;）</li>
<li>若该类具有父类，JVM会保证子类的&lt;clinit&gt;()执行前，父类的&lt;clinit&gt;()已经执行完毕</li>
<li>虚拟机必须保证一个类的&lt;clinit&gt;()方法在多线程下被同步加锁</li>
</ul>
<h5 id="顺序执行的字节码文件示例">顺序执行的字节码文件示例</h5>
<pre><code>package com.atguigu;

public class ClazzInit {
    public static int mun = 1;
    static {
        mun = 2;
        number = 10;
    }
    public static int number = 20;

    public static void main(String[] args) {

    }
}
</code></pre>
<p><strong>clint字节码文件</strong></p>
<pre><code class="language-tex"> 0 iconst_1
 1 putstatic #2 &lt;com/atguigu/ClazzInit.mun&gt;
 4 iconst_2
 5 putstatic #2 &lt;com/atguigu/ClazzInit.mun&gt;
 8 bipush 10
10 putstatic #3 &lt;com/atguigu/ClazzInit.number&gt;
13 bipush 20
15 putstatic #3 &lt;com/atguigu/ClazzInit.number&gt;
18 return
</code></pre>
<p>可以明显看出number先赋值为10，在赋值为20</p>
<h5 id="代码错误示例">代码错误示例</h5>
<pre><code>package com.atguigu;

public class ClazzInit {
    public static int mun = 1;
    static {
        mun = 2;
        number = 10;
        System.out.println(number); //非法的前向引用
    }
    public static int number = 20;

    public static void main(String[] args) {

    }
}
</code></pre>
<h5 id="注意事项">注意事项</h5>
<ul>
<li>如果一个类没有静态变量或者静态代码块，这个类不会生成&lt;clinit&gt;()方法</li>
</ul>
<pre><code>package com.atguigu;

public class ClazzInit {
    public  int mun = 1;
    public static void main(String[] args) {

    }
}
</code></pre>
<p><strong>字节码文件截图</strong><br>
<img src="https://EastBeforeDawn.github.io/post-images/1591884212469.png" alt="" loading="lazy"></p>
<h5 id="多线程类加载加锁示例">多线程类加载加锁示例</h5>
<pre><code>package com.atguigu;

public class ClazzInit {
    static class DeadClazz{
        static {
            if(true) {
                System.out.println(Thread.currentThread().getName() + &quot;DeadClazz类正在加载&quot;);
                while (true) {

                }
            }
        }
    }
    public static void main(String[] args) {
        Runnable runnable = () -&gt; {
            DeadClazz deadClazz = new DeadClazz();
        };
        Thread t1 = new Thread(runnable);
        Thread t2 = new Thread(runnable);
        t1.start();
        t2.start();
    }
}
</code></pre>
<p>会输出一个线程正在加载，另外一个线程一直等待</p>
<h3 id="类加载器">类加载器</h3>
<blockquote>
<ul>
<li>JVM支持两种类型的类加载器，分别为引导类加载器（Bootstrap ClassLoader）和自定义类加载器（User-Defined ClassLoader）</li>
<li>从概念上来讲，自定义类加载器一般指的是程序中由开发人员自定义的一类类加载器，但是Java虚拟机规范却没有这么定义，而是将**<code>所有派生于抽象类ClassLoader的类加载器都划分为自定义类加载器</code>**</li>
</ul>
</blockquote>
<p><code>注意:下图中三个已经实现的加载器不是继承关系</code><br>
<img src="https://EastBeforeDawn.github.io/post-images/1591884228613.png" alt="" loading="lazy"></p>
<h4 id="启动类加载器引导类加载器bootstrap-classloader">启动类加载器（引导类加载器，Bootstrap ClassLoader）</h4>
<ul>
<li>这个类加载使用C/C++ 语言实现，嵌套在JVM 内部</li>
<li>它用来加载Java的核心库（JAVA_HOME/jre/lib/rt.jar、resource.jar或sun.boot.class.path路径下的内容），用于提供JVM自身需要的类</li>
<li>并不继承自 java.lang.ClassLoader，没有父加载器</li>
<li>加载扩展类和应用程序类加载器，并指定为他们的父类加载器</li>
<li>出于安全考虑，Boostrap 启动类加载器只加载名为java、Javax、sun等开头的类</li>
</ul>
<h4 id="扩展类加载器extension-classloader">扩展类加载器（Extension ClassLoader）</h4>
<ul>
<li>java语言编写，由sun.misc.Launcher$ExtClassLoader实现</li>
<li>派生于 ClassLoader</li>
<li>父类加载器为启动类加载器</li>
<li>从java.ext.dirs系统属性所指定的目录中加载类库，或从JDK的安装目录的jre/lib/ext 子目录（扩展目录）下加载类库。如果用户创建的JAR 放在此目录下，也会自动由扩展类加载器加载</li>
</ul>
<h4 id="应用程序类加载器也叫系统类加载器appclassloader">应用程序类加载器（也叫系统类加载器，AppClassLoader）</h4>
<ul>
<li>java语言编写，由 sun.misc.Lanucher$AppClassLoader 实现</li>
<li>派生于 ClassLoader</li>
<li>父类加载器为扩展类加载器</li>
<li>它负责加载环境变量classpath或系统属性java.class.path 指定路径下的类库</li>
<li>该类加载是程序中默认的类加载器，一般来说，Java应用的类都是由它来完成加载的</li>
<li>通过 ClassLoader#getSystemClassLoader() 方法可以获取到该类加载器</li>
</ul>
<h4 id="类加载器代码示例">类加载器代码示例</h4>
<pre><code class="language-java">public class ClassLoaderTest {
    public static void main(String[] args) {
        //获取系统类加载器
        ClassLoader systemClassLoader = ClassLoader.getSystemClassLoader();
        System.out.println(systemClassLoader);//sun.misc.Launcher$AppClassLoader@135fbaa4

        //获取其上层：扩展类加载器
        ClassLoader extClassLoader = systemClassLoader.getParent();
        System.out.println(extClassLoader);  //sun.misc.Launcher$ExtClassLoader@2503dbd3

        //再获取其上层：获取不到引导类加载器
        ClassLoader bootstrapClassLoader = extClassLoader.getParent();
        System.out.println(bootstrapClassLoader);     //null

        //对于用户自定义类来说，默认使用系统类加载器进行加载，输出和systemClassLoader一样
        ClassLoader classLoader = ClassLoaderTest.class.getClassLoader();
        System.out.println(classLoader);  //sun.misc.Launcher$AppClassLoader@135fbaa4

        //String 类使用引导类加载器进行加载。Java的核心类库都使用引导类加载器进行加载，所以也获取不到
        ClassLoader classLoader1 = String.class.getClassLoader();
        System.out.println(classLoader1);  //null

        //获取BootstrapClassLoader可以加载的api的路径
        URL[] urls = sun.misc.Launcher.getBootstrapClassPath().getURLs();
        for (URL url : urls) {
            System.out.println(url.toExternalForm());
        }
    }
}
</code></pre>
<p><strong>结果</strong></p>
<pre><code>sun.misc.Launcher$AppClassLoader@18b4aac2
sun.misc.Launcher$ExtClassLoader@61bbe9ba
null
sun.misc.Launcher$AppClassLoader@18b4aac2
null
file:/Library/Java/JavaVirtualMachines/jdk1.8.0_231.jdk/Contents/Home/jre/lib/resources.jar
file:/Library/Java/JavaVirtualMachines/jdk1.8.0_231.jdk/Contents/Home/jre/lib/rt.jar
file:/Library/Java/JavaVirtualMachines/jdk1.8.0_231.jdk/Contents/Home/jre/lib/sunrsasign.jar
file:/Library/Java/JavaVirtualMachines/jdk1.8.0_231.jdk/Contents/Home/jre/lib/jsse.jar
file:/Library/Java/JavaVirtualMachines/jdk1.8.0_231.jdk/Contents/Home/jre/lib/jce.jar
file:/Library/Java/JavaVirtualMachines/jdk1.8.0_231.jdk/Contents/Home/jre/lib/charsets.jar
file:/Library/Java/JavaVirtualMachines/jdk1.8.0_231.jdk/Contents/Home/jre/lib/jfr.jar
file:/Library/Java/JavaVirtualMachines/jdk1.8.0_231.jdk/Contents/Home/jre/classes
</code></pre>
<h4 id="用户自定义类加载器">用户自定义类加载器</h4>
<blockquote>
<p>在Java的日常应用程序开发中，类的加载几乎是由3种类加载器相互配合执行的，在必要时，我们还可以自定义类加载器，来定制类的加载方式</p>
</blockquote>
<h5 id="为什么要自定义类加载器">为什么要自定义类加载器？</h5>
<ul>
<li>隔离加载类</li>
<li>修改类加载的方式</li>
<li>扩展加载源（可以从数据库、云端等指定来源加载类）</li>
<li>防止源码泄露（Java代码容易被反编译，如果加密后，自定义加载器加载类的时候就可以先解密，再加载）</li>
</ul>
<h5 id="用户自定义加载器实现步骤">用户自定义加载器实现步骤</h5>
<ul>
<li>开发人员可以通过继承抽象类 java.lang.ClassLoader 类的方式，实现自己的类加载器，以满足一些特殊的需求</li>
<li>在JDK1.2之前，在自定义类加载器时，总会去继承ClassLoader类并重写loadClass()方法，从而实现自定义的类加载类，但是JDK1.2之后已经不建议用户去覆盖loadClass()方式，而是建议把自定义的类加载逻辑写在findClass()方法中</li>
<li>编写自定义类加载器时，如果没有太过于复杂的需求，可以直接继承URLClassLoader类，这样就可以避免自己去编写findClass()方法及其获取字节码流的方式，使自定义类加载器编写更加简洁</li>
</ul>
<h5 id="classloader常用方法">ClassLoader常用方法</h5>
<blockquote>
<p>ClassLoader类，是一个抽象类，其后所有的类加载器都继承自ClassLoader（不包括启动类加载器）</p>
</blockquote>
<table>
<thead>
<tr>
<th>方法</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>getParent()</td>
<td>返回该类加载器的超类加载器</td>
</tr>
<tr>
<td>loadClass(String name)</td>
<td>加载名称为name的类，返回java.lang.Class类的实例</td>
</tr>
<tr>
<td>findClass(String name)</td>
<td>查找名称为name的类，返回java.lang.Class类的实例</td>
</tr>
<tr>
<td>findLoadedClass(String name)</td>
<td>查找名称为name的已经被加载过的类，返回java.lang.Class类的实例</td>
</tr>
<tr>
<td>defineClass(String name, byte[] b, int off, int len)</td>
<td>把字节数组b中内容转换为一个Java类，返回java.lang.Class类的实例</td>
</tr>
<tr>
<td>resolveClass(Class&lt;?&gt; c)</td>
<td>连接指定的一个Java类</td>
</tr>
</tbody>
</table>
<h5 id="获取classloader的途径">获取ClassLoader的途径</h5>
<ul>
<li>获得当前类的ClassLoader
<ul>
<li>clazz.getClassLoader()</li>
</ul>
</li>
<li>获得当前线程上下文的ClassLoader
<ul>
<li>Thread.currentThread().getContextClassLoader()</li>
</ul>
</li>
<li>获取系统的ClassLoader
<ul>
<li>ClassLoader.getSystemClassLoader()</li>
</ul>
</li>
<li>获取调用者的ClassLoader</li>
<li>DriverManager.getCallerClassLoader();</li>
</ul>
<h4 id="双亲委派机制">双亲委派机制</h4>
<blockquote>
<p>Java虚拟机对class文件采用的是按需加载的方式，也就是说当需要使用该类的时候才会将它的class文件加载到内存生成class对象。而且加载某个类的class文件时，Java虚拟机采用的是双亲委派模式，即把请求交给父类处理，它是一种任务委派模式。<br>
<img src="https://EastBeforeDawn.github.io/post-images/1591884247393.png" alt="" loading="lazy"></p>
</blockquote>
<h5 id="工作过程">工作过程</h5>
<ol>
<li>如果一个类加载器收到了类加载请求，它并不会自己先去加载，而是把这个请求委托给父类的加载器去执行；</li>
<li>如果父类加载器还存在其父类加载器，则进一步向上委托，依次递归，请求最终将到达顶层的启动类加载器；</li>
<li>如果父类加载器可以完成类加载任务，就成功返回，倘若父类加载器无法完成此加载任务，子加载器才会尝试自己去加载，这就是双亲委派模式</li>
</ol>
<h5 id="优势">优势</h5>
<ul>
<li>
<p>避免类的重复加载，JVM中区分不同类，不仅仅是根据类名，相同的class文件被不同的ClassLoader加载就属于两个不同的类（比如，Java中的Object类，无论哪一个类加载器要加载这个类，最终都是委派给处于模型最顶端的启动类加载器进行加载，如果不采用双亲委派模型，由各个类加载器自己去加载的话，系统中会存在多种不同的Object类）</p>
</li>
<li>
<p>保护程序安全，防止核心API被随意篡改，避免用户自己编写的类动态替换 Java的一些核心类，比如我们自定义类：java.lang.String</p>
</li>
</ul>
<p><strong><code>在JVM中表示两个class对象是否为同一个类存在两个必要条件：</code></strong></p>
<ul>
<li>类的完成类名必须一致，包括包名</li>
<li>加载这个类的ClassLoader（指ClassLoader实例对象）必须相同</li>
</ul>
<h5 id="代码示例1">代码示例1</h5>
<pre><code class="language-java">package java.lang;

public class String {
    
    public static void main(String[] args) {
        System.out.println(&quot;我说自定义String类&quot;);
    }
}
</code></pre>
<p><strong>结果</strong></p>
<pre><code>错误: 在类 java.lang.String 中找不到 main 方法, 请将 main 方法定义为:
   public static void main(String[] args)
否则 JavaFX 应用程序类必须扩展javafx.application.Application
</code></pre>
<h5 id="代码示例2">代码示例2</h5>
<p>在java包下新建类</p>
<pre><code>package java.atguigu;

public class ClazzLoaderTest {
    public static void main(String[] args) {
        String s = new String();
    }
}
</code></pre>
<p><strong>结果</strong></p>
<pre><code class="language-tex">Error: A JNI error has occurred, please check your installation and try again
Exception in thread &quot;main&quot; java.lang.SecurityException: Prohibited package name: java.atguigu
	at java.lang.ClassLoader.preDefineClass(ClassLoader.java:655)
	at java.lang.ClassLoader.defineClass(ClassLoader.java:754)
	at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)
	at java.net.URLClassLoader.defineClass(URLClassLoader.java:468)
	at java.net.URLClassLoader.access$100(URLClassLoader.java:74)
	at java.net.URLClassLoader$1.run(URLClassLoader.java:369)
	at java.net.URLClassLoader$1.run(URLClassLoader.java:363)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.net.URLClassLoader.findClass(URLClassLoader.java:362)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:355)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
	at sun.launcher.LauncherHelper.checkAndLoadMain(LauncherHelper.java:495)
</code></pre>
<h5 id="沙箱安全机制">沙箱安全机制</h5>
<blockquote>
<p>如果我们自定义String类，但是在加载自定义String类的时候会率先使用引导类加载器加载，而引导类加载器在加载的过程中会先加载jdk自带的文件（rt.jar包中java\lang\String.class），报错信息说没有main方法就是因为加载的是rt.jar包中的String类。这样就可以保证对java核心源代码的保护，这就是简单的沙箱安全机制。</p>
</blockquote>
<h5 id="破坏双亲委派模型">破坏双亲委派模型</h5>
<blockquote>
<p>双亲委派模型并不是一个强制性的约束模型，而是Java设计者推荐给开发者的类加载器实现方式，可以“被破坏”，只要我们自定义类加载器，重写loadClass()方法，指定新的加载逻辑就破坏了，重写findClass()方法不会破坏双亲委派。</p>
</blockquote>
<blockquote>
<p>双亲委派模型有一个问题：顶层ClassLoader，无法加载底层ClassLoader的类。典型例子JNDI、JDBC，所以加入了线程上下文类加载器（Thread Context ClassLoader）,可以通过Thread.setContextClassLoaser()设置该类加载器，然后顶层ClassLoader再使用Thread.getContextClassLoader()获得底层的ClassLoader进行加载。</p>
</blockquote>
<blockquote>
<p>Tomcat中使用了自定ClassLoader，并且也破坏了双亲委托机制。每个应用使用WebAppClassloader进行单独加载，他首先使用WebAppClassloader进行类加载，如果加载不了再委托父加载器去加载，这样可以保证每个应用中的类不冲突。每个tomcat中可以部署多个项目，每个项目中存在很多相同的class文件（很多相同的jar包），他们加载到jvm中可以做到互不干扰。</p>
</blockquote>
<blockquote>
<p>利用破坏双亲委派来实现代码热替换（每次修改类文件，不需要重启服务）。因为一个Class只能被一个ClassLoader加载一次，否则会报java.lang.LinkageError。当我们想要实现代码热部署时，可以每次都new一个自定义的ClassLoader来加载新的Class文件。JSP的实现动态修改就是使用此特性实现。</p>
</blockquote>
<h5 id="类的主动使用和被动使用">类的主动使用和被动使用</h5>
<p>Java程序对类的使用方式分为：主动使用和被动使用。虚拟机规范规定有且只有7种情况必须立即对类进行“初始化”，即类的主动使用。</p>
<ul>
<li>创建类的实例</li>
<li>访问某个类或接口的静态变量，或者对该静态变量赋值</li>
<li>调用类的静态方法（即遇到new、getstatic、putstatic、invokestatic这四条字节码指令时）</li>
<li>反射</li>
<li>初始化一个类的子类</li>
<li>Java虚拟机启动时被标明为启动类的类</li>
<li>JDK7 开始提供的动态语言支持：java.lang.invoke.MethodHandle实例的解析结果，REF_getStatic、REF_putStatic、REF_invokeStatic句柄对应的类没有初始化，则初始化</li>
</ul>
<p>除以上7种情况，其他使用Java类的方式被看作是对类的被动使用，都不会导致类的初始化。</p>
<p><strong>代码示例</strong></p>
<pre><code>public class NotInitialization {
    public static void main(String[] args) { 
        //只输出SupperClass int 123,不会输出SubClass init
        //对于静态字段，只有直接定义这个字段的类才会被初始化
        System.out.println(SubClass.value); 
    }
}

class SuperClass {
    static {
        System.out.println(&quot;SupperClass init&quot;);
    }
    public static int value = 123;
}

class SubClass extends SuperClass {
    static {
        System.out.println(&quot;SubClass init&quot;);
    }
}
</code></pre>
<h2 id="运行时数据区的内存结构">运行时数据区的内存结构</h2>
<blockquote>
<p>内存是非常重要的系统资源，是硬盘和CPU的中间仓库及桥梁，承载着操作系统和应用程序的实时运行<br>
JVM内存布局规定了Java在运行过程中内存申请、分配、管理的策略，保证了JVM的高效稳定运行<br>
不同的JVM对于内存的划分方式和管理机制存在着部分差异</p>
</blockquote>
<p><img src="https://EastBeforeDawn.github.io/post-images/1591884267919.png" alt="" loading="lazy"><br>
<img src="https://EastBeforeDawn.github.io/post-images/1591884274422.png" alt="" loading="lazy"></p>
<p><strong>线程</strong></p>
<ul>
<li>线程是一个程序里的运行单元。JVM允许一个应用有多个线程并行的执行。</li>
<li>在HotspotJVM里，每个线程都与操作系统的本地线程直接映射
<ul>
<li>当一个Java线程准备好执行以后， 此时一个操作系统的本地线程也同时创建。Java线程执行终止以后，本地线程也会回收。</li>
</ul>
</li>
<li>操作系统负责所有都线程安排调度到任何一个可用的CPU上，一旦本地线程初始化成功，就会调用Java线程的run方法</li>
</ul>
<h3 id="1program-counter-register-程序计数寄存器">1.Program Counter Register (程序计数寄存器)</h3>
<blockquote>
<p>Register 的命名源于CPU的寄存器，CPU只有把数据装载到寄存器才能够运行</p>
</blockquote>
<blockquote>
<p>寄存器存储指令相关的现场信息，由于CPU时间片轮限制，众多线程在并发执行过程中，任何一个确定的时刻，一个处理器或者多核处理器中的一个内核，只会执行某个线程中的一条指令。这样必然导致经常中断或恢复，如何保证分毫无差呢?</p>
</blockquote>
<blockquote>
<p>每个线程在创建后，都会产生自己的程序计数器和栈帧，程序计数器用来存放执行指令的偏移量和行号指示器等，线程执行或恢复都要依赖程序计数器。程序计数器在各个线程之间互不影响，此区域也不会发生内存溢出异常。</p>
</blockquote>
<blockquote>
<p><strong><code>这里并非广义上的物理寄存器，它是对PC物理寄存器的一种抽象的模拟</code></strong></p>
</blockquote>
<h4 id="定义">定义</h4>
<ul>
<li>程序计数器是一块较小的内存空间，可看作当前线程正在执行的字节码的行号指示器</li>
<li>如果当前线程正在执行的是
<ul>
<li>Java方法 ,计数器记录的就是当前线程正在执行的字节码指令的地址</li>
<li>本地方法,那么程序计数器值为undefined</li>
</ul>
</li>
</ul>
<h4 id="作用">作用</h4>
<ul>
<li>字节码解释器通过改变程序计数器来依次读取指令，从而实现代码的流程控制，如：顺序执行、选择、循环、异常处理</li>
<li>在多线程的情况下，程序计数器用于记录当前线程执行的位置，从而当线程被切换回来的时候能够知道该线程上次运行到哪儿了。</li>
</ul>
<h4 id="特点">特点</h4>
<ul>
<li>一块较小的内存空间</li>
<li>线程私有。每条线程都有一个独立的程序计数器。</li>
<li>是唯一一个不会出现OOM的内存区域。</li>
<li>生命周期随着线程的创建而创建，随着线程的结束而死亡。</li>
</ul>
<h5 id="代码示例">代码示例</h5>
<pre><code>package com.atguigu;

public class ClazzLoaderTest {
    public static void main(String[] args) {
        int a = 0;
        int b = 0;
        System.out.println(a);
    }
}
</code></pre>
<p><strong>字节码</strong></p>
<pre><code class="language-tex">//第一列为指令地址
//第二列为操作指令 
 0 iconst_0
 1 istore_1
 2 iconst_0
 3 istore_2
 4 getstatic #2 &lt;java/lang/System.out&gt;
 7 iload_1
 8 invokevirtual #3 &lt;java/io/PrintStream.println&gt;
11 return
</code></pre>
<figure data-type="image" tabindex="2"><img src="https://EastBeforeDawn.github.io/post-images/1591884292118.png" alt="" loading="lazy"></figure>
<h3 id="2-java虚拟机栈jvm-stack">2. Java虚拟机栈(JVM Stack)</h3>
<blockquote>
<p>由于跨平台性的设计， Java的指令都是根据栈来设计的。不同平台的CPU架构不同，所以不能设计成基于寄存器的。<br>
优点是跨平台,指令集小,编译器容易实现,缺点是性能下降,实现同样 的功能需要更多的指令。</p>
</blockquote>
<h4 id="定义-2">定义</h4>
<ul>
<li>java虚拟机栈（Java Virtual Machine Stack），早期也叫Java栈。相对于基于寄存器的运行环境来说，JVM是基于栈结构的运行环境。栈结构移植性更好，可控性更强。JVM中的虚拟机栈是描述Java方法执行的内存区域。</li>
<li>栈中的元素用于支持虚拟机进行方法调用，每个方法从开始调用到执行完成的过程，就是栈帧从入栈到出栈的过程。</li>
<li>它保存方法的局部变量、8种基本数据类型、对象的引用地址、部分结果，并参与方法的调用和返回。</li>
</ul>
<h4 id="特点-2">特点</h4>
<ul>
<li>Java虚拟机栈也是线程私有的</li>
<li>随着线程的创建而创建,随着线程的死亡而死亡.</li>
</ul>
<h4 id="会出现的异常">会出现的异常</h4>
<p>Java虚拟机规范中规定：<code>java栈的大小是动态的或者是固定不变的</code></p>
<h5 id="stackoverflowerror">StackOverFlowError</h5>
<ul>
<li>如果采用固定大小的Java虚拟机栈，那每一个线程的java虚拟机栈容量可以在线程创建的时候独立选定。如果线程请求分配的栈容量超过java虚拟机栈允许的最大容量，java虚拟机将会抛出一个 StackOverFlowError异常</li>
</ul>
<h5 id="outofmemoryerror">OutOfMemoryError</h5>
<ul>
<li>如果java虚拟机栈可以动态拓展，并且在尝试拓展的时候无法申请到足够的内存，或者在创建新的线程时没有足够的内存去创建对应的虚拟机栈，那java虚拟机将会抛出一个 OutOfMemoryError异常</li>
</ul>
<h4 id="设置栈的大小-xss">设置栈的大小 -Xss</h4>
<ul>
<li>-Xss=1M</li>
<li>-Xss=1024k</li>
</ul>
<h4 id="栈的存储原理">栈的存储原理</h4>
<h5 id="栈中储存什么">栈中储存什么</h5>
<ul>
<li>每个线程都有自己的栈，栈中的数据都是以栈帧 (Stack Frame)的格式存在。</li>
<li>在这个线程正在执行的每个方法都各自对应一个栈帧 (Stack Frame)。</li>
<li>栈帧是一个内存区块，是一个数据集，维系着方法执行过程中的各种数据信息。</li>
</ul>
<h5 id="栈运行原理">栈运行原理</h5>
<ul>
<li>JVM直接接对Java栈的操作只有两个，就是对栈帧的压栈和出栈，遵循“先进后出” / “后进先出”原则。</li>
<li>在一条活动线程中，一个时间点上，只会有一个活动的栈帧。即当前正在执行的方法的栈帧（栈顶栈帧）是有效的，这个栈帧被称为当前栈帧 (Current Frame)，与当前栈帧相对应的方法就是”当前方法（Current Method)，定义这个方法的类就是当前类(Current Class)</li>
<li>在执行引擎运行时，所有指令都只能针对当前栈帧进行操作</li>
<li>如果在该方法中调用了其他方法，对应的新的栈帧会被创建出来，放在栈的顶端，成为新的当前桢。</li>
</ul>
<hr>
<ul>
<li>不同线程中所包含的栈帧是不允许存在相互引用的，即不可能在一个栈帧之中引用另外一个线程的栈帧。</li>
<li>如果当前方法调用了其他方法，方法返回之际，当前栈帧会传回此方法的执行结果给前一个栈帧，接着，虚拟机会丢弃当前栈帧，使得前一个栈帧重新成为当前栈帧。</li>
<li>Java方法有两种返回函数的方式，一种是正常的函数返回，使用return指令；另外一种是抛出异常。不管使用哪种方式，都会导致栈帧被弹出。</li>
</ul>
<h4 id="栈的内部结构">栈的内部结构</h4>
<blockquote>
<p>每个栈帧中存储有：</p>
</blockquote>
<ul>
<li><code>局部变量表(Local Variables)</code></li>
<li><code>操作数栈 (Operand Stack)(或表达式栈)</code></li>
<li>动态链接 (Dynamic Linking)(或指向运行时常量池的方法引用)</li>
<li>方法返回地址(Return Address)(或方法正常退出或者异常退出的定义)</li>
<li>一些附加信息<br>
<img src="https://EastBeforeDawn.github.io/post-images/1591884307067.png" alt="" loading="lazy"></li>
</ul>
<h4 id="1局部变量表local-variables">1.局部变量表(Local Variables)</h4>
<ul>
<li>局部变量表也被称之为局部变量数组或本地变量表</li>
<li>定义为一个数字数组，主要用于存储方法参数和定义在方法体内的局部变量，这些数据类型包括各类基本数据类型、对象引用 (reference)，以及returnAddress 类型。</li>
<li>由于局部变量表是建立在线程的栈上，是线程的私有数据，因此不存在数据安全问题</li>
<li>局部变量表所需的容量大小是在编译期确定下来的，并保存在方法的 Code 属性的 maximum local variables数据项中。在方法运行期间是不会改变局部变量表的大小的。</li>
</ul>
<h5 id="slot的理解">slot的理解</h5>
<ul>
<li>参数值的存放总是在局部变量数组的index0开始，到数组长度-1的索引结束。</li>
<li>局部变量表，最基本的存储单位是slot (变量槽)</li>
<li>局部变量表中存放编译期可知的各种基本数据类型（8种），引用类型(reference) , returnAddress类型。</li>
<li>在局部变量表中，32位以内的类型只占1个slot (包括returnAddress类型) ，64位的类型（long和double)占两个slot
<ul>
<li>byte 、short 、char 在存储前被转换为 int， boolean 也被转换为int，0 表示false，非0表示true。</li>
<li>long 和double 则占据两个slot。</li>
</ul>
</li>
</ul>
<pre><code class="language-tex">public static void main(java.lang.String[]);
    descriptor: ([Ljava/lang/String;)V
    flags: ACC_PUBLIC, ACC_STATIC
    Code:
      stack=2, locals=3（表示三个局部变量）, args_size=1
         0: iconst_0
         1: istore_1
         2: iconst_0
         3: istore_2
         4: getstatic     #2                  // Field java/lang/System.out:Ljava/io/PrintStream;
         7: iload_1
         8: invokevirtual #3                  // Method java/io/PrintStream.println:(I)V
        11: return
      LineNumberTable:
        line 5: 0
        line 6: 2
        line 7: 4
        line 8: 11
      LocalVariableTable:
        Start  Length  Slot  Name   Signature
            0      12     0  args   [Ljava/lang/String;  // 第一个
            2      10     1     a   I           //第二个
            4       8     2     b   I           // 第三个
}
</code></pre>
<ul>
<li>JVM会为局部变量表中的每一个Slot都分配一个访问索引，通过这个索引即可成功访问到局部变量表中指定的局部变量值</li>
<li>当一个实例方法被调用的时候，它的方法参数和方法体内部定义的局部变量将会<code>按照顺序</code>被复制到局部变量表中的每一个Slot上</li>
<li><code>如果需要访问局部变量表中一个64bit的局部变量值时，只需要使用前一个索引即可。</code>（比如：访问long或double类型变量）</li>
<li>如果当前帧是由构造方法或者实例方法创建的，那么<code>该对象引用this将会存放在index为0的slot处</code>，其余的参数按照参数表顺序继续排列</li>
</ul>
<h5 id="slot的重复利用">slot的重复利用</h5>
<ul>
<li>栈帧中的局部变量表中的槽位是可以重用的，如果一个局部变量过了其作用域，那么在其作用域之后申明的 新的局部变量就很有可能会复用过期局部变量的槽位，从而达到节省资源的目的。<br>
<img src="https://EastBeforeDawn.github.io/post-images/1591884320390.png" alt="" loading="lazy"></li>
<li>图中index为2的索引出现两次，是因为变量c在代码块中，作用域只有4行，在局部变量表的数组里已经开辟了空间，定义变量b的时候重新利用的c的空间</li>
</ul>
<h5 id="静态变量与局部变量的对比">静态变量与局部变量的对比</h5>
<ul>
<li>参数表分配完毕之后，再根据方法体内定义的变量的顺序和作用域分配</li>
<li>我们知道类变量表有两次初始化的机会，第一次是在“准备阶段”，执行系统初始化，对类变量设置零值，另一次则是在“初始化”阶段，赋予程序员在代码中定义的初始值。</li>
<li>和类变量初始化不同的是，局部变量表不存在系统初始化的过程，这意味着一旦定义了局部变量则必须人为的初始化，否则无法使用。</li>
</ul>
<pre><code class="language-java">public class ClazzLoaderTest {
    public static void main(String[] args) {
        int a ;
       // System.out.println(a); 变量未进行初始化
    }
}
</code></pre>
<h5 id="补充说明">补充说明</h5>
<ul>
<li>在栈帧中，与性能调优关系最为密切的部分就是前面提到的局部变量表。在方法执行时，虚拟机使用局部变量表完成方法的传递。</li>
<li>局部变量表中的变量也是重要的垃圾回收根节点，只要被局部变量表中直接或间接引用的对象都会被回收。</li>
</ul>
<h4 id="2操作数栈-operand-stack">2.操作数栈 (Operand Stack)</h4>
<ul>
<li>每一个独立的栈帧中除了包含局部变量表以外，还包含一个后进先出(Last-In-First-Out)的操作数栈，也可以称之为表达式栈(Expression Stack)</li>
<li>操作数栈，在方法执行过程中，根据字节码指令，往栈中写入数据或提取数据，即入栈( push) /出栈(pop)。
<ul>
<li>某些字节码指令将值压入操作数栈，其余的字节码指令将操作数取出栈。使用它们后再把结果压入栈。</li>
<li>比如：执行复制、交换、求和等操作</li>
</ul>
</li>
</ul>
<hr>
<ul>
<li>操作数栈，<code>主要用于保存计算过程的中间结果，同时作为计算过程中变量临时的存储空间</code></li>
<li>操作数栈就是JVM执行引擎的下一个工作区，当一个方法刚开始执行的时候，一个新的栈帧也会随之创建出来，<code>这个方法的操作数栈是空的</code></li>
<li>每一个操作数栈都会拥有一个明确的栈深度用于存储数值，其所需的最大深度在编译期就定义好了，保存在方法的Code属性中，为max_statck的值</li>
<li>栈中的任何一个元素都是可以任意的Java数据类型；32bit的类型占用一个栈单位深度，64bit的类型占用两个栈单位的深度</li>
<li>操作数栈<code>并非采用访问索引的方式来进行数据访问的</code>，而是只能通过标准的入栈和出栈操作完成一次数据访问</li>
<li><code>如果被调用的方法带有返回值的话，其返回值将会被压入当前栈帧的操作数栈中</code>，并更新PC寄存器中下一条需要执行的字节码指令</li>
<li>操作数栈中的元素的数据类型必须与字节码指令的序列严格匹配，这由编译器在编译期间进行验证，同时在类加载过程中的类检验阶段的数据流分析阶段要再次检验</li>
<li>另外，我们说Java虚拟机的<code>解释引擎是基于栈的执行引擎</code>，其中栈指的就是操作数栈</li>
</ul>
<h5 id="代码示例-2">代码示例</h5>
<pre><code>public void testOperation() {

		byte i = 15;
		int j = 8;
		int k = i + j;

	}
</code></pre>
<p><strong>使用javap命令反编译class文件：javap -v 类名.class</strong></p>
<pre><code class="language-tex"> public void testOperation();
    descriptor: ()V
    flags: ACC_PUBLIC
    Code:
      stack=2, locals=4, args_size=1
         0: bipush        15
         2: istore_1
         3: bipush        8
         5: istore_2
         6: iload_1
         7: iload_2
         8: iadd
         9: istore_3
        10: return
</code></pre>
<p><strong>执行过程</strong><br>
<img src="https://EastBeforeDawn.github.io/post-images/1591884337130.png" alt="" loading="lazy"><br>
<img src="https://EastBeforeDawn.github.io/post-images/1591884340418.png" alt="" loading="lazy"><br>
<img src="https://EastBeforeDawn.github.io/post-images/1591884344946.png" alt="" loading="lazy"><br>
<img src="https://EastBeforeDawn.github.io/post-images/1591884348959.png" alt="" loading="lazy"></p>
<h5 id="栈顶缓存top-of-stack-cashing技术">栈顶缓存（Top-of-Stack Cashing）技术</h5>
<ul>
<li>基于栈式架构的虚拟机所使用的的零地址指令更加紧凑，但完成一项操作的时候必然需要使用更多的入栈和出栈和指令，这同时也就意味着将需要更多的指令分派（instruction dispatch）次数和内存读/写次数</li>
<li>由于操作数栈式存储在内存中的，因此频繁的执行内存读/写操作必然会影响执行速度。为了解决这个问题，HotSpot JVM的设计者们提出了栈顶缓存技术，<code>将栈顶元素全部缓存在物理CPU的寄存器中，以此降低对内存的读/写次数，提升执行引擎的执行效率</code></li>
</ul>
<h4 id="3动态链接">3.动态链接</h4>
<ul>
<li>每一个栈帧内部都包含一个指向*<code>运行时常量池</code>*中<code>该栈帧所属方法的引用</code>。包含这个引用的目的就是为了支持当前方法的代码能够实现<code>动态链接(Dynamic Linking)</code>。比如：invokedynamic指令</li>
<li>Java源文件被编译到字节码文件中时，所有的变量和方法引用都作为符号引用保存在class文件的常量池里。比如，描述一个方法调用另外的其他方法时，就是通过常量池中的指向方法的符号引用来表示的，那么<code>动态链接的作用就是为了将这些符号引用转换为调用方法的直接引用</code><br>
<img src="https://EastBeforeDawn.github.io/post-images/1591884375832.png" alt="" loading="lazy"></li>
</ul>
<h5 id="方法的调用">方法的调用</h5>
<p><strong>静态链接与动态链接</strong></p>
<blockquote>
<p>在JVM中，将符号引用转换为调用方法的直接引用与方法的绑定机制相关。</p>
</blockquote>
<ul>
<li>静态链接：
<ul>
<li>当一个字节码文件被装载进JVM内部时，如果被调用的目标方法在编译期可知，且运行期保持不变时。这种情况下将调用方法的符号引用转换为直接引用的过程称之为静态链接。</li>
</ul>
</li>
<li>动态链接：
<ul>
<li>如果<code>被调用的方法在编译期无法被确定下来</code>，也就是说，只能够在程序运行期将调用方法的符号引用转换为直接引用，由于这种转换过程具备动态性，因此也就被称之为动态链接。</li>
</ul>
</li>
</ul>
<hr>
<p><strong>早期绑定与晚期绑定</strong></p>
<blockquote>
<p>对应的方法的绑定机制为：早期绑定（Early Binding)和晚期绑定(Late Binding)。绑定是一个字段、方法或者类在符号引用被替换为直接引用的过程，这仅仅发生一次。</p>
</blockquote>
<ul>
<li>早期绑定：
<ul>
<li>早期绑定就是指被调用的目标方法如果在编译期可知，且运行期保持不变时，将这个方法与所属的类型进行绑定，这样一来，由于十分明确了被调用的目标方法究竟是哪一个，因此也就可以使用静态链接的方式将符号引用转换为直接引用。</li>
</ul>
</li>
<li>晚期绑定：
<ul>
<li>如果被调用的方法在编译期无法被确定下来，只能够在程序运行期根据实际的类型绑定相关的方法，这种绑定方式也就被称之为晚期绑定。</li>
</ul>
</li>
</ul>
<pre><code class="language-java">package com.atguigu.java2;

/**
 * 说明早期绑定和晚期绑定的例子
 * @author shkstart
 * @create 2020 上午 11:59
 */
class Animal{

    public void eat(){
        System.out.println(&quot;动物进食&quot;);
    }
}
interface Huntable{
    void hunt();
}
class Dog extends Animal implements Huntable{
    @Override
    public void eat() {
        System.out.println(&quot;狗吃骨头&quot;);
    }

    @Override
    public void hunt() {
        System.out.println(&quot;捕食耗子，多管闲事&quot;);
    }
}

class Cat extends Animal implements Huntable{

    public Cat(){
        super();//表现为：早期绑定
    }

    public Cat(String name){
        this();//表现为：早期绑定
    }

    @Override
    public void eat() {
        super.eat();//表现为：早期绑定
        System.out.println(&quot;猫吃鱼&quot;);
    }

    @Override
    public void hunt() {
        System.out.println(&quot;捕食耗子，天经地义&quot;);
    }
}
public class AnimalTest {
    public void showAnimal(Animal animal){
        animal.eat();//表现为：晚期绑定
    }
    public void showHunt(Huntable h){
        h.hunt();//表现为：晚期绑定
    }
}
</code></pre>
<ul>
<li>随着高级语言的横空出世，类似于Java一样的基于面对对象的编程语言如今越来越多，尽管这类编程语言在语法风格上存在一定的差别，但是它们彼此之间始终保持着一个共性，那就是都支持封装、继承和多态等面对对象的特性，既然这一类的编程语言具备多态特性，那么自然也就具备了早期绑定和晚期绑定两种绑定方式。</li>
<li>Java中任何一个普通的方法其实都具有虚函数的特性，它们相当于C++语言中的虚函数（ C++中则需要使用关键字 virtual来显式定义）。如果在 Java程序中不希望某个方法拥有虚函数的特征时，则可以使用关键字final来标记这个方法。</li>
</ul>
<hr>
<p><strong>虚方法与非虚方法</strong></p>
<ul>
<li>非虚方法：
<ul>
<li>如果方法在编译期就确定了具体的调用版本，这个版本在运行时是不可变的，这样的方法称为非虚方法</li>
<li>静态方法，私有方法，final方法，实例构造器，父类方法都是非虚方法</li>
</ul>
</li>
<li>其他方法都是虚方法</li>
</ul>
<h5 id="方法调用指令">方法调用指令</h5>
<ul>
<li>普通调用指令
<ul>
<li>invokestatic：调用静态方法，解析阶段确定唯一方法版本</li>
<li>invokespecial: 调用&lt;init&gt;方法、私有及父类方法，解析阶段确定唯一方法版本</li>
<li>invokevirtual：调用所有的虚方法</li>
<li>invokeinterface：调用接口方法</li>
</ul>
</li>
<li>动态调用指令
<ul>
<li>invokedynamic：动态解析出需要调用的方法，然后执行</li>
</ul>
</li>
</ul>
<p>前四条指令固化在虚拟机内部，方法的调用执行不可人为干预。而invokedynamic指令则支持由用户确定方法的版本，其中<code>invokespecial和invokestatic调用的方法称为非虚方法，其余的（final修饰除外）称为虚方法</code></p>
<pre><code class="language-java"> 
 package com.atguigu.java2;

/**
 * 解析调用中非虚方法、虚方法的测试
 *
 * invokestatic指令和invokespecial指令调用的方法称为非虚方法
 * @author shkstart
 * @create 2020 下午 12:07
 */
class Father {
    public Father() {
        System.out.println(&quot;father的构造器&quot;);
    }

    public static void showStatic(String str) {
        System.out.println(&quot;father &quot; + str);
    }

    public final void showFinal() {
        System.out.println(&quot;father show final&quot;);
    }

    public void showCommon() {
        System.out.println(&quot;father 普通方法&quot;);
    }
}

public class Son extends Father {
    public Son() {
        //invokespecial
        super();
    }
    public Son(int age) {
        //invokespecial
        this();
    }
    //不是重写的父类的静态方法，因为静态方法不能被重写！
    public static void showStatic(String str) {
        System.out.println(&quot;son &quot; + str);
    }
    private void showPrivate(String str) {
        System.out.println(&quot;son private&quot; + str);
    }

    public void show() {
        //invokestatic
        showStatic(&quot;atguigu.com&quot;);
        //invokestatic
        super.showStatic(&quot;good!&quot;);
        //invokespecial
        showPrivate(&quot;hello!&quot;);
        //invokespecial
        super.showCommon();

        //invokevirtual
        showFinal();//因为此方法声明有final，不能被子类重写，所以也认为此方法是非虚方法。
        //虚方法如下：
        //invokevirtual
        showCommon();
        info();

        MethodInterface in = null;
        //invokeinterface
        in.methodA();
    }

    public void info(){

    }

    public void display(Father f){
        f.showCommon();
    }

    public static void main(String[] args) {
        Son so = new Son();
        so.show();
    }
}

interface MethodInterface{
    void methodA();
}
</code></pre>
<p><strong>关于invokedynamic指令</strong></p>
<ul>
<li>JVM字节码指令集一直比较稳定，Java7中才增加了一个invokedynamic指令，这其实是<code>Java实现[动态类型语言]的一种改进</code></li>
<li>但是在Java7中并没有提供直接生成invokedynamic指令的方法，需要借助ASM这种底层字节码工具来产生invokedynamic指令。直到Java8的Lambda表达式的出现，invokedynamic指令的生成，在Java中才有了直接的生成方式。</li>
<li>Java7中增加的动态语言类型支持的本质是对Java虛拟机规范的修改，而不是对Java语言规则的修改，这一块相对来讲比较复杂，增加了虚拟机中的方法调用，最直接的受益者就是运行在Java平台的动态语言的编译器。</li>
</ul>
<pre><code>package com.atguigu;

/**
 * 体会invokedynamic指令
 * @author shkstart
 * @create 2020 下午 3:09
 */
@FunctionalInterface
interface Func {
    public boolean func(String str);
}

public class Lambda {
    public void lambda(Func func) {
        return;
    }

    public static void main(String[] args) {
        Lambda lambda = new Lambda();

        Func func = s -&gt; {
            return true;
        };

        lambda.lambda(func);

        lambda.lambda(s -&gt; {
            return true;
        });
    }
}
</code></pre>
<p>lambda表达式的引入一定程度上具备了动态语言的特点</p>
<pre><code class="language-tex"> 0 new #2 &lt;com/atguigu/Lambda&gt;
 3 dup
 4 invokespecial #3 &lt;com/atguigu/Lambda.&lt;init&gt;&gt;
 7 astore_1
 8 invokedynamic #4 &lt;func, BootstrapMethods #0&gt;
13 astore_2
14 aload_1
15 aload_2
16 invokevirtual #5 &lt;com/atguigu/Lambda.lambda&gt;
19 aload_1
20 invokedynamic #6 &lt;func, BootstrapMethods #1&gt;
25 invokevirtual #5 &lt;com/atguigu/Lambda.lambda&gt;
28 return
</code></pre>
<p><strong>动态类型语言和静态类型语言</strong></p>
<blockquote>
<p>动态类型语言和静态类型语言两者的区别就在于对类型的检查是在编译期还是在运行期，满足前者就是静态类型语言，反之是动态类型语言</p>
</blockquote>
<ul>
<li>静态类型语言是判断变量自身的类型信息。</li>
<li>动态类型语言是判断变量值的类型信息。</li>
<li>变量没有类型信息，变量值才有类型信息，这是动态语言的一个重要的特征</li>
<li>Java是静态类型语言 ，String s = &quot;123&quot;;</li>
<li>JS是动态类型语言，var s = 123;</li>
</ul>
<p><strong>Java语言中方法重写的本质：</strong></p>
<ol>
<li>找到操作数栈顶的第一个元素所执行的对象的实际类型，记作C。</li>
<li>如果在类型 C中找到与常量中的描述符合简单名称都相符的方法，则进行访问权限校验，如果通过则返回这个方法的直接引用，査找过程结束；如果不通过，则返回java. lang. IllegalAccessError 异常。</li>
<li>否则，按照继承关系从下往上依次对C的各个父类进行第2步的搜索和验证过程。</li>
<li>如果始终没有找到合适的方法，则抛出java.lang.AbstractMethodError异常。</li>
</ol>
<p><strong>IllegalAccessError 介绍：</strong></p>
<ul>
<li>程序试图访问或修改一个属性或调用一个方法，这个属性或方法，你没有权限访问。一般<br>
的，这个会引起编译器异常。这个错误如果发生在运行时，就说明一个类发生了不兼容的<br>
改变。</li>
</ul>
<h5 id="虚方法表">虚方法表</h5>
<ul>
<li>在面向对象的编程中，会很频繁的使用到动态分派，如果在每次动态分派的过程中都要重新在类的方法元数据中搜索合适的目标的话就可能影响到执行效率。因此，为了提高性能，JVM采用在类的方法区建立一个虚方法表(virtual method table)(非虚方法不会出现在表中）来实现。使用索引表來代替查找。</li>
<li>每个类中都有一个虛方法表，表中存放有各个方法的实际入口。</li>
<li>那么虚方法表什么时候被创建？
<ul>
<li>虚方法表会在类加载的链接阶段被创建并开始初始化，类的变量初阶段准备完成之后，JVM会把该类的方法表也初始化完毕。</li>
</ul>
</li>
</ul>
<figure data-type="image" tabindex="3"><img src="https://EastBeforeDawn.github.io/post-images/1591884395949.png" alt="" loading="lazy"></figure>
<h4 id="4方法返回地址">4.方法返回地址</h4>
<blockquote>
<p>存放调用该方法的pc寄存器的值</p>
</blockquote>
<ul>
<li>一个方法的结束有两种方式
<ul>
<li>正常执行完成</li>
<li>出现未处理的异常，非正常退出</li>
</ul>
</li>
<li>无论哪种方式退出，在方法退出后都返回到该方法被调用的位置，方法正常退出时，<code>调用者的pc计数器的值作为返回地址</code>，即调用该方法的指令的下一条指令的地址。而异常退出，返回地址是要通过异常表来确定，栈帧中一般不会保存这部分信息<br>
<img src="https://EastBeforeDawn.github.io/post-images/1591884452836.png" alt="" loading="lazy"></li>
</ul>
<blockquote>
<p>本质上，方法的退出就是当前栈帧出栈的过程，此时，需要恢复上层方的局部变量表、操作数栈、将返回值压入调用者栈帧的操作数栈、设置PC寄存器值等，让调用者方法继续执行下去。<br>
正常完成出口和异常完成出口的区別在于：通过异常完成出口退出的不会给他的上层调用者产生任何的返回值。</p>
</blockquote>
<blockquote>
<p>当一个方法开始执行后，只有两种方式可以退出这个方法：</p>
</blockquote>
<ol>
<li>执行引擎遇到任意一个方法返回的字节码指令（return) 会有返回值传递给上层的方让调用者，简称正常完成出口;</li>
</ol>
<ul>
<li>一个方法在正常调用完成之后究竟需要使用哪一个返回指令还需要根据方法返回值的实际数据类型而定。</li>
<li>在字节码指令中，返回指令包含 ireturn (当返回值是 boolean、 byte、 char、short和 int类型时使用）、 lreturn、 freturn、 dreturn以及 areturn，另外还有一个return指令供声明为void的方法、实例初始化方法、类和接口的初始化方法使用。</li>
</ul>
<ol start="2">
<li>在方法执行的过程中遇到了异常（Exception)，并且这个异常没有在方法内进行处理，也就是只要在本方法的异常表中没有搜索到匹配的异常处理器，就会导致方法退出。简称异常完成出口。</li>
</ol>
<ul>
<li>方法执行过程中抛出异常时的异常处理，存储在一个异常处理表，方便在发生异常的时候找到处理异常的代码</li>
</ul>
<h4 id="5一些附加信息">5.一些附加信息</h4>
<blockquote>
<p>栈帧中还允许携带与Java虚拟机实现相关的一些附加信息。例如，对程序调试提供支持的信息</p>
</blockquote>
<h4 id="java栈面试题">Java栈面试题</h4>
<h4 id="方法定义的局部变量是否是线程安全"># 方法定义的局部变量是否是线程安全</h4>
<ul>
<li>具体情况具体分析</li>
</ul>
<pre><code class="language-java">package com.atguigu.java3;

/**
 * 面试题：
 * 方法中定义的局部变量是否线程安全？具体情况具体分析
 *
 *   何为线程安全？
 *      如果只有一个线程才可以操作此数据，则必是线程安全的。
 *      如果有多个线程操作此数据，则此数据是共享数据。如果不考虑同步机制的话，会存在线程安全问题。
 * @author shkstart
 * @create 2020 下午 7:48
 */
public class StringBuilderTest {

    int num = 10;

    //s1的声明方式是线程安全的
    public static void method1(){
        //StringBuilder:线程不安全
        StringBuilder s1 = new StringBuilder();
        s1.append(&quot;a&quot;);
        s1.append(&quot;b&quot;);
        //...
    }
    //sBuilder的操作过程：是线程不安全的
    public static void method2(StringBuilder sBuilder){
        sBuilder.append(&quot;a&quot;);
        sBuilder.append(&quot;b&quot;);
        //...
    }
    //s1的操作：是线程不安全的
    public static StringBuilder method3(){
        StringBuilder s1 = new StringBuilder();
        s1.append(&quot;a&quot;);
        s1.append(&quot;b&quot;);
        return s1;
    }
    //s1的操作：是线程安全的
    public static String method4(){
        StringBuilder s1 = new StringBuilder();
        s1.append(&quot;a&quot;);
        s1.append(&quot;b&quot;);
        return s1.toString();
    }

    public static void main(String[] args) {
        StringBuilder s = new StringBuilder();


        new Thread(() -&gt; {
            s.append(&quot;a&quot;);
            s.append(&quot;b&quot;);
        }).start();

        method2(s);

    }

}
</code></pre>
<h3 id="3本地方法栈">3.本地方法栈</h3>
<h4 id="学在前面本地方法接口">学在前面：本地方法接口</h4>
<blockquote>
<p>简单地讲，一个Native Method就是一个Java调用非Java代码的借口。一个Native Method是这样一个Java方法：该方法的实现由非Java语言实现，比如C。这个特征并非Java所特有，很多其它的编程语言都有这一机制，比如在C++中，你可以用extern &quot;C&quot;告知C++编译器去调用一个C的函数。I<br>
&quot;A native method is a Java method whose implementation is provided by non-java code.&quot;<br>
在定义一个native method时，并不提供实现体（有些像定义一个Java interface)，因为其实现体是由非java语言在外面实现的<br>
本地接口的作用是融合不同的编程语言为Java所用，它的初衷是融合C/C++程序</p>
</blockquote>
<h5 id="为什么要使用natice-method">为什么要使用Natice Method</h5>
<blockquote>
<p>Java使用起来非常方便，然而有些层次的任务用Java实现起来小容易，或者我们对程序的效率很在意时，问题就来了。</p>
</blockquote>
<ul>
<li>与Java环境外交互
<ul>
<li>有时Java应用想要与Java外面的环境交互，这是本地方法存在的主要原因。你可以想想Java需要与一些底层系统，如操作系统或某些硬件交换信息时的情况。本地方法正是这样的一种交流机制：它为我们提供了一个个非常简洁的接口而且我们不用去了解Java应用之外的繁琐的细节。</li>
</ul>
</li>
</ul>
<h4 id="本地方法栈">本地方法栈</h4>
<ul>
<li>Java虚拟机栈用于管理Java方法的调用，而本地方法栈用于管理本地方法的调用。</li>
<li>本地方法栈，也是线程私有的。</li>
<li>允许被实现成固定或者是可动态扩展的内存大小。（在内存溢出方面时相同的）
<ul>
<li>如果线程请求分配的栈容量超过本地方法栈允许的最大容量，Java虚拟机将会<br>
抛出一个 Stack〇verflowError 异常</li>
<li>如果本地方法栈可以动态扩展，并且在尝试扩展的时候无法申请到足够的内存，或者在创建新的线程时没有足够的内存去创建对应的本地方法栈，那么Java虚拟机将会抛出一个OutOfMemoryError异常。</li>
</ul>
</li>
<li>本地方法是使用C语言实现的</li>
<li>它的具体做法是Native Method Stack中登记native方法，在Execution Engine执行时加载本地方法库。</li>
</ul>
<h5 id="本地方法栈运行时状态">本地方法栈运行时状态</h5>
<blockquote>
<p>当某个线程调用一个本地方法时，它就进入了一个全新的并且不在受虚拟机限制的世界。它和虚拟机拥有同样的权限</p>
</blockquote>
<ul>
<li>本地方法可以通过本地方法接口来访问虚拟也机内部的运行时数据区。</li>
<li>它甚至可以直接使用本地处理器中的寄存器</li>
<li>直接从本地内存的堆中分配任意数量的内存。</li>
</ul>
<p>并不是所有的JVM都支持本地方法。因为Java虚拟机规范并没有明确要求本地方法栈的使用语言、具体实现方式、数据结构等。如果jvm产品不打算支持native方法，也可以无需实现本地方法栈。<br>
在Hotspot JVM中，直接将本地方法栈和虚拟机栈合二为一。</p>
<h3 id="4堆heap">4.堆(heap)</h3>
<h4 id="核心概述">核心概述</h4>
<ul>
<li>
<p>一个JVM实例只存在一个堆内存，堆也是Java内存管理的核心区域。</p>
</li>
<li>
<p>Java堆区在 JVM启动的时候即被创建，其空间大小也就确定了。是 JVM管理的最大一块内存空间。</p>
<ul>
<li>堆内存的大小是可以调节的。</li>
</ul>
</li>
<li>
<p>《Java虚拟机规范》规定，堆可以处于物理上不连续的内存空间中，但在逻辑上它应该被视为连续的。</p>
</li>
<li>
<p>所有的线程共享Java堆，在这里还可以划分线程私有的缓冲区（Thread Local Allocation Buffer, TLAB) 。</p>
</li>
</ul>
<hr>
<ul>
<li>《Java虚拟机规范》中对Java堆的描述是：所有的对象实例以及数组都应在运行时分配在堆上。 (The heap is the run-time data area from which memory for all class instances and arrays is allocated ):
<ul>
<li><code>“几乎”</code>所有的对象实例都在这里分配内存。从实际使用角度看的。</li>
</ul>
</li>
<li>数组和对象可能永远不会存储在栈上，因力栈帧中保存引用，这个引用指向对象或者数组在堆中的位置。</li>
<li>在方法结束后，堆中的对象不会马上被移除，仅仅在垃圾收集的时候才会被移除。</li>
<li>堆，是GC ( Garbage Collection，垃圾收集器）执行垃圾回收的重点区域。</li>
</ul>
<h4 id="内存细分">内存细分</h4>
<blockquote>
<p>现代垃圾收集器大部分都基于分代收集理论设计，堆空间可以细分</p>
</blockquote>
<h5 id="java-7及之前">Java 7及之前</h5>
<ul>
<li>堆内存逻辑上分为三部分：新生区+养老区+<code>永久区</code>
<ul>
<li>Young Generation Space 新生区    Young/New
<ul>
<li>又被划分为Eden区和Survivor区</li>
</ul>
</li>
<li>Tenure generation space 养老区 Old/Tenure</li>
<li>Permanent Space 永久区                Perm</li>
</ul>
</li>
</ul>
<h5 id="java-8及之后">Java 8及之后</h5>
<ul>
<li>堆内存逻辑上分为三部分:新生区+养老区+<code>元空间</code>
<ul>
<li>Young Generation Space 新生区 Young/New
<ul>
<li>又被划分为Eden区和Survivor区</li>
</ul>
</li>
</ul>
</li>
<li>Tenure generation space 养老区 Old/Tenure</li>
<li>Meta Space 元空间 Meta</li>
</ul>
<h5 id="年轻代与老年代">年轻代与老年代</h5>
<ul>
<li>存储在JVM中的Java对象可以被划分为两类：
<ul>
<li>一类是生命周期较短的瞬时对象，这类对象的创建和消亡都非常迅速</li>
<li>另外一类对象的生命周期却非常长，在某些极端的情况下还能够与JVM的生命周期保持一致。</li>
</ul>
</li>
<li>Java堆区进一步细分的话，可以划分为年轻代（YoungGen)和老年代（OldGen)</li>
<li>其中年轻代又可以划分为Eden空间、Survivor0空间和Survivor1空间（有时也叫做from区、to区）。</li>
</ul>
<hr>
<ul>
<li>配置新生代与老年代在堆结构的占比。
<ul>
<li>默认- XX: NewRatio=2,表示新生代占1,老年代占2,新生代占整个堆的1/3</li>
<li>可以修改-XX: NewRatio=4,表示新生代占1,老年代占4,新生代占整个堆的 1/5</li>
</ul>
</li>
<li>在HotSpot中，Eden空间和另外两个Survivor空间缺省所占的比例是8 :1:1</li>
<li>当然开发人员可以通选项 “-XX:SurvivorRatio”调整这个空间比例。比如-XX:SurvivorRatio=8
<ul>
<li>几乎所有的 Java对象都是在Eden区被new出来的。</li>
</ul>
</li>
<li>绝大部分的 Java对象的销毁都在新生代进行了。</li>
<li>IBM公司的专门研究表明，新生代中80%的对象都是“朝生夕死”的。</li>
<li>可以以使用选项&quot;-Xmn&quot;设置新生代最大内存大小
<ul>
<li>这个参数一般使用默认值就可以了。</li>
</ul>
</li>
</ul>
<h4 id="堆空间大小的设置">堆空间大小的设置</h4>
<ul>
<li>
<p>Java堆用来储存对象堆实例，那么Java堆的大小在启动时就设定好了，可以通过选项&quot;-Xmx&quot;和&quot;-Xms&quot;来进行设置。</p>
<ul>
<li>“-Xms&quot;用于表示堆区的起始内存，等价于-XX: InitialHeapSize</li>
<li>“-Xmx&quot;则用于表示堆区的最大内存，等价于-XX:MaxHeapSize</li>
</ul>
</li>
<li>
<p>一旦堆区中的内存大小超过“-Xmx&quot;所指定的最大内存时，将会抛出 OutOfMemoryError异常</p>
</li>
<li>
<p>通常会将 -Xms和 - Xmx两个参数配置相同的值，其目的是为了能够在java垃圾回收器清理完堆区后不需要重新分隔计算堆区的大小，从而提高性能。</p>
<ul>
<li>默认情况下，初始内存大小：物理电脑内存大小/ 64</li>
</ul>
</li>
<li>
<p>最大内存大小：物理电脑内存大小/ 4</p>
</li>
</ul>
<h4 id="对象分配过程概述">对象分配过程概述</h4>
<blockquote>
<p>为新对象分配内存是一件非常严谨和复杂的任务，JVM的设计者们不仅需要考虑内存如何分配、在哪里分配等问题，并且由于内存分配算法与内存回收算法密切相关，所以还需要考虑GC执行完内存回收后是否会在内存空间中产生内存碎片。</p>
</blockquote>
<ol>
<li>new 的对象先放在伊甸园区，此区有大小限制</li>
<li>当伊甸园的空间填满时，程序又需要创建对象，JVM的垃圾回收器将对伊甸园区进行垃圾回收(Minor GC),将伊甸园区中的不再被其他对象所引用的对象进行销毁。再加载新的对象放到伊甸园区。</li>
<li>然后将伊甸园中的剩余对象移动到幸存者0区。</li>
<li>如果再次触发垃圾回收，此时上次幸存下来的放到幸存者0区的，如果没有回收，就会到幸存者1区。</li>
<li>如果再次经历垃圾回收，此时会重新放回幸存者0区，接着再去幸存者1区。</li>
<li>啥时候能去养老区呢？可以设罝次数。默认是15次。</li>
</ol>
<ul>
<li>可以设置参数：-XX:MaxTenuringThreshold=<N>进行设置</li>
</ul>
<ol start="7">
<li>在养老区，相对悠闲。当养老区内存不足时，再次触发GC: Major GC,进行养老区的内存清理。</li>
<li>若养老区执行了Major GC之后发现依然无法进行对象的保存，就会产生00M异常</li>
</ol>
<ul>
<li>java.lang.OutOfMemoryError: Java heap space</li>
</ul>
<h5 id="总结">总结</h5>
<ul>
<li>针对幸存者 S0,Sl区的总结：复制之后有交换，谁空谁是to.</li>
<li>关于垃圾回设：频繁在新生区收集，很少在养老区收集，几乎不在永久区/元空间收集</li>
</ul>
<h4 id="minor-gc-major-gc-和full-gc">Minor GC ，Major GC 和Full GC</h4>
<blockquote>
<p>JVM在进行GC时，并非每次都对面三个内存（新生代、老年代、方法区)区域一起回收的，大部分时候回收的都是指新生代。<br>
针对Hotspot VM的实现，它里面的GC按照回收区域又分为两大种类型：一种是部分收集（Partial GC), —种是整堆收集（Full GC)</p>
</blockquote>
<h5 id="部分收集">部分收集</h5>
<p>部分收集：不是完整的收集整个Java堆的垃圾收集。其中又分为：</p>
<ul>
<li>新生代收收集（Minor GC / Young GC)：只是新生代的垃圾收集</li>
<li>老年代收集（Major GC / Old GC)：只有老年代的垃圾收集
<ul>
<li>目前只有CMS GC会有单独收集老年代的行为</li>
<li>注意，很多时候Major GC会 和Full GC浞淆使用，具体要分辨是老年代回收还是整堆回收。</li>
</ul>
</li>
<li>混合收集（Mixed GC):收集整个新生代以及部分老年代的垃圾收集。
<ul>
<li>目前，只有G1 GC会有这种行为</li>
</ul>
</li>
</ul>
<h5 id="整堆收集">整堆收集</h5>
<p>整堆收集(Full GC):收集整个Java堆和方法区的垃圾收集</p>
<h5 id="年轻代-gcminor-gc触发机制">年轻代 GC(Minor GC)触发机制</h5>
<ul>
<li>当年轻代空间不足时，就会触发Minor GC，这里的年轻代满指的是Eden代满，Survivor满不会引发GC。（每次Minor GC会清理年轻代的内存。）</li>
<li>因为Java对象大多都具备朝生夕灭的特性，所以Minor GC非常频繁，一般回收速度也比较快。这一定义既清晰又易于理解。</li>
<li>Minor GC会引发STW，暂停其它用户的线程，等垃圾回收结束，用户线程才恢复运行。<br>
<img src="./1591863057157.png" alt="Alt text" loading="lazy"></li>
</ul>
<h5 id="老年代gc-major-gcfull-gc触发机制">老年代GC (Major GC/Full GC)触发机制：</h5>
<ul>
<li>指发生在老年代的GC,对象从老年代消失时，我们说“Major GC” 或“Full GC“发生了。</li>
<li>出现了Major GC，经常会伴随至少一次的Minor GC (但非绝对的，在ParallelScavenge收集器的收集策略就有直接进行Major GC的策略选择过程)
<ul>
<li>也就足在老年代空间不足时，会先尝试触发Minor GC。如果之后空间还不足则触发Major GC</li>
</ul>
</li>
<li>Major GC的速度一般会比Minor GC慢40倍以上，STW的时间更长。</li>
<li>如果Major GC后，内存还不足，就报00M了 。</li>
<li>Major GC的速度一般会比Minor GC慢10倍以上。</li>
</ul>
<h5 id="fullgc触发机制">FullGC触发机制</h5>
<p>FullGC执行的情况如下五种</p>
<ul>
<li>调用System.gc()时，系统建议执行Full GC,但是不必然执行</li>
<li>老年代空间不足</li>
<li>方法区空间不足</li>
<li>通过Minor GC后进入老年代的平均大小大于老年代的可用内存</li>
<li>由Eden区、survivor0 (From Space)区向survivor1(ToSpace) 区复制时，对象大小大于To Space的可用内存，则把该对象转到老年代，且老年代的可用内存小于该对象大小</li>
</ul>
<p>** 说明：full gc是开发或调优中尽量要避免的。这样暂停的时间会短一些 **</p>
<h4 id="堆分代收集思想">堆分代收集思想</h4>
<p>为什么需要把Jaya堆分代?不分代就不能正常工作了吗?<br>
经研究，不同对象的生命周期不同。70%-99%的对象是临时对象。</p>
<ul>
<li>新生代：有Eden、两块大小相同的Survivor(又称为from/to， s0/s1) 构成，to总为空。</li>
<li>老年代：存放新生代中经历多次GC仍然存活的对象。</li>
</ul>
<p>其实不分代完全可以，分代的唯一理由就是优化GC性能。如果没有分代，那所有的对象都在一块，就如同把一个学校的人都关在一个教室。GC的时候要找到哪些对象没用，这样就会对堆的所有区域进行扫描。而很多对象都是朝生夕死的，如果分代的话，把新创建的对象放到某一地方，当GC的时候先把这块存储“朝生夕死”对象的区域进行回收，这样就会腾出很大的空间出来。</p>
]]></content>
    </entry>
</feed>